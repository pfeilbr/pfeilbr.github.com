[{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/sceptre-playground  learn sceptre, a tool to drive cloudformation\n StackGroup Config - config/dev/config.yaml - project_code, region, profile, etc. Stack Config - config/dev/template.yaml - config for specific stack. e.g. stack params, template_path, dependencies, hooks, etc. Stack - templates/template.yaml  Demo via Get Started — Sceptre 2.6.3 documentation\n# install cli pipx install sceptre # create new project sceptre new project my-sceptre-project cd my-sceptre-project # create stack sceptre create dev/template.yaml # show stack outputs sceptre --ignore-dependencies list outputs dev/template.yaml # update stack sceptre update dev/template.yaml # delete stack sceptre delete dev/template.yaml Resources  sceptre GitHub - Sceptre/sceptre: Build better AWS infrastructure Introduction to Sceptre: An AWS Cloudformation Orchestration Tool  ","permalink":"https://brianpfeil.com/post/sceptre/","postedOnDate":" November 6, 2021","tags":["cloudformation","infrastructure-as-code"],"title":"Sceptre"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-step-functions-aws-sdk-integration-playground  learn AWS Step Functions AWS SDK Integrations. Provides direct integration with 200+ AWS services\nDemo Based on Gather Amazon S3 bucket info using AWS SDK service integrations - AWS Step Functions.\nDeploy example01.yaml stack\n NOTE: ResultSelector added to ListBuckets to hard code an array containing a single bucket to reduce amount of processing.\n PROFILE=\u0026#34;admin\u0026#34; REGION=\u0026#34;us-east-1\u0026#34; STACK_NAME=\u0026#34;aws-step-functions-aws-sdk-integration-playground\u0026#34; aws cloudformation deploy \\  --profile \u0026#34;${PROFILE}\u0026#34; \\  --region \u0026#34;${REGION}\u0026#34; \\  --stack-name \u0026#34;${STACK_NAME}\u0026#34; \\  --template-file example01.yaml \\  --capabilities \u0026#34;CAPABILITY_IAM\u0026#34; \u0026#34;CAPABILITY_NAMED_IAM\u0026#34; \u0026#34;CAPABILITY_AUTO_EXPAND\u0026#34; # execute step fn aws stepfunctions start-execution \\  --state-machine-arn \u0026#34;arn:aws:states:us-east-1:529276214230:stateMachine:Gather-S3-Bucket-Info-Standard\u0026#34; \\  --input \u0026#34;{}\u0026#34; Example Execution\nResources  AWS Step Functions adds support for over 200 AWS Services with AWS SDK Integration Now — AWS Step Functions Supports 200 AWS Services To Enable Easier Workflow Automation | Amazon Web Services AWS SDK service integrations - AWS Step Functions  ","permalink":"https://brianpfeil.com/post/aws-step-functions-aws-sdk-integration/","postedOnDate":" October 15, 2021","tags":["aws","sdk","step-functions"],"title":"AWS Step Functions AWS SDK Integration"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/github-actions-configure-aws-credentials-playground  learn aws-actions/configure-aws-credentials\nDemo PROFILE=admin REGION=us-east-1 STACK_NAME=\u0026#34;configure-aws-credentials-playground\u0026#34; aws cloudformation deploy \\  --profile \u0026#34;${PROFILE}\u0026#34; \\  --region \u0026#34;${REGION}\u0026#34; \\  --stack-name \u0026#34;${STACK_NAME}\u0026#34; \\  --template-file sample-role.yaml \\  --capabilities \u0026#34;CAPABILITY_IAM\u0026#34; \u0026#34;CAPABILITY_NAMED_IAM\u0026#34; \\  --parameter-overrides GitHubOrg=pfeilbr \\  RepositoryName=github-actions-configure-aws-credentials-playground \\ # OIDCProviderArn=\u0026#34;arn:aws:iam::529276214230:oidc-provider/vstoken.actions.githubusercontent.com\u0026#34; # run workflow manually gh workflow run default.yml # list runs gh run list --workflow=default.yml # show run details  gh run view \u0026lt;run-id\u0026gt; # delete stack aws cloudformation delete-stack \\  --profile \u0026#34;${PROFILE}\u0026#34; \\  --region \u0026#34;${REGION}\u0026#34; \\  --stack-name \u0026#34;${STACK_NAME}\u0026#34; successful workflow run with aws sts get-caller-identity\nResources  aws-actions/configure-aws-credentials AWS federation comes to GitHub Actions benkehoe/github-actions-boto3-demo: Demonstrate how GitHub OIDC token getting should be included in boto3  ","permalink":"https://brianpfeil.com/post/github-actions-configure-aws-credentials/","postedOnDate":" October 6, 2021","tags":["aws","github","iam"],"title":"GitHub Actions | Configure AWS Credentials"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/github-actions-playground  learn github actions\nResources  GitHub Actions Documentation - GitHub Docs  ","permalink":"https://brianpfeil.com/post/github-actions/","postedOnDate":" September 20, 2021","tags":[],"title":"GitHub Actions"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/ngrok-playground  learn ngrok npm package\nsee index.js\nDemo expose local express.js web app\nnpm install node index.js screenshots\nResources  GitHub - bubenshchykov/ngrok: Expose your localhost to the web. Node wrapper for ngrok.  ","permalink":"https://brianpfeil.com/post/ngrok/","postedOnDate":" September 20, 2021","tags":[],"title":"Ngrok"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-healthlake-playground  learn Health Data Lake and Healthcare Analytics - Amazon HealthLake - Amazon Web Services\nConcepts  DataStore  data is encrypted at rest  Customers can choose an AWS owned KMS key or a Customer-managed KMS key when creating a Data Store.\n  encrypted in transit  Amazon HealthLake uses TLS 1.2 to encrypt data in transit through the public endpoint and through backend services.\n    import data (line delimited json record - .ldjson) from S3 bucket  where each line consists of a valid FHIR resource   query data using Create, Read, Update, Delete functions via provided REST endpoint for a given DataStore use FHIR search  After the data is ingested, it is indexed using Amazon ES, which makes the data searchable.\n  Integrated medical natural language processing (NLP)  the NLP results are automatically included in the results for a returned DocumentReference resource type. No separate actions/etc. required.   Amazon HealthLake automatically integrates with natural language processing (NLP) for the DocumentReference resource type. The integrated medical NLP output is provided as an extension to the existing DocumentReference resource. The integration involves reading the text data within the resource, and then calling the following integrated medical NLP operations: DetectEntities-V2, InferICD10-CM, and InferRxNorm.\n  export data to S3  Amazon HealthLake enables you to bulk export your files to an Amazon S3 bucket. Use either the console or start-fhir-export-job to begin an export job. Afterwards, you can use describe-fhir-export-job to monitor the status of the job and discover its properties. After the export job is complete, the data can then be visualized using AWS Quicksight or accessed by other AWS services.\n  VPC endpoint (PrivateLink) support  You can establish a private connection between your VPC and Amazon HealthLake by creating an interface VPC endpoint. Interface VPC endpoints are powered by AWSPrivateLink\n   Examples # https://docs.aws.amazon.com/healthlake/latest/devguide/healthlake-examples-cli.html ​aws healthlake create-fhir-datastore \\  --datastore-type-version R4 \\  --preload-data-config PreloadDataType=\u0026#34;SYNTHEA\u0026#34; \\  --datastore-name \u0026#34;FhirTestDatastore\u0026#34; Resources  Paging Doctor Cloud! Amazon HealthLake Is Now Generally Available | Amazon Web Services Amazon HealthLake Workshop https://www.hl7.org/fhir/patient-examples.html# - FHIR examples  ","permalink":"https://brianpfeil.com/post/aws-healthlake/","postedOnDate":" September 16, 2021","tags":["aws"],"title":"AWS Healthlake"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/hugging-face-playground  learn hugging face transformers (transfer learning)\nbased on Hugging Face Transformers Package – What Is It and How To Use It - KDnuggets\nTransformers is an opinionated library built for:\n NLP researchers and educators seeking to use/study/extend large-scale transformers models hands-on practitioners who want to fine-tune those models and/or serve them in production engineers who just want to download a pretrained model and use it to solve a given NLP task.  Demo pipenv install pipenv install transformers pipenv install tensorflow # note first run will download the [pipeline] model (potentially time consuming) on first run pipenv run python main.py Resourcces  Hugging Face – The AI community building the future. Hugging Face Transformers Package – What Is It and How To Use It - KDnuggets Hosting Hugging Face models on AWS Lambda for serverless inference | Amazon Web Services  ","permalink":"https://brianpfeil.com/post/hugging-face/","postedOnDate":" September 13, 2021","tags":["machine-learning","nlp","python"],"title":"Hugging Face"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/cdktf-playground  learn cdktf. based on Build AWS Infrastructure with TypeScript\nNotes  cdktf generates tf hcl json cdktf synth creates cdktf.out can use tf apply within a cdktf.out/stacks/* directory to deploy or let cdktf do both the synth and tf deploy  Demo cdktf init --template=typescript --local # add aws provider to `cdktf.json` // \u0026#34;hashicorp/aws@~\u0026gt; 3.42\u0026#34; # creates `.gen` folder which is codegend .ts cdktf get # edit `main.ts` # deploy cdktf deploy # clean up cdktf destroy Directory Structure\nDeploy Output\nDestroy Output\nResources  Write CDK for Terraform configurations  ","permalink":"https://brianpfeil.com/post/cdk-for-terraform/","postedOnDate":" September 3, 2021","tags":["aws","cdk","terraform"],"title":"CDK for Terraform"},{"categories":[],"contents":"azure  Management IAM  Service Principals Roles Role Assignments Resources   Azure Policy Azure Resource Manager (ARM)  Resources   Azure Blueprints Blob Storage  Resources   Storage Queues Service Bus Queues Service Bus Topics  Resources   Event Grid  Resources   Event Hub Cosmos DB SQL Database SQL Managed Instance Static Web Apps Functions  Resources   Function Proxies  Resources   API Management (APIM)  Resources   SignalR  Resources   Key Vault CDN App Configuration Data Factory Synapse Analytics HDInsight Databricks Data Lake Analytics Logic Apps  Resources   Application Insights Cognitive Search Introducing Authentication Azure AD Authentication Options for Users Azure Cost Management + Billing documentation  Management  Account -\u0026gt; [Management Groups] -\u0026gt; Subscriptions -\u0026gt; Resources Groups -\u0026gt; Resources  e.g. hierarchy in URI for Key Vault Resource /subscriptions/8a1f586d-1032-4471-803a-25126ef17c42/resourceGroups/resource-group-01/providers/Microsoft.KeyVault/vaults/pfeilkeyvault01   Management Groups (enable enterprise governance) are optional but allow you to group subscriptions and apply policies at management group level that are inherited by all contained subscriptions. (e.g. only create storage accounts in a given geography) Billing done at Subscription level Resource groups - scope for applying role-based access control (RBAC) permissions   Regions Availability Zones Each Azure region is always paired with another region within the same geography. provide reliable services and data redundancy  IAM  Azure AD - stories identities in directory and governs access to azure resources. Identity - the fact of being something or someone. e.g. Users, Applications, Servers. Authentication - process of verification of identity Authorization - process of ensuring that only authenticated identities get access to the resources for which they have been granted access. Access Management - process of controlling, verifying, tracking and managing access to authorized users and applications.   RBAC - role based access control Azure AD Roles - roles that allow admin access to global (tenant-level) settings and services. e.g. user and group admin, domain names, adding/removing user licenses, etc. Azure Roles - roles that define permissions to azure resources. Privileged Identity Management (PIM) - just in time access to elevated roles. Eligible roles are assigned to a user. That user can go into PIM to request access. Duration and reason can be set when requesting and assuming the elevated role.  Service Principals  An Azure service principal is a security identity used by user-created apps, services, and automation tools to access specific Azure resources. Think of it as a \u0026lsquo;user identity\u0026rsquo; (login and password or certificate) with a specific role, and tightly controlled permissions to access your resources. It only needs to be able to do specific things, unlike a general user identity. It improves security if you only grant it the minimum permissions level needed to perform its management tasks.\n Similar to AWS IAM User\n create service principal in portal via Azure AD | App registrations  # create service principal az ad sp create-for-rbac --name \u0026#34;http://service-principal-01\u0026#34; # assign role az role assignment create --assignee \u0026#34;00133c8e-a08e-490e-ae7c-872ea2debf1e\u0026#34; --role Contributor # login az login --service-principal -u \u0026lt;appid\u0026gt; --password {password-or-path-to-cert} --tenant {tenant} Roles  permissions - read blob (Microsoft.Storage/storageAccounts/blobServices/containers/blobs/read). read storage queue (Microsoft.Storage/storageAccounts/queueServices/queues/messages/read) scopes - subscriptions or resource groups) where this role will be available for assignment. Azure RBAC scope covers management groups, subscriptions, resource groups, and resources Portal | Subscription | Access control (IAM) - assign / create / delete roles.  Role Assignments  process of attaching a role definition to a user, group, service principal, or managed identity at a particular scope for the purpose of granting access Role Definition (permissions) + Resource + Scope Can view / managed in portal via \u0026ldquo;Access control (IAM)\u0026rdquo; blade  Resources  Role-Based Access Control | AZ-900 Episode 28 - Cheat Sheet Use Azure service principals with Azure CLI Create an Azure AD app \u0026amp; service principal in the portal - Microsoft identity platform Securing Azure Services with Managed Identities Azure AD consent framework - describes process of grant permissions to an application and the user consent flow  Azure Policy  policies focus on resource properties e.g. only create resources where location is US. Policy Definitions - include ALLOW and DENY for singular check and singular effect Initiative - grouping of multiple policies can assign policy at the following scope levels: management group, subscription, resource group  can add an exclusion scope that specifies where not to apply the policy   show which resources are compliant and non-compliant with policies there are built-in policies and you can create you own custom policies  summary\nazure portal view\npolicy blocking resource creation\nAzure Resource Manager (ARM)  infrastructure-as-code with json parameters, variables, resources, outputs nested templates external templates. reference via URL  Resources  Azure/azure-quickstart-templates  Azure Blueprints similar to AWS Service Catalog\n helps with ensuring security and compliance Package of various Azure components (artifacts). Resource Groups, ARM Templates, Policy Assignments, Role Assignments central repository for pre-approved patterns and solutions Blueprint Definitions - container for artifacts Blueprint Assignments - assign to resource group and it deploys artifacts to it supports versioning.  Blob Storage Resources  Static website hosting in Azure Storage  Storage Queues  good for async worker processes 64 kb size limit on messages messages stored up to 7 days  Service Bus Queues  FIFO 256 KB - 1 MB message size duplicate detection (idempotent) supports in order and at-most-once delivery dead-letter queues message expiration  Service Bus Topics  topic and subscriptions support duplicate detection (idempotent) message TTL dead-letter queues  Resources  Service Bus Explorer on the Azure portal is now available in preview  Event Grid  AWS EventBridge Publishers - built-in events from azure services. custom events from own applications Event Sources - where the event happens. e.g. Azure Storage Topics - endpoint where the source sends events  System topics - built-in topics provided by Azure services such as Azure Storage, Azure Event Hubs, and Azure Service Bus Custom topics - application and third-party topics   Subscriptions - which events on a topic you\u0026rsquo;re interested in receiving. When creating the subscription, you provide an endpoint for handling the event  Resources  Azure Resource Manager template samples - Event Grid - Azure Event Grid Receive events from Azure Event Grid to an HTTP endpoint - Azure Event Grid  Event Hub   AWS Kinesis\n  streaming\n  partitions\n  consumer groups, consumers\n  listening streaming applications\n  stream to blob storage (similar to aws firehose -\u0026gt; S3) as .avro files\n  namespace -\u0026gt; hub\n  Cosmos DB  NoSQL multi-model / multiple interfaces - SQL, MongoDB, Cassandra, Tables, and Gremlin similar to AWS DynamoDB  SQL Database  PaaS Database Engine (not fully managed) handles upgrading, patching, backups, and monitoring, without user involvement similar to AWS RDS  SQL Managed Instance  \u0026hellip;  Static Web Apps  allows you to build modern web applications that automatically publish from changes made in GitHub.  Functions  triggers and bindings Azure Durable Functions - lets you write stateful functions in a serverless compute environment. Similar to AWS Step Functions, but implemented as language level library custom handlers via binary that runs local http server  deploy function via zip file. ensure correct nodejs folder structure\naz functionapp deployment source config-zip -g \u0026lt;resource_group\u0026gt; -n \\ \u0026lt;app_name\u0026gt; --src \u0026lt;zip_file_path\u0026gt; When http triggered function is configured with Azure AD authentication, the identity information is in the req.headers\nExample\n\u0026#34;x-ms-client-principal-name\u0026#34;: \u0026#34;brian.pfeil@gmail.com\u0026#34;, \u0026#34;x-ms-client-principal-id\u0026#34;: \u0026#34;38d35c72-5a26-464c-bbb3-c4487a1d4779\u0026#34;, \u0026#34;x-ms-client-principal-idp\u0026#34;: \u0026#34;aad\u0026#34;, Resources  mspnp/serverless-reference-implementation - great full-stack serverless reference Zip push deployment for Azure Functions JavaScript developer reference for Azure Functions  Function Proxies  Proxies are defined inside a proxies.json configuration file at the root of the project. see following for details https://docs.microsoft.com/en-us/azure/azure-functions/functions-proxies#advanced-configuration allow us to define a single API surface for multiple function apps map a path (/something) to backend URL. e.g. /hello -\u0026gt; https://durablefnsplayground01.azurewebsites.net/api/orchestrators/{functionName}?code=UD0/aY27zc3FPpjNjaAqMU73yVJuLB1tva3U9TaaWDAMzwEzg3qeVA== this way you don\u0026rsquo;t need to expose code query string parameter you can map a path and hard code a response for mocking  Resources  Work with proxies in Azure Functions Microsoft Azure Function Proxies in 5 Minutes  API Management (APIM)  AWS API Gateway import OpenAPI /Swagger spec can import a function app as an API in API Management APIM product - contains one or more APIs as well as a usage quota and the terms of use. Once a product is published, developers can subscribe to the product and begin to use the product\u0026rsquo;s APIs Subscriptions - developers who need to consume the published APIs must include a valid subscription key in HTTP requests when they make calls to those APIs  can be scoped to product, all APIs, or an individual API need to provide ocp-apim-subscription-key header when calling   Policies - allow the publisher to change the behavior of the API through configuration.  specified in XML Allow for request and response transformations. Rate limiting. Similar to AWS APIG request/response mapping templates.   as of 2021-02-12 takes about 30 min to create API Management instance  Resources  Import an Azure Function App as an API in API Management - Azure API Management Policies in Azure API Management  SignalR  real-time application websocket, SSE (EventSource), HTTP long polling  Resources  Enable automatic updates in a web application using Azure Functions and SignalR Service - Learn MicrosoftDocs/mslearn-advocates.azure-functions-and-signalr  Key Vault  AWS Secrets Manager functions can have Key Vault references which make the secrets available in environment variables. The secrets are also caches per function instance on startup  Example Secret\nCDN  CDN profile - collection of CDN endpoints  App Configuration  centralized service for management of application settings and feature flags supports key vault integration via references to the secrets stored in key vault integrates with event grid. emits events when App Configuration changes that you can subscribe and respond to e.g. A/B testing with percentages e.g. multiple apps use same settings like storage key  Data Factory  managed ETL concepts  Pipelines - outer container Connections (Linked Services) - connection information for source(s) and sink(s) with credentials / keys Dataset - file formats and schema Activities - copy data, transform, etc. Triggers - on-demand/manual (REST API), scheduled, tumbling windows, event based via event grid for blob storage for a pipeline run Parameters - can be passed into pipeline and used with the various types.    Synapse Analytics  \u0026hellip;  HDInsight  Apache Spark , Apache Hadoop , Apache Kafka , Apache HBase , Apache Storm , and Machine Learning Services like AWS EMR  Databricks  spark, hadoop, and friends \u0026hellip;  Data Lake Analytics  \u0026hellip;  Logic Apps  schedule, automate, and orchestrate tasks, business processes, and workflows when you need to integrate apps, data, systems, and services across enterprises or organizations  Guidance\nThe following flowchart summarizes the key questions to ask when you\u0026rsquo;re considering using Logic Apps.\nResources  Securing Logic App with Azure AD authentication using API Management Workflow Definition Language schema reference - Azure Logic Apps  Application Insights  author queries using Kusto Query Language  Cognitive Search  indexing  push model - upload json docs for indexing pull model - point indexers where the content lives. e.g. azure blob storage   querying - can include relevance tuning, autocomplete, synonym matching, fuzzy matching, pattern matching, filter, and sort. spelling mistakes, geospatial queries, paging, highlighting. Skillset - content type indexer for unstructured and structured content (docx, pdf, ). predefined ones from Microsoft, or custom skills that you create. e.g. text split skill, sentiment detection skill  document cracking - understand the contents of the document. text, images, metadata, etc.   portions of underlying tech is based on apache lucene   Introducing Authentication   OAuth 2.0 is specifically about authorization and permissions\n  Open ID Connect (OIDC) is focused on authentication and built on OAuth 2.0. Has strict JWT format that part of the spec.\n  identity token\n typically JWT user claims - e.g. username, email    access token\n short lived (e.g. 1 hr) typically JWT scope    refresh token\n long life (e.g. 14 days) can be used to request an access token without the user needing to login again    Azure AD Authentication Options for Users  Azure AD Connect - replicate objects in AD to Azure AD. AD is the source of truth.  Azure Cost Management + Billing documentation  https://docs.microsoft.com/en-us/azure/cost-management-billing/  ","permalink":"https://brianpfeil.com/post/azure/","postedOnDate":" June 15, 2021","tags":["azure"],"title":"Azure"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-api-gateway-to-s3-static-site-playground   WARNING: you probably shouldn\u0026rsquo;t do this / there\u0026rsquo;s a better way just because you can do it doesn\u0026rsquo;t mean you should :) was curious if it could be done\n#awswishlist private s3 bucket websites with TLS support\n   example of hosting static site (create-react-app) with api gateway -\u0026gt; s3 static site content at my-react-app  Example Deployment Steps STAGE=\u0026#34;dev\u0026#34; STACK_NAME=\u0026#34;aws-api-gateway-to-s3-static-site-playground\u0026#34; # deploy resoruces sam deploy --guided # build react app pushd my-react-app # need to set root to subpath because of api gateway stage in path limitation PUBLIC_URL=\u0026#34;/${STAGE}\u0026#34; npm run build popd # deploy site aws s3 sync my-react-app/build/ s3://aws-api-gateway-to-s3-static-sit-staticsitebucket-2k3gk0lgl72u # visit site open https://a4kesxi0gg.execute-api.us-east-1.amazonaws.com/dev/index.html screenshots Resources  API-Gateway S3 Proxy - followed this console guide to get it to work. export as openapi from console and embed in template.yaml Tutorial: Create a REST API as an Amazon S3 proxy in API Gateway - Amazon API Gateway API Gateway S3 Integration Signature does not match with blank folder name Functionless S3 Integration inside a Serverless Casserole-Part 1 SAM Template for AWS Api Gateway Integration with S3 as AWS Service  ","permalink":"https://brianpfeil.com/post/aws-api-gateway-to-s3-static-site/","postedOnDate":" May 21, 2021","tags":["aws","s3","api-gateway"],"title":"AWS API Gateway to S3 Static Site"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-app-runner-playground  learn AWS App Runner\nComments  good service to get users \u0026ldquo;closer\u0026rdquo; to serverless on eases the onboarding to AWS for solutions less knobs/options to turn/get wrong it\u0026rsquo;s cheap, but not as cheap as lambda. public only endpoints for now similar goals and roadmap as GCP Cloud Run (AWS is playing catch-up) More choices for containers and potentially confusing for customers (container options menu is getting pretty big)   Notes  prefer App Runner AWS managed container runtimes (e.g. Node and Python). Similar to lambda, ElasticBeanstalk, CloudFoundry, Heroku, etc. App Runner product manager said the managed container runtimes as based on elastic beanstalk. (source video - AWS App Runner Workshop) aws takes care of / not your responsibility  load balanced autoscale no clusters   App Runner configuration file (apprunner.yaml) - connect directly to github config options  health check config cpu, memory instance role   see Create a source code repository service for all options\n  custom domain support Node and Python managed container runtimes to start. Planned to support and follow order of lambda supported runtimes. public endpoints only (as of 2021-05-18) - see roadmap #1, #2 for private endpoints and access to VPC resources.   Pricing  You are charged for the compute and memory resources used by your application. In addition, if you automate your deployments, you will pay a set monthly fee for each application that covers all automated deployments for that month. If you opt to deploy from source code, you will pay a build fee for the amount of time it takes App Runner to build a container from your source code.\n  Demo # setup mkdir hello-app-runner touch apprunner.yaml # install venv and deps pipenv install # run locally pipenv run python app.py # deploy SERVICE_NAME=\u0026#34;hello-app-runner-01\u0026#34; aws apprunner create-service --service-name ${SERVICE_NAME} \\  --source-configuration file://apprunner.yaml  Resources  Introducing AWS App Runner Hello AWS App Runner - youtube AWS App Runner Workshop - youtube. good details on roadmap. aws tech pm is a part of it. Documentation | AWS App Runner aws-containers/apprunnerworkshop apprunner-roadmap - vote up issues important to your needs aws-containers/hello-app-runner AWS App Runner API Reference Pricing  ","permalink":"https://brianpfeil.com/post/aws-app-runner/","postedOnDate":" May 19, 2021","tags":["aws","containers"],"title":"AWS App Runner"},{"categories":[],"contents":"Source Resources  Thinking Architecturally - Nathaniel Schutta - youtube Thinking Architecturally: Lead Technical Change Within Your Engineering Team - oreilly book Infrastructure \u0026amp; Ops Superstream Series: CI/CD - oreilly video Building Evolutionary Architectures - oreilly book  Notes (Thinking Architecturally - Nathaniel Schutta youtube video)  AaaS - Architecture-as-a-Service many competing agendas technology change is a constant nobody wants to be on legacy platform  java foundational tech for aws, google, twitter, netflix, etc.   how to evaluate technology chasing the new things computer science - lifetime learning education doesn\u0026rsquo;t end. lifetime of learning. developers have strong opinions new and old tech https://youtu.be/d5bNZX8tpiI?t=681 new - unfinished, unbuggy, unproven old - refined, stable, tested predictable hype cycle how do we know where not to use tech. takes trial and error. asked to build something never built before, using tools we got a few weeks ago, shocked we don\u0026rsquo;t know how long it takes developer get bored quickly learning keeps it fresh commit at some point. can\u0026rsquo;t constantly experiment bleeding edge \u0026hellip; means you will bleed pioneers \u0026hellip; ones with arrows in back hope is not a strategy need to be deliberate when it comes to technology choices challenge is how to keep up (\u0026ldquo;technology merry go round\u0026rdquo;) make it part of routine to learn  \u0026ldquo;morning coffee\u0026rdquo; - peruse the tech news   attention is most precious resource you have  attention is a resource. it doesn\u0026rsquo;t scale. don\u0026rsquo;t waste your attention. have to be selective.   if its a big enough deal, you will hear about it. how do we know where to invest our time?  be aware of bias skating to where the puck was   thoughtworks technology radar  20% projects are good space, but fallen out of favor in some circles   innovation fridays architectural briefing - one person does research, presents back to team. short ~45min  briefing pans out -\u0026gt; workshop/invest more in it   greenfield always works. need to use in target env to understand constraints start with low risk capability / not company core security - want to stay safe, need to go fast. time feeds black hats policy needed. measure and enforce, hard part pros and cons - always trade-offs \u0026ldquo;it depends\u0026rdquo; means -\u0026gt; tell me more. not a stopper. ack the negatives. the most insight is learned from this question \u0026ldquo;You haven\u0026rsquo;t mastered a tool until you understand when it should not be used\u0026rdquo; - Kelsey what is the appropriate scale for evaluation. e.g. 1-5  harvey balls. images to remove the \u0026ldquo;hard number\u0026rdquo; focus effect  nobody tells you which criteria to use, up to you, need to make with incomplete information   architects spread thin, need to scale with principles, north stars, etc. arch agile backlash. chose tech that can evolve - evolutionary arch  create arch with expectation of change. à la werner \u0026ldquo;everything fails, all the time\u0026rdquo; \u0026ldquo;evolutionary arch supports guided, incremental change across multiple dimensions\u0026rdquo;   [arch]fitness functions  0: make arch change, 1: eval result, 2: closer to goal? yes -\u0026gt; keep, no -\u0026gt; trash, 3: -\u0026gt; goto 0 (basic regression iterations as in stats/ML) set of tests we exec to validate arch. (arch unit tests) reminds everyone on the team what\u0026rsquo;s important for your arch informs discussions around tradeoffs need to be visible to team need to be reviewed on regular basis   just because you can measure it doesn\u0026rsquo;t mean it matters avoid resume driven design  ","permalink":"https://brianpfeil.com/post/thinking-architecturally/","postedOnDate":" May 13, 2021","tags":["architecture"],"title":"Thinking Architecturally"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/hashicorp-vault-playground  learn HashiCorp Vault\nNotes  iam and ec2 auth methods iam uses sts:GetCallerIdentity under the hood  vault server receives request with attributes to construct sigv4 and issues the request to AWS STS AWS STS API endpoint is wide open / available to anyone. No auth required to issue request to it.   vault roles map/bind to aws roles - vault roles add additional capabilities (e.g. leases, finer grain policies, etc.). new layer to manage  Demo # install macOS (single golang binary) brew tap hashicorp/tap brew install hashicorp/tap/vault # start in-memory server vault server -dev # set env vars export VAULT_ADDR=\u0026#39;http://127.0.0.1:8200\u0026#39; export VAULT_TOKEN=\u0026#34;s.uObLGyypsT6LWnxNaKNurYaV\u0026#34; # ok to expose for demo. ephemeral for in-memoery dev # confirm connectivity / env vars / server running vault status # put secret vault kv put secret/hello foo=bar # get secret (json output) vault kv get -format=json secret/hello # delete secret vault kv delete secret/hello # list secrets engines vault secrets list -format=json # enable aws secrets engine vault secrets enable -path=aws aws # make aws keys available to env export AWS_ACCESS_KEY_ID=\u0026lt;aws_access_key_id\u0026gt; export AWS_SECRET_ACCESS_KEY=\u0026lt;aws_secret_key\u0026gt; # configure AWS secrets engine vault write aws/config/root \\  access_key=$AWS_ACCESS_KEY_ID \\  secret_key=$AWS_SECRET_ACCESS_KEY \\  region=us-east-1 # create role vault write aws/roles/my-role \\  credential_type=iam_user \\  policy_document=-\u0026lt;\u0026lt;EOF { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1426528957000\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] } ] } EOF # generate access key pair for role # creates an IAM user with the policy inlined. # e.g. arn:aws:iam::529276214230:user/vault-root-my-role-1620146368-5005 vault read aws/creds/my-role  Screenshots Example IAM User Created by Vault  Resources  Vault Tutorials - HashiCorp Learn Getting Started | Vault - HashiCorp Learn HTTP API: Libraries | Vault by HashiCorp AWS - Auth Methods | Vault by HashiCorp hashicorp/vault-lambda-extension - utilizes the AWS Lambda Extensions API to help your Lambda function read secrets from your Vault deployment https://registry.terraform.io/modules/hashicorp/vault/aws/latest/examples/vault-iam-auth Serverless lambda with vault — Avoiding committing your passwords  ","permalink":"https://brianpfeil.com/post/hashicorp-vault/","postedOnDate":" May 4, 2021","tags":["secrets-management","security"],"title":"Hashicorp Vault"},{"categories":[],"contents":"Multi-Account AWS Environment options.\nAWS Landing Zone In short, it a collection of AWS accounts and other mechanisms to establish guardrails within those accounts.\nCreated as part of AWS Solutions Library.\n AWS Landing Zone is currently in Long-term Support and will not receive any additional features\n Should now use AWS Control Tower\n zip file with CloudFormation templates builds accounts types enables AWS Config, apply config rules enables CloudTrail enables SSO and AD connector Builds Account Vending Machine - self-service portal using Service Catalog to allow devs to request accounts, which are then created via CodePipeline  Core Accounts The following landing zone managed accounts are created as part of landing zone\n Log Archive - consolidated log files Security - creates auditor (read-only) and administrator (full-access) cross-account roles from a Security account to all AWS Landing Zone managed accounts. Also master Amazon GuardDuty account Shared services - AD, DNS, LDAP Sandbox Accounts - devs can experiment / PoCs/ etc. Business Unit accounts - dev, test, prod workloads  AWS Control Tower  Better packaged and managed AWS Landing Zone. AWS Landing Zone as a first class AWS service. Functions as a pre-baked layer of abstraction on top of AWS Organizations, AWS Config, CloudTrail, CloudFormation, and a few other services All in AWS Console. No IaC for it.  Control Tower Landing Zone Creating Service Catalog | Create Control Tower Manged Account superwerker  Opinionated layer on top of Control Tower. Automates the setup of an AWS Cloud environment with prescriptive best practices.  AWS Organization Formation  Infrastructure as Code (IaC) tool for AWS Organizations. Implemented using CloudFormation Custom Resource Types (providers) which then orchestrate and call the relevant AWS APIs  Resources  AWS Control Tower Customizations for AWS Control Tower | Implementations | AWS Solutions AWS Organizations superwerker AWS Organization Formation AWS CONTROL TOWER - How to Automate Landing Zone deployment with AWS Control Tower | Detailed DEMO  ","permalink":"https://brianpfeil.com/post/multi-account-aws-environment/","postedOnDate":" April 29, 2021","tags":["aws","governance","management"],"title":"Multi-Account AWS Environment"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-chalice-playground  learn aws/chalice\n framework for writing serverless apps in python. It allows you to quickly create and deploy applications that use AWS Lambda.\n Notes  focus is on building REST APIs (API Gateway + lambda) event sources support - cron, EventBridge, S3, SNS, SQS, Kinesis, DynamoDB compiles down to SAM template + zip containing python code + dependencies can combine with CDK to get all CDK features + chalice easy workflow/deploy benefits   Demo # install in isolated venv via pipx pipx install chalice # create new project chalice new-project helloworld # deploy cd helloworld chalice deploy # see `helloworld/.chalice` for package artifacts # test api gateway endpoint curl https://zqzmirc025.execute-api.us-east-1.amazonaws.com/api/ # output: {\u0026#34;hello\u0026#34;:\u0026#34;world\u0026#34;} # generate package chalice package packaged/ # SAM template created at `helloworld/packaged/sam.json` # bundled python code + deps at `helloworld/packaged/deployment.zip` # tear down chalice delete contents of helloworld/packaged/deployment.zip\nResources aws/chalice\n","permalink":"https://brianpfeil.com/post/aws-chalice/","postedOnDate":" April 28, 2021","tags":["aws","serverless","python","lambda"],"title":"AWS Chalice"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-cdk-step-functions-playground  CDK app providing API Gateway endpoint to provision a CloudFormation stack. Endpoint is backed by step function that initiates the create-stack and polls (describe-stack) on an interval for completion.\nThis can be used as a backend to provision a AWS CloudFormation Custom Resource Type that itself is backed by a set of AWS services.\nsee CDK stack components at lib/aws-cdk-step-functions-playground-stack.ts\nArchitecture lambda lambda - \"step fn\" \"step fn\" - \"lambda\\n(cfn create stack)\" \"lambda\\n(cfn create stack)\" - wait wait - \"lambda\\n(create stack status)\" \"lambda\\n(create stack status)\" - \"choice (stack created?)\" \"choice (stack created?)\"-wait \"choice (stack created?)\"-end } --  Dependencies  CDK awscurl  Demo # install deps npm install # deploy cdk deploy --force --require-approval never # test with IAM auth (aws sigv4 request) awscurl --service execute-api -X POST https://7t0zeiul1l.execute-api.us-east-1.amazonaws.com/prod/ -d \u0026#39;{\u0026#34;foo\u0026#34;: \u0026#34;bar\u0026#34;}\u0026#39;  Welcome to your CDK TypeScript project! This is a blank project for TypeScript development with CDK.\nThe cdk.json file tells the CDK Toolkit how to execute your app.\nUseful commands  npm run build compile typescript to js npm run watch watch for changes and compile npm run test perform the jest unit tests cdk deploy deploy this stack to your default AWS account/region cdk diff compare deployed stack with current state cdk synth emits the synthesized CloudFormation template  ","permalink":"https://brianpfeil.com/post/aws-cdk-step-functions/","postedOnDate":" April 26, 2021","tags":["aws","cdk","step-functions"],"title":"AWS CDK Step Functions"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-cloudformation-custom-resource-type-playground  examples for creating CloudFormation extensions and specifically CloudFormation Custom Resource Type\n An extension is an artifact, registered in the CloudFormation Registry, which augments the functionality of CloudFormation in a native manner\n  You can use the CloudFormation CLI to register extensions—both those you create yourself, as well as ones shared with you—with the CloudFormation registry. This enables you to use CloudFormation capabilities to create, provision, and manage these custom types in a safe and repeatable manner, just as you would any AWS resource\n There are the following four types of CloudFormation extension mechanisms:\n CloudFormation Custom Resources CloudFormation Module CloudFormation Custom Resource Types CloudFormation Macros  Example Custom Resource Types  python-custom-resource-type-example typescript-custom-resource-type-example  Notes  Custom resources can be backed by lambda or SNS topic  TODO  Org::Service::WAFCDN -\u0026gt; CDK app containing API Gateway (custom auth token | or cloudformation security context identity) -\u0026gt; Step Fn -\u0026gt; create stack -\u0026gt; wait stack -\u0026gt; loop custom resource lambda handler is just a pass through to APIG provisioning the resources. store API Key in secrets manager and reference from cfn custom resource type property  - Sid:DeleteAppRolesEffect:AllowAction:- wafcdn:*Resource:!Sub \u0026#34;arn:aws:cloudformation:${AWS::Region}:${AWS::AccountId}:type/resource/MyOrg-MyService-MyResource/*\u0026#34;Resources  User Guide for Extension Development Use Python to manage third-party resources in AWS CloudFormation | Amazon Web Services Learn Best Practices for Implementing AWS Lambda-backed Custom Resources with AWS CloudFormation Writing an AWS CloudFormation Resource Provider in Python: Step by Step - Cloudar CloudFormation Resource Providers - A Chicken and Egg Problem Resolve the \u0026quot;Resource timed out waiting for creation of physical resource\u0026quot; error in AWS CloudFormation Deploying CloudFormation resource type  ","permalink":"https://brianpfeil.com/post/aws-cloudformation-custom-resource-type/","postedOnDate":" April 23, 2021","tags":["aws","cloudformation"],"title":"AWS CloudFormation Custom Resource Type"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-cdk-pipeline-playground  learn AWS CDK Pipelines\nExample CI/CD pipeline and solution code exist in single CDK project / repo in all authored in same language (typescript). Any commits to main automatically trigger a CodePipeline to run and deploy changes to production. The changes can be to the solution or the pipeline itself.\nSummary  Simple API Gateway -\u0026gt; Lambda solution to exercise CDK pipeline capabilities. via AWS Solutions Constructs | aws-apigateway-lambda Creation of PreProd enviroment (stack) with e2e integration tests. Creation of Prod environment (stack) Automated creation of metrics, alarms, and notification (sns email) for API Gateway and Lambda resources via awslabs/cdk-watchful Automated notification (sns email) of CodePipeline state change events (STARTED, SUCCEEDED, FAILED) via EventBridge -\u0026gt; SNS rule.  High-level Development Workflow  Create solution stack lib/aws-cdk-pipeline-playground-stack.ts (API gateway -\u0026gt; Lambda). Create stage lib/aws-cdk-pipeline-demo-stage.ts(CdkpipelinesDemoStage) that wraps the solution stack (AwsCdkPipelinePlaygroundStack) for CodePipeline Create pipeline stack lib/aws-cdk-demo-pipeline-stack.ts and add CdkpipelinesDemoStage stage to it  Steps npx cdk init --language=typescript CDK_VERSION=\u0026#34;1.97.0\u0026#34; # install pipeline deps npm install \\  @aws-cdk/aws-codepipeline@$CDK_VERSION \\  @aws-cdk/aws-codepipeline-actions@$CDK_VERSION \\  @aws-cdk/pipelines@$CDK_VERSION # leverages `@aws-solutions-constructs/aws-apigateway-lambda` # see https://docs.aws.amazon.com/solutions/latest/constructs/aws-apigateway-lambda.html # note CDK version must match `aws-solutions-constructs` version (e.g. $CDK_VERSION) npm i \\  @aws-cdk/aws-apigateway@$CDK_VERSION \\  @aws-cdk/aws-lambda@$CDK_VERSION \\  @aws-solutions-constructs/aws-apigateway-lambda@$CDK_VERSION # build locally npm run build # test npm run test # create *this* repo in github and do initial push to ensure it exists for # CodePipeline to find # provision pipeline # [optional] if not already ran. bootstrap for each target account+region combination cdk bootstrap aws://AWS_ACCOUNT_NUMBER/us-east-1 cdk bootstrap aws://AWS_ACCOUNT_NUMBER/us-west-1 # ensure `cdk-pipeline-01-github-token` exists in Secrets Manager # one-time operation, deploy the pipeline stack from local machine cdk deploy --force --require-approval never # add stage to pipeline. this is the api gateway -\u0026gt; lambda stack code lib/aws-cdk-demo-pipeline-stack.ts # edit # push changes and pipeline will run and deploy PreProd stage npm run build git commit -am \u0026#39;Add PreProd stage\u0026#39; git push # the pipeline automatically reconfigures itself to add the new stage and # deploy to it # modify solution and/or pipeline, commit, and iterate Notes Each pipeline stage is compiled into it\u0026rsquo;s own cloud assembly as follows:\n cdk.out/assembly-Dev cdk.out/assembly-CdkpipelinesDemoPipelineStack-PreProd cdk.out/assembly-CdkpipelinesDemoPipelineStack-Prod  You can deploy and individual stage (cfn stack) by itself. For example, for dev.\nnpm run build # If necessary, to recompile the Lambda sources cdk synth cdk -a cdk.out/assembly-Dev deploy --force --require-approval never # ensure dev account is bootstrapped first npx cdk bootstrap \\  --cloudformation-execution-policies arn:aws:iam::aws:policy/AdministratorAccess \\  aws://DEVELOPER_ACCOUNT/us-east-1   see cdk-deploy-to.sh for handy deployment script for different account+region combinations. Remember to bootstrap target account+region with cdk bootstrap aws://account/region had to downgrade npm 7 to 6 to get around types error when running npm run build on codebuild. see self mutating cdk pipeline fails after updating cdk version from 1.85.0 to 1.92.0 · Issue #13541 · aws/aws-cdk # steps npm install -g npm@6 rm package-lock.json npm i   Screenshots AWS Console | CodePipeline SNS Email Notifications CodePipeline State Change COMPLETED API Gateway 5XX Count Threshold Hit Lambda Error Count Threshold Hit Resources  CDK Pipelines: Continuous delivery for AWS CDK applications | Amazon Web Services cdkworkshop.com | CDK PIPELINES @aws-cdk/pipelines module · AWS CDK   original cdk generated README.md below\n Welcome to your CDK TypeScript project! This is a blank project for TypeScript development with CDK.\nThe cdk.json file tells the CDK Toolkit how to execute your app.\nUseful commands  npm run build compile typescript to js npm run watch watch for changes and compile npm run test perform the jest unit tests cdk deploy deploy this stack to your default AWS account/region cdk diff compare deployed stack with current state cdk synth emits the synthesized CloudFormation template  ","permalink":"https://brianpfeil.com/post/aws-cdk-pipeline/","postedOnDate":" April 15, 2021","tags":["aws","cdk","codepipeline","cicd"],"title":"AWS CDK Pipeline"},{"categories":[],"contents":" original RFC proposal date 2020-09-27\n Issue | ReactCDK: Add JSX/TSX Support PR | \u0026ldquo;RFC 256: ReactCDK - Add JSX/TSX Support\u0026rdquo; Rendered Proposal (feature: react-cdk-add-jsx-tsx-support)    Summary Support the expression of cloud infrastructure resources via React JSX / TSX. Cloud solutions are composed of many services. Being able to efficiently and naturally express the composition is a developer ergonomics/DX concern.\nREADME Create CDK applications using React.\nHello ReactCDK Example ReactCDK application\nconst { ReactCDK, App, Stack } = require(\u0026#39;@aws-cdk/react\u0026#39;) const Bucket = require(\u0026#39;@aws-cdk/react/s3\u0026#39;) const { CloudFrontDistribution, Origins, DefaultOrigin } = require(\u0026#39;@aws-cdk/react/cloudfront\u0026#39;) const { Api, Resource, Integration } = require(\u0026#39;@aws-cdk/react/apigateway\u0026#39;) const Lambda = require(\u0026#39;@aws-cdk/react/lambda\u0026#39;) const EchoLambda = ( \u0026lt;Lambda\u0026gt; { async ({event, context}) =\u0026gt; ({ \u0026#34;statusCode\u0026#34;: 200, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; } \u0026#34;body: JSON.stringify(event) }) } \u0026lt;/Lambda\u0026gt; ) const EchoApi = ( \u0026lt;Api\u0026gt; \u0026lt;Resource path=\u0026#34;*\u0026#34;\u0026gt; \u0026lt;Integration type=\u0026#34;lambda\u0026#34;\u0026gt; \u0026lt;EchoLambda /\u0026gt; \u0026lt;/Integration\u0026gt; \u0026lt;/Resource\u0026gt; \u0026lt;/Api\u0026gt; ) const WebsiteBucket = () =\u0026gt; ( \u0026lt;Bucket src=\u0026#34;./public\u0026#34; /\u0026gt; ) const MyCloudFrontDistribution = ( \u0026lt;CloudFrontDistribution\u0026gt; \u0026lt;Origins\u0026gt; \u0026lt;DefaultOrigin oai=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;WebsiteBucket /\u0026gt; \u0026lt;/DefaultOrigin\u0026gt; \u0026lt;Origin path=\u0026#34;/api/*\u0026#34;\u0026gt; \u0026lt;EchoApi /\u0026gt; \u0026lt;/Origin\u0026gt; \u0026lt;/Origins\u0026gt; \u0026lt;/CloudFrontDistribution\u0026gt; ) const MyApp = ( \u0026lt;App\u0026gt; \u0026lt;Stack\u0026gt; \u0026lt;MyCloudFrontDistribution /\u0026gt; \u0026lt;/Stack\u0026gt; \u0026lt;/App\u0026gt; ) ReactCDK.render(MyApp, {region: \u0026#39;us-east-1\u0026#39;}) Motivation Why are we doing this?\nDeveloper accessibility. Expanding and making the AWS platform accessible to a larger group of people.\n Library / framework support is a natural evolution on top of already supported CDK languages. React is familiar to a large group of frontend developers. It\u0026rsquo;s a generalized tech that allows developers to naturally express composition, which is the core tenet of serverless / serviceful solutions. This eases developers into more advanced AWS usage and therefore enabling them to get more value from the platform. Library/framework support on top of already supported language (ts) via jsii  What use cases does it support?\nThe large pool of existing React developers who have experience with React and it\u0026rsquo;s component based composition idioms. Allows them to reuse and leverage their existing knowledge to build full stack cloud solutions.\nWhat is the expected outcome?\nMore people leveraging CDK suite -\u0026gt; more innovation and solutions -\u0026gt; advance humanity.\nDesign Summary Code generate a set of ReactCDK components that has feature parity with all TS components from cfn constructs to solutions constructs.\nDetailed Design Codegen ReactCDK components A set of ReactCDK components that has feature parity with all TS components from cfn constructs to solutions constructs.\n mapping from react concepts of props, state, children, render props to typescript CDK constructors, params, hierarchical nesting (parent), etc. code generated based on the jsii manifests of CDK modules via @eladb custom react renderer / reconciler where cloud (cfn) is it\u0026rsquo;s render target getting there via CDK language layer. ReactCDKBaseComponent (class or functional component/hooks friendly) ReactCDKPatternComponent - pre-composed infra for common use cases. leverage React ecosystem adjacencies (e.g. react storybook, etc.) wrap these ReactCDK components for Amplify “Backend” library special cases of lambda function code being webpack + babel + etc being transpiled, bundled, etc. and handed over to CDK provisioning layer.  this is a bit more involved and also needs research. this is the blending of app code and infra resources it interacts with. This is somewhat similar to Meteor, but instead of only mongodb, it\u0026rsquo;s every cfn supported AWS service. Need to not make same mistakes as meteor.\n  step function special cases where the components that make it up are customized for developer ergonomics/dx. this is additional alternative to amplify add [backend] (e.g. api, auth, etc.)  Drawbacks  React is not universally liked. If it becomes associated with CDK there is potential brand/product damage. CDK is associated and tied to AWS brand. AWS tends to support all \u0026ldquo;popular\u0026rdquo; frameworks equally. Favoring one might not be good for brand. Might draw demand / more work for Vue.js, Angular, Svelete, etc. support Frontend libraries and frameworks come and go much more frequently than programming languages. React itself has gone through major \u0026ldquo;idiomatic\u0026rdquo; changes throughout it\u0026rsquo;s short lifetime. For example, classes, functional components, hooks. JSX has remained stable, but there could be \u0026ldquo;another\u0026rdquo; evolution step that makes JSX a moving target. A new layer and choice is introduced to the end user. Should I use a supported programming language or go up a layer and use a supported higher-level technology.  Rationale and Alternatives  leverage developers existing knowledge around technologies that easy the use of component oriented solutions. there are no technical negative impacts in not doing this. Purely additive. There is only the \u0026ldquo;potential\u0026rdquo; lost opportunity cost.  Adoption Strategy  Leverage existing Amplify brand platform/position with frontend developer community. This is an additive \u0026ldquo;personality\u0026rdquo; / choice for a target CDK user type. Does not impact existing code bases.  Unresolved questions  mapping from react concepts of props, state, children, render props to typescript CDK constructors, params, hierarchical nesting (parent), etc.  Future Possibilities There currently is a \u0026ldquo;locality of code\u0026rdquo; issue with CDK, SAM, CFN, etc. The infrastructure I define is not close to the application code that leverages it (e.g. lambda code living in separate file, referencing it via s3://.zip). Explicit IAM permissions (or what could be codegened) live only in infra code. Application code events expressed in code seamlessly leveraging EventBridge for example without the developer needing to do any additional work. Would be a step towards a \u0026ldquo;cloud native programming language\u0026rdquo; where the programming language control constructs naturally scale and map to corresponding services (e.g. control flow -\u0026gt; step fn, events -\u0026gt; EventBridge, lambdas (lang level) -\u0026gt; lambdas :))\nImplementation Plan Resources  original \u0026ldquo;concept\u0026rdquo; conversation on twitter Hello ReactCDK app concept gist Part 1/3 - Beginners guide to Custom React Renderers. How to build your own renderer from scratch?  ","permalink":"https://brianpfeil.com/post/reactcdk-rfc/","postedOnDate":" April 11, 2021","tags":["cdk","react","rfc"],"title":"ReactCDK RFC"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-well-architected-playground  deep dive on all things AWS Well-Architected\nKey Points  consistent pre-launch review process against AWS best practices helps you understand the pros and cons of decisions you make while building systems review process is a conversation and not an audit. working together to improve. practical advice. goal is not to have \u0026ldquo;perfect\u0026rdquo; architecture from the start. identify areas for improvement and choose a couple that delivery the most value AWS does not provide prescriptive guidance on how to perform the review. WA tool is the closest. concepts: Pillars -\u0026gt; Design Principles -\u0026gt; Questions enables: learn -\u0026gt; measure -\u0026gt; improve iterative cycle input: answer questions, output: improvement plan (PDF reports) learning / education - can be used as standalone tool solely for learning what the best practices are milestone - record the state of a workload for given point in time. e.g. original design, design review, v1, v2  Use Cases  learning best practices for the cloud technology governance portfolio management - inventory of workloads, historical decisions made, risks, highlights where to invest  Well-Architected Framework  The AWS Well-Architected Framework helps you to design and operate a reliable, secure, efficient, and cost-efficient systems on AWS. It also helps you constantly measure your architecture against best practices and provides you an opportunity to improve your architecture.\n 5 Pillars  Operational Excellence Security Reliability Performance Efficiency Cost Optimization  Review Process  The review process describes in high-level terms, how the assessment of the principles should be done. For AWS, this should be a lightweight process, which is taking rather hours, instead of days and it should be repeated multiple times across the architecture lifecycle. AWS states that it is important to have a conversation (not an audit) and a “blame-free approach” during the review and it is also important to involve the right people. The results of the conversations should be a list of issues that can then be prioritized based on the business context and that can be formulated into a set of actions that help to improve the overall customer experience of the architecture.\n Well-Architected Tool AWS Console Tool that steps a user through the Well-Architected Review Process\nWell-Architected Alternate Renditions Consuming the WA PDFs or web content can be a bit challenging with navigation. The WA questions, resources, etc. are available as json via the AWS WA Console Tool with some scraping. This creates alternate renditions based on this data.\n Run aws-well-architected-reformat/main.js to generate a reformatted and condensed version of WA. cd aws-well-architected-reformat node main.js \u0026gt; ../aws-well-architected-condensed.md  see alternate rendition at aws-well-architected-condensed.md See aws-well-architected-reformat/data for the question data as json for each lens.  Notes on pulling data via AWS Console\n# aws console request format POST https://console.aws.amazon.com/wellarchitected/api/apiservice {\u0026#34;method\u0026#34;:\u0026#34;GET\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/workloads/4cfa14fe4a9d351afc9975cfdcb434af/lensReviews/wellarchitected/answers\u0026#34;,\u0026#34;region\u0026#34;:\u0026#34;us-east-1\u0026#34;,\u0026#34;headers\u0026#34;:{\u0026#34;Content-Type\u0026#34;:\u0026#34;application/json\u0026#34;,\u0026#34;Accept\u0026#34;:\u0026#34;application/json\u0026#34;},\u0026#34;params\u0026#34;:{\u0026#34;PillarId\u0026#34;:\u0026#34;operationalExcellence\u0026#34;,\u0026#34;MaxResults\u0026#34;:50,\u0026#34;Locale\u0026#34;:\u0026#34;en\u0026#34;}} # helpful Resources on right sidebar example https://wa.aws.amazon.com/TypeII/en/foundationaltechnicalreview/foundationaltechnicalreview.sec_q1.helpful-resources.en.html Feature Request One area where there is a gap for an enterprises are all the company specific policies, standards, and best practices that are additive and need to be addressed on top of AWS. These types of questions and guidance would need to happen outside of WA Tool.\nA feature to define custom lenses - a customer defined lens. This way the single WA Tool could be the method for review facilitation, improvement reporting and maintaining history.\nKey Visuals Resources  AWS Well-Architected Documentation | AWS Well-Architected Framework The Review Process - AWS Well-Architected Framework AWS Well Architected framework: A Complete Checklist AWS Well-Architected Framework Cheatsheet | Cloud Noon  ","permalink":"https://brianpfeil.com/post/aws-well-architected/","postedOnDate":" April 9, 2021","tags":["aws","aws-well-architected","architecture"],"title":"AWS Well-Architected"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/api-gateway-private-endpoints-playground  learn API Gateway private endpoints\nSetup Steps configure API Gateway private endpoint that leverages HTTP proxy integration. Test via lambda with VPC config that issues HTTP GET request to vpc endpoint.\nNotes\n supported on REST API endpoints (not HTTP API at the time 2021-04-05) be sure to re-deploy API for policy changes check security groups check VPC endpoint policy check lambda VPC config and security groups   API Gateway resource policy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;execute-api:Invoke\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:execute-api:us-east-1:529276214230:scheqe4ymi/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotEquals\u0026#34;: { \u0026#34;aws:sourceVpce\u0026#34;: \u0026#34;vpce-02b487f2d021986fb\u0026#34; } } }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;execute-api:Invoke\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:execute-api:us-east-1:529276214230:scheqe4ymi/*\u0026#34; } ] }  note the Deny + Allow combination*\n  Lambda test code\nconst https = require(\u0026#39;https\u0026#39;); exports.handler = (event, context, callback) =\u0026gt; { // https://scheqe4ymi.execute-api.us-east-1.amazonaws.com/prod  var options = { host: \u0026#39;vpce-02b487f2d021986fb-yl0hav78.execute-api.us-east-1.vpce.amazonaws.com\u0026#39;, path: \u0026#39;/prod/index.html\u0026#39;, method: \u0026#39;GET\u0026#39;, port: 443, headers: { \u0026#39;Host\u0026#39;:\u0026#39;scheqe4ymi.execute-api.us-east-1.amazonaws.com\u0026#39; } }; const cb = function(response) { let str = \u0026#39;\u0026#39;; response.on(\u0026#39;data\u0026#39;, function (chunk) { str += chunk; }); response.on(\u0026#39;end\u0026#39;, function () { console.log(str); const response = { statusCode: 200, body: JSON.stringify(str), }; callback(null, response) return response; }); } https.request(options, cb).end(); }  note the Host header that allows for the request to be routed\n Screenshots Resources  Introducing Amazon API Gateway Private Endpoints | Amazon Web Services How do I troubleshoot issues connecting to an API Gateway private API endpoint?  ","permalink":"https://brianpfeil.com/post/api-gateway-private-endpoints/","postedOnDate":" April 6, 2021","tags":["aws","api-gateway","vpc","network"],"title":"API Gateway Private Endpoints"},{"categories":["HTML","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/cfn-diagram-playground  learn cfn-diagram\n CLI tool to visualise CloudFormation/SAM/CDK templates as diagrams.\n Usage # install npm i -g @mhlabs/cfn-diagram # draw.io render cfn-dia draw.io --template-file CloudFrontS3WebsiteCdkStack.template.yaml \\  --output-file CloudFrontS3WebsiteCdkStack.drawio # html render cfn-dia html --template-file CloudFrontS3WebsiteCdkStack.template.yaml \\  --output-path CloudFrontS3WebsiteCdkStack-html Screenshots Notes  good starting point. generate draw.io to get all resources and icons, then modify from there. allows for filtering by resource types to eliminate resources that may not be needed. works by importing cfn template into CDK. CDK allows to treat as graph for traversal and inspection  Resources  mhlabs/cfn-diagram How (and Why) You Need To Start Generating Your Serverless Infrastructure Diagrams | Ready, Set, Cloud!  ","permalink":"https://brianpfeil.com/post/cfn-diagram/","postedOnDate":" April 5, 2021","tags":["cloudformation","diagram","tools"],"title":"CFN Diagram"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/api-gateway-service-integrations-for-http-apis-playground  Example API Gateway service integration with EventBridge with SAM\nAPI Gateway -\u0026gt; EventBridge -\u0026gt; CloudWatch Log Group\nRunning cd eventbridge # deploy sam deploy --guided # run following to given eventbridge rule permissions to write to log group # can not create resource-based policy for Log Group via cfn # see https://stackoverflow.com/questions/49242010/how-to-define-resource-policy-for-cloudwatch-logs-with-cloudformation aws logs put-resource-policy \\  --region us-east-1 \\  --policy-name eventbridge-rule-to-logs \\  --policy-document \u0026#39;{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;:[ \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34; : \u0026#34;arn:aws:logs:*:*:log-group:*\u0026#34; } ] }\u0026#39; # send event to api gateway endpoint curl --header \u0026#34;Content-Type: application/json\u0026#34; \\  --request POST \\  --data \u0026#39;{\u0026#34;detail\u0026#34;:\u0026#34;{\\\u0026#34;action\\\u0026#34;: \\\u0026#34;withdrawal\\\u0026#34;, \\\u0026#34;amount\\\u0026#34;: 100}\u0026#34;}\u0026#39; \\  https://8djn9e18ej.execute-api.us-east-1.amazonaws.com # response: {\u0026#34;Entries\u0026#34;:[{\u0026#34;EventId\u0026#34;:\u0026#34;11555ee7-774f-e922-1022-46401bbe5f9b\u0026#34;}],\u0026#34;FailedEntryCount\u0026#34;:0} # view event in log group aws logs tail \u0026#34;apigateway-http-api-service-integration/EventBus\u0026#34; # response # 2021-04-02T23:47:46+00:00 ca4b84fb-60f2-302d-b6ce-90338469d249 {\u0026#34;version\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;id\u0026#34;:\u0026#34;11555ee7-774f-e922-1022-46401bbe5f9b\u0026#34;,\u0026#34;detail-type\u0026#34;:\u0026#34;MyDetailType\u0026#34;,\u0026#34;source\u0026#34;:\u0026#34;demo\u0026#34;,\u0026#34;account\u0026#34;:\u0026#34;529276214230\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2021-04-02T23:47:46Z\u0026#34;,\u0026#34;region\u0026#34;:\u0026#34;us-east-1\u0026#34;,\u0026#34;resources\u0026#34;:[],\u0026#34;detail\u0026#34;:{\u0026#34;action\u0026#34;:\u0026#34;withdrawal\u0026#34;,\u0026#34;amount\u0026#34;:100}} # cleanup STACK_NAME=\u0026#34;apig-svc-int-eb-cwl-01\u0026#34; aws cloudformation delete-stack --stack-name $STACK_NAME aws cloudformation wait stack-delete-complete --stack-name $STACK_NAME Screenshots Resources  Working with AWS service integrations for HTTP APIs - Amazon API Gateway  ","permalink":"https://brianpfeil.com/post/api-gateway-service-integrations-for-http-apis/","postedOnDate":" April 2, 2021","tags":["aws","api-gateway","eventbridge","cloudwatch","integration"],"title":"API Gateway Service Integrations for HTTP APIs"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-ses-playground  learn Simple Email Service (Amazon SES)\n Notes  send or receive emails verify domain (DNS txt) and/or email addresses (confirmation email) - verify that you own the email address or domain that you plan to send from understand Service quotas max message size - 10 MB per message (after base64 encoding). sending identity - domain or an email address send emails via SMTP or API (AWS CLI, AWS SDK) connect to a URL that provides an endpoint for the Amazon SES API or SMTP interface (e.g. email-smtp.us-east-1.amazonaws.com:587) DKIM support - DKIM works by adding a digital signature to the headers of an email message. This signature can then be validated against a public cryptographic key that is located in the organization\u0026rsquo;s DNS record SPF support - SPF establishes a method for receiving mail servers to verify that incoming email from a domain was sent from a host authorized by that domain’s administrators. TXT record \u0026quot;v=spf1 include:amazonses.com ~all\u0026quot; IAM to control user access to email sending (e.g. ses:SendEmail) Configuration sets - groups of rules that you can apply to the emails you send using Amazon SES. can publish email sending events to CWL, Firehose, SNS Event types - Send, Reject, Delivery, Bounce, Complaint, Click Open Rendering Failure store inbound emails in S3 trigger lambdas based on inbound emails publish your email sending events to CWLs or kinesis firehose Sending personalized email via email templates. templates contain placeholder values. based on Handlebars template system list management  customers can manage their own mailing lists, known as contact lists. can create topics, associate topic preferences to a contact and specify OPT_[IN|OUT] for the topic.   Global Suppression List  includes a global suppression list. When any Amazon SES customer sends an email that results in a hard bounce, Amazon SES adds the email address that produced the bounce to a global suppression list. The global suppression list is global in the sense that it applies to all Amazon SES customers. In other words, if a different customer attempts to send an email to an address that\u0026rsquo;s on the global suppression list, Amazon SES accepts the message, but doesn\u0026rsquo;t send it, because the email address is suppressed. enabled by default for all Amazon SES accounts. You can\u0026rsquo;t disable it.   reputation dashboard to track bounce and complaint rates Dedicated IP Addresses IP pool management – If you lease dedicated IP addresses to use with Amazon SES, you can create groups of these addresses, called dedicated IP pools. You can then associate these dedicated IP pools with configuration sets SES sandbox - all new accounts.  only send mail to verified email addresses and domains only send mail from verified email addresses and domains send a maximum of 200 messages per 24-hour period send a maximum of 1 message per second   need to request production access to move out of sandbox VPC endpoint support - see New – Amazon Simple Email Service (SES) for VPC Endpoints   Send Email Using API create destination.json and message.json files\n# send email # NOTE: cli security principal must have `ses:SendEmail` permission aws ses send-email \\  --from \u0026#39;brian.pfeil@allthecloudbits.com\u0026#39; \\  --destination file://destination.json \\  --message file://message.json # output/response # { # \u0026#34;MessageId\u0026#34;: \u0026#34;010001788372bd22-b3d9950b-8310-43bf-bef3-256917951097-000000\u0026#34; # }  Using SMTP interface Create SMTP Credentials Creates IAM user arn:aws:iam::529276214230:user/ses-smtp-user.20210330-092121 with following policy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ses:SendRawEmail\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Send Email using SMTP # Testing your connection to the Amazon SES SMTP interface openssl s_client -crlf -quiet -starttls smtp -connect email-smtp.us-east-1.amazonaws.com:587 # base64 encode creds SMTP_USERNAME=$(echo -n \u0026#34;SMTPUsername\u0026#34; | openssl enc -base64) SMTP_PASSWORD=$(echo -n \u0026#34;SMTPPassword\u0026#34; | openssl enc -base64) # create SMTP email # see `smtp-email-example.txt` # send email openssl s_client -crlf -quiet -starttls smtp -connect email-smtp.us-east-1.amazonaws.com:587 \u0026lt; smtp-email-example.txt  Resources  Documentation | Amazon Simple Email Service  ","permalink":"https://brianpfeil.com/post/aws-ses/","postedOnDate":" March 30, 2021","tags":["aws","ses","email"],"title":"AWS SES"},{"categories":["HTML","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-copilot-playground  learn AWS Copilot CLI\nWorkload Types  load balanced web service backend service - isolated to private VPC that is accessible to frontend web app (load balanced web service) scheduled job  Concepts  Application - a group of related services, environments, and pipelines Environments - environment can have its own version of a service running allowing you to create a \u0026ldquo;test\u0026rdquo; and \u0026ldquo;production\u0026rdquo; environment Service - your code and all of the supporting infrastructure needed to get it up and running on AWS Jobs - ephemeral ECS tasks that are triggered by an event. uses CloudWatch\u0026rsquo;s rate expressions. Scheduled Jobs are composed of an AmazonECS Task Definition, Task Role, Task Execution Role, a Step Function State Machine for retrying on failures, and finally an Event Rule to trigger the state machine. Pipelines - release pipeline that deploys your service whenever you push to your git repository. (At this time, Copilot supports GitHub, Bitbucket, and CodeCommit repositories.) When a push is detected, your pipeline will build your service, push the image to ECR, and deploy to your environments.  Notes  copilot cli automatically creates thw following stacks  aws-copilot-playground-infrastructure-roles stack  StackSet-aws-copilot-playground-infrastructure-777bf4f7-f4a1-469e-bbff-5113f346b47e    similar dev workflow to Elastic Beanstalk (eb), Cloud Foundry (cf), heroku.  Files and Directories  copilot/ - copilot working directory copilot/aws-copilot-playground-nginx/manifest.yml - manifest file generated by copilot  Running # copilot does not allow use of root account. # copilot will use `AWS_PROFILE` setting export AWS_PROFILE=admin copilot init copilot deploy copilot app show copilot svc ls # create new service (web, backend, scheduled) copilot svc init copilot svc show copilot svc logs # delete all resources / stack(s) copilot app delete Resources  AWS Copilot CLI - AWS Copilot CLI ECSworkshop.com  ","permalink":"https://brianpfeil.com/post/aws-copilot/","postedOnDate":" March 21, 2021","tags":["aws","ecs","copilot"],"title":"AWS Copilot"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/amazon-managed-workflows-for-apache-airflow-playground  learn Amazon Managed Workflows for Apache Airflow\nInstall Steps  create S3 bucket with versioning enabled create VPC - this is where RDS Postgres for airflow data lives, the airflow web UI runs in a container here create aiflow environment  Notes  you create named MWAA environments and they each have own configuration airflow ui exposed publically or private within VPC login to airflow ui with IAM user can create web login token via AWS CLI upload DAG .py files to dag path in S3 run DAGs via airflow cli, REST endpoint, boto3 invoke DAG via lambda install additional deps by providing requirements.txt auto scales up and down via Apache Celery Executor by adding / removing worker containers as needed scale via number of workers, and environment class  Airflow Plugins\n Hooks: Hooks are basically python modules that enables tasks to access external platform, like AWS, AZURE, GCP and many more. Sensors: Sensors are python modules which are used to create watcher tasks(in the most basic sense), for example s3Sensor is used to create s3 file watcher task. A sensor stays in running state till a specific state appears. Operators: Operators are typically execution engines. Operators are used to create task that execute some process, based on the type of Operator. For example: PythonOperator can be used create a task that will run a specific python method.  XCom\n share small bits of data between tasks stored in airflow postgres db  Example Environment Attributes { \u0026#34;Environment\u0026#34;: { \u0026#34;AirflowConfigurationOptions\u0026#34;: {}, \u0026#34;AirflowVersion\u0026#34;: \u0026#34;1.10.12\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:airflow:eu-west-1:xxxxxxxxxxxx:environment/airflow-blogpost-dublin\u0026#34;, \u0026#34;CreatedAt\u0026#34;: 1610632127.0, \u0026#34;DagS3Path\u0026#34;: \u0026#34;dags\u0026#34;, \u0026#34;EnvironmentClass\u0026#34;: \u0026#34;mw1.medium\u0026#34;, \u0026#34;ExecutionRoleArn\u0026#34;: \u0026#34;arn:aws:iam:: xxxxxxxxxxxx:role/airflow-demo-mwaa-eks-iamrole\u0026#34;, \u0026#34;LastUpdate\u0026#34;: { \u0026#34;CreatedAt\u0026#34;: 1611137820.0, \u0026#34;Status\u0026#34;: \u0026#34;SUCCESS\u0026#34; }, \u0026#34;LoggingConfiguration\u0026#34;: { \u0026#34;DagProcessingLogs\u0026#34;: { \u0026#34;CloudWatchLogGroupArn\u0026#34;: \u0026#34;arn:aws:logs:: xxxxxxxxxxxx:log-group:airflow-ricsue-dublin-DAGProcessing\u0026#34;, \u0026#34;Enabled\u0026#34;: true, \u0026#34;LogLevel\u0026#34;: \u0026#34;INFO\u0026#34; }, \u0026#34;SchedulerLogs\u0026#34;: { \u0026#34;CloudWatchLogGroupArn\u0026#34;: \u0026#34;arn:aws:logs:: xxxxxxxxxxxx:log-group:airflow-ricsue-dublin-Scheduler\u0026#34;, \u0026#34;Enabled\u0026#34;: true, \u0026#34;LogLevel\u0026#34;: \u0026#34;INFO\u0026#34; }, \u0026#34;TaskLogs\u0026#34;: { \u0026#34;CloudWatchLogGroupArn\u0026#34;: \u0026#34;arn:aws:logs:: xxxxxxxxxxxx:log-group:airflow-ricsue-dublin-Task\u0026#34;, \u0026#34;Enabled\u0026#34;: true, \u0026#34;LogLevel\u0026#34;: \u0026#34;INFO\u0026#34; }, \u0026#34;WebserverLogs\u0026#34;: { \u0026#34;CloudWatchLogGroupArn\u0026#34;: \u0026#34;arn:aws:logs:: xxxxxxxxxxxx:log-group:airflow-ricsue-dublin-WebServer\u0026#34;, \u0026#34;Enabled\u0026#34;: true, \u0026#34;LogLevel\u0026#34;: \u0026#34;INFO\u0026#34; }, \u0026#34;WorkerLogs\u0026#34;: { \u0026#34;CloudWatchLogGroupArn\u0026#34;: \u0026#34;arn:aws:logs:: xxxxxxxxxxxx:log-group:airflow-ricsue-dublin-Worker\u0026#34;, \u0026#34;Enabled\u0026#34;: true, \u0026#34;LogLevel\u0026#34;: \u0026#34;INFO\u0026#34; } }, \u0026#34;MaxWorkers\u0026#34;: 5, \u0026#34;Name\u0026#34;: \u0026#34;ricsue-dublin\u0026#34;, \u0026#34;NetworkConfiguration\u0026#34;: { \u0026#34;SecurityGroupIds\u0026#34;: [ \u0026#34;sg-0c88ef4755c295zzz\u0026#34; ], \u0026#34;SubnetIds\u0026#34;: [ \u0026#34;subnet-0493dffd0282f4xxx\u0026#34;, \u0026#34;subnet-08f416023356ffyyy\u0026#34; ] }, \u0026#34;RequirementsS3Path\u0026#34;: \u0026#34;requirements/requirements.txt\u0026#34;, \u0026#34;ServiceRoleArn\u0026#34;: \u0026#34;arn:aws:iam:: xxxxxxxxxxxx:role/aws-service-role/airflow.amazonaws.com/AWSServiceRoleForAmazonMWAA\u0026#34;, \u0026#34;SourceBucketArn\u0026#34;: \u0026#34;arn:aws:s3:::airflow-mybucket\u0026#34;, \u0026#34;Status\u0026#34;: \u0026#34;AVAILABLE\u0026#34;, \u0026#34;Tags\u0026#34;: {}, \u0026#34;WebserverAccessMode\u0026#34;: \u0026#34;PUBLIC_ONLY\u0026#34;, \u0026#34;WebserverUrl\u0026#34;: \u0026#34;aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee.c5.eu-west-1.airflow.amazonaws.com\u0026#34;, \u0026#34;WeeklyMaintenanceWindowStart\u0026#34;: \u0026#34;SUN:14:00\u0026#34; } } Resources  Amazon Managed Workflows for Apache Airflow Interacting with Amazon Managed Workflows for Apache Airflow via the command line AWS CLI Command Reference | mwaa Airflow — Custom Plugins Airflow XCOM : The Ultimate Guide  ","permalink":"https://brianpfeil.com/post/amazon-managed-workflows-for-apache-airflow/","postedOnDate":" March 13, 2021","tags":[],"title":"Amazon Managed Workflows for Apache Airflow"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-glue-pyspark-fetch-databases-and-tables-metadata-playground  example AWS Glue pyspark job script that fetches all the catalog databases and tables metadata.\nsee main.py\n first method uses spark sql second method uses python boto3 Glue client to interact with Glue API directly  Notes ensure --enable-glue-datacatalog is enabled for glue job to allow spark sql to access metadata catalog\nGlue Console Script View\n","permalink":"https://brianpfeil.com/post/aws-glue-pyspark-fetch-databases-and-tables-metadata/","postedOnDate":" February 19, 2021","tags":["aws","glue","spark","python"],"title":"AWS Glue Pyspark Fetch Databases and Tables Metadata"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-durable-functions-playground  learn Azure Durable Functions\nRunning LOCATION=eastus BASE_NAME=durable-fns-playground-01 RESOURCE_GROUP=\u0026#34;${BASE_NAME}\u0026#34; STORAGE_ACCOUNT=$(echo $BASE_NAME | sed -e \u0026#39;s/-//g\u0026#39;) FUNCTION_APP=$(echo $BASE_NAME | sed -e \u0026#39;s/-//g\u0026#39;) # create resource group az group create \\  --name \u0026#34;${RESOURCE_GROUP}\u0026#34; \\  --location \u0026#34;${LOCATION}\u0026#34; # create storage account az storage account create \\  --name \u0026#34;${STORAGE_ACCOUNT}\u0026#34; \\  --location \u0026#34;${LOCATION}\u0026#34; \\  --resource-group \u0026#34;${RESOURCE_GROUP}\u0026#34; \\  --sku \u0026#34;Standard_LRS\u0026#34; # create function app in azure az functionapp create \\  --resource-group \u0026#34;${RESOURCE_GROUP}\u0026#34; \\  --consumption-plan-location \u0026#34;${LOCATION}\u0026#34; \\  --runtime \u0026#34;node\u0026#34; \\  --runtime-version 12 \\  --functions-version 3 \\  --name \u0026#34;${FUNCTION_APP}\u0026#34; \\  --storage-account \u0026#34;${STORAGE_ACCOUNT}\u0026#34; # create functions # DurableFunctionsHTTPstarter is HTTP endpoint that invokes DurableFunctionsOrchestrator # which then calls DurableFunctionsActivity multiple time with different parameters func new -t \u0026#34;Durable Functions HTTP starter\u0026#34; -l javascript -n DurableFunctionsHTTPstarter func new -t \u0026#34;Durable Functions orchestrator\u0026#34; -l javascript -n DurableFunctionsOrchestrator func new -t \u0026#34;Durable Functions activity\u0026#34; -l javascript -n DurableFunctionsActivity # deploy func azure functionapp publish \u0026#34;${FUNCTION_APP}\u0026#34; # get function all base URL FUNCTION_APP_URL=\u0026#34;https://$(az functionapp show -g ${RESOURCE_GROUP} -n ${FUNCTION_APP} --query defaultHostName -o tsv)/api\u0026#34; # pull down app settings for running locally func azure functionapp fetch-app-settings \u0026#34;${FUNCTION_APP}\u0026#34; # run locally func start # trigger durable function curl \u0026#39;http://localhost:7071/api/orchestrators/DurableFunctionsOrchestrator\u0026#39; # async execution - output # # { # \u0026#34;id\u0026#34;: \u0026#34;20f2ddc1e34543379efc49a09962dfc5\u0026#34;, # \u0026#34;statusQueryGetUri\u0026#34;: \u0026#34;http://localhost:7071/runtime/webhooks/durabletask/instances/20f2ddc1e34543379efc49a09962dfc5?taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34;, # \u0026#34;sendEventPostUri\u0026#34;: \u0026#34;http://localhost:7071/runtime/webhooks/durabletask/instances/20f2ddc1e34543379efc49a09962dfc5/raiseEvent/{eventName}?taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34;, # \u0026#34;terminatePostUri\u0026#34;: \u0026#34;http://localhost:7071/runtime/webhooks/durabletask/instances/20f2ddc1e34543379efc49a09962dfc5/terminate?reason={text}\u0026amp;taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34;, # \u0026#34;rewindPostUri\u0026#34;: \u0026#34;http://localhost:7071/runtime/webhooks/durabletask/instances/20f2ddc1e34543379efc49a09962dfc5/rewind?reason={text}\u0026amp;taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34;, # \u0026#34;purgeHistoryDeleteUri\u0026#34;: \u0026#34;http://localhost:7071/runtime/webhooks/durabletask/instances/20f2ddc1e34543379efc49a09962dfc5?taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34; # } # fetch `statusQueryGetUri` curl \u0026#39;http://localhost:7071/runtime/webhooks/durabletask/instances/20f2ddc1e34543379efc49a09962dfc5?taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#39; # { # \u0026#34;name\u0026#34;: \u0026#34;DurableFunctionsOrchestrator\u0026#34;, # \u0026#34;instanceId\u0026#34;: \u0026#34;20f2ddc1e34543379efc49a09962dfc5\u0026#34;, # \u0026#34;runtimeStatus\u0026#34;: \u0026#34;Completed\u0026#34;, # \u0026#34;input\u0026#34;: null, # \u0026#34;customStatus\u0026#34;: null, # \u0026#34;output\u0026#34;: [ # \u0026#34;Hello Tokyo!\u0026#34;, # \u0026#34;Hello Seattle!\u0026#34;, # \u0026#34;Hello London!\u0026#34; # ], # \u0026#34;createdTime\u0026#34;: \u0026#34;2021-02-04T21:33:29Z\u0026#34;, # \u0026#34;lastUpdatedTime\u0026#34;: \u0026#34;2021-02-04T21:33:30Z\u0026#34; # } # --- # start in own terminal # Show interactive streaming logs for an Azure-hosted Function App func azure functionapp logstream \u0026#34;${FUNCTION_APP}\u0026#34; # trigger durable function curl \u0026#34;${FUNCTION_APP_URL}/orchestrators/DurableFunctionsOrchestrator?code=CODE\u0026#34; # async execution - output # # { # \u0026#34;id\u0026#34;: \u0026#34;7501819801f942ebaed9289e87420cbd\u0026#34;, # \u0026#34;statusQueryGetUri\u0026#34;: \u0026#34;https://durablefnsplayground01.azurewebsites.net/runtime/webhooks/durabletask/instances/7501819801f942ebaed9289e87420cbd?taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34;, # \u0026#34;sendEventPostUri\u0026#34;: \u0026#34;https://durablefnsplayground01.azurewebsites.net/runtime/webhooks/durabletask/instances/7501819801f942ebaed9289e87420cbd/raiseEvent/{eventName}?taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34;, # \u0026#34;terminatePostUri\u0026#34;: \u0026#34;https://durablefnsplayground01.azurewebsites.net/runtime/webhooks/durabletask/instances/7501819801f942ebaed9289e87420cbd/terminate?reason={text}\u0026amp;taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34;, # \u0026#34;rewindPostUri\u0026#34;: \u0026#34;https://durablefnsplayground01.azurewebsites.net/runtime/webhooks/durabletask/instances/7501819801f942ebaed9289e87420cbd/rewind?reason={text}\u0026amp;taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34;, # \u0026#34;purgeHistoryDeleteUri\u0026#34;: \u0026#34;https://durablefnsplayground01.azurewebsites.net/runtime/webhooks/durabletask/instances/7501819801f942ebaed9289e87420cbd?taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34; # } # fetch `statusQueryGetUri` curl \u0026#34;https://durablefnsplayground01.azurewebsites.net/runtime/webhooks/durabletask/instances/7501819801f942ebaed9289e87420cbd?taskHub=DurableFunctionsHub\u0026amp;connection=Storage\u0026amp;code=CODE\u0026#34; # { # \u0026#34;name\u0026#34;: \u0026#34;DurableFunctionsOrchestrator\u0026#34;, # \u0026#34;instanceId\u0026#34;: \u0026#34;7501819801f942ebaed9289e87420cbd\u0026#34;, # \u0026#34;runtimeStatus\u0026#34;: \u0026#34;Completed\u0026#34;, # \u0026#34;input\u0026#34;: null, # \u0026#34;customStatus\u0026#34;: null, # \u0026#34;output\u0026#34;: [ # \u0026#34;Hello Tokyo!\u0026#34;, # \u0026#34;Hello Seattle!\u0026#34;, # \u0026#34;Hello London!\u0026#34; # ], # \u0026#34;createdTime\u0026#34;: \u0026#34;2021-02-04T20:55:25Z\u0026#34;, # \u0026#34;lastUpdatedTime\u0026#34;: \u0026#34;2021-02-04T20:55:26Z\u0026#34; # } # query function logs read -r -d \u0026#39;\u0026#39; QUERY \u0026lt;\u0026lt; EOM traces | project timestamp, message | where timestamp \u0026gt; ago(24h) | limit 10 EOM az monitor app-insights query \\  --app \u0026#39;cd03d419-0bba-410e-ac3f-d7e934c027f1\u0026#39; \\  --analytics-query \u0026#34;${QUERY}\u0026#34; # output # # { # \u0026#34;tables\u0026#34;: [ # { # \u0026#34;columns\u0026#34;: [ # { # \u0026#34;name\u0026#34;: \u0026#34;timestamp\u0026#34;, # \u0026#34;type\u0026#34;: \u0026#34;datetime\u0026#34; # }, # { # \u0026#34;name\u0026#34;: \u0026#34;message\u0026#34;, # \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; # } # ], # \u0026#34;name\u0026#34;: \u0026#34;PrimaryResult\u0026#34;, # \u0026#34;rows\u0026#34;: [ # [ # \u0026#34;2021-02-04T20:56:04.3256227Z\u0026#34;, # \u0026#34;Host Status: {\\r\\n \\\u0026#34;id\\\u0026#34;: \\\u0026#34;durablefnsplayground01\\\u0026#34;,\\r\\n \\\u0026#34;state\\\u0026#34;: \\\u0026#34;Running\\\u0026#34;,\\r\\n \\\u0026#34;version\\\u0026#34;: \\\u0026#34;3.0.15193.0\\\u0026#34;,\\r\\n \\\u0026#34;versionDetails\\\u0026#34;: \\\u0026#34;3.0.15193 Commit hash: 75da1ebed23b08b39c8c3c20b3ea687813c0acdf\\\u0026#34;,\\r\\n \\\u0026#34;platformVersion\\\u0026#34;: \\\u0026#34;91.0.7.116\\\u0026#34;,\\r\\n \\\u0026#34;instanceId\\\u0026#34;: \\\u0026#34;00d386aeb51a3d5098651c58f61ffb53a9b1a656ea9e9b0dd570b9834cdc3d4f\\\u0026#34;,\\r\\n \\\u0026#34;computerName\\\u0026#34;: \\\u0026#34;DW0-HR0-3-17\\\u0026#34;,\\r\\n \\\u0026#34;processUptime\\\u0026#34;: 145740,\\r\\n \\\u0026#34;extensionBundle\\\u0026#34;: {\\r\\n \\\u0026#34;id\\\u0026#34;: \\\u0026#34;Microsoft.Azure.Functions.ExtensionBundle\\\u0026#34;,\\r\\n \\\u0026#34;version\\\u0026#34;: \\\u0026#34;1.5.0\\\u0026#34;\\r\\n }\\r\\n}\u0026#34; # ], # [ # \u0026#34;2021-02-04T20:56:05.4099623Z\u0026#34;, # \u0026#34;Host Status: {\\r\\n \\\u0026#34;id\\\u0026#34;: \\\u0026#34;durablefnsplayground01\\\u0026#34;,\\r\\n \\\u0026#34;state\\\u0026#34;: \\\u0026#34;Running\\\u0026#34;,\\r\\n \\\u0026#34;version\\\u0026#34;: \\\u0026#34;3.0.15193.0\\\u0026#34;,\\r\\n \\\u0026#34;versionDetails\\\u0026#34;: \\\u0026#34;3.0.15193 Commit hash: 75da1ebed23b08b39c8c3c20b3ea687813c0acdf\\\u0026#34;,\\r\\n \\\u0026#34;platformVersion\\\u0026#34;: \\\u0026#34;91.0.7.116\\\u0026#34;,\\r\\n \\\u0026#34;instanceId\\\u0026#34;: \\\u0026#34;00d386aeb51a3d5098651c58f61ffb53a9b1a656ea9e9b0dd570b9834cdc3d4f\\\u0026#34;,\\r\\n \\\u0026#34;computerName\\\u0026#34;: \\\u0026#34;DW0-HR0-3-17\\\u0026#34;,\\r\\n \\\u0026#34;processUptime\\\u0026#34;: 146826,\\r\\n \\\u0026#34;extensionBundle\\\u0026#34;: {\\r\\n \\\u0026#34;id\\\u0026#34;: \\\u0026#34;Microsoft.Azure.Functions.ExtensionBundle\\\u0026#34;,\\r\\n \\\u0026#34;version\\\u0026#34;: \\\u0026#34;1.5.0\\\u0026#34;\\r\\n }\\r\\n}\u0026#34; # ], # ... Resources  Azure Durable Functions documentation  ","permalink":"https://brianpfeil.com/post/azure-durable-functions/","postedOnDate":" February 5, 2021","tags":["azure"],"title":"Azure Durable Functions"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-arm-playground  RESOURCE_GROUP_NAME=\u0026#34;armplayground01\u0026#34; # create resource group az group create --name \u0026#34;${RESOURCE_GROUP_NAME}\u0026#34; --location eastus # deploy arm outputs example az deployment group create \\  --name \u0026#34;my-deployment-01\u0026#34; --resource-group \u0026#34;${RESOURCE_GROUP_NAME}\u0026#34; \\  --template-file \u0026#34;templates/outputs.azuredeploy.json\u0026#34; \\  --parameters @templates/outputs.parameters.json ","permalink":"https://brianpfeil.com/post/azure-arm/","postedOnDate":" January 29, 2021","tags":["azure"],"title":"Azure ARM"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-functions-playground  learn azure functions.\nFollowing is based on Create a JavaScript function from the command line - Azure Functions\n# create nodejs function project func init LocalFunctionProj --javascript cd LocalFunctionProj # create new function trigger via http request func new --name HttpExample --template \u0026#34;HTTP trigger\u0026#34; --authlevel \u0026#34;anonymous\u0026#34; # start locally func start # make request against local endpoint curl http://localhost:7071/api/HttpExample?name=Brian # create resource group az group create --name \u0026#34;AzureFunctionsQuickstart-rg\u0026#34; --location \u0026#34;eastus\u0026#34; # create storage account az storage account create --name \u0026#34;brianpfeilmystorage01\u0026#34; --location \u0026#34;eastus\u0026#34; --resource-group \u0026#34;AzureFunctionsQuickstart-rg\u0026#34; --sku \u0026#34;Standard_LRS\u0026#34; # create function app in azure az functionapp create --resource-group \u0026#34;AzureFunctionsQuickstart-rg\u0026#34; --consumption-plan-location \u0026#34;eastus\u0026#34; --runtime \u0026#34;node\u0026#34; --runtime-version 12 --functions-version 3 --name \u0026#34;brianpfeilmyfn01\u0026#34; --storage-account \u0026#34;brianpfeilmystorage01\u0026#34; # deploy func azure functionapp publish \u0026#34;brianpfeilmyfn01\u0026#34; # invoke function on azure curl \u0026#34;https://brianpfeilmyfn01.azurewebsites.net/api/httpexample?name=Brianv2\u0026#34; # view near real-time streaming logs func azure functionapp logstream \u0026#34;brianpfeilmyfn01\u0026#34; # fetch the app settings. this populates them in `local.settings.json` # credentials for the storage account are stored in the `AzureWebJobsStorage` property # this is needed to store message in storage queue func azure functionapp fetch-app-settings \u0026#34;brianpfeilmyfn01\u0026#34; # Show settings for a function app. (autogenerated) az functionapp config appsettings list --name \u0026#34;brianpfeilmyfn01\u0026#34; --resource-group \u0026#34;AzureFunctionsQuickstart-rg\u0026#34; # Update a function app\u0026#39;s settings. (autogenerated) az functionapp config appsettings set --name \u0026#34;brianpfeilmyfn01\u0026#34; --resource-group \u0026#34;AzureFunctionsQuickstart-rg\u0026#34; --settings \u0026#34;AzureWebJobsStorage=$storageConnectionString\u0026#34; # list available function templates for javascript func templates list -l javascript # create new function using \u0026#34;Durable Functions HTTP starter\u0026#34; template func new -t \u0026#34;Durable Functions HTTP starter\u0026#34; -l javascript -n DurableFunctionsHTTPstarter Screenshots message(s) in the azure storage queue\nManaged Identity for Function in Azure Console\nNotes  app settings can be access via environment variables. See Configure function app settings in Azure Functions Use Key Vault references to store secrets stored in Key Vault. They are automatically fetched and provided as environment variables to your function.  see Secure App Settings variables in Azure Functions e.g. App Settings Value KeyVault Reference @Microsoft.KeyVault(SecretUri=https://pfeilkeyvault01.vault.azure.net/secrets/secret01/e0fca4271fb243178a0a861d8e6fbc59)   Functions have in/out bindings defined in function.json To access other azure resources/services from a function, you configure a managed identity on the function app and provide access to Azure resources for that identity using Azure role-based access control. See Azure Services that support managed identities - Azure AD.  system-assigned managed identity - identity tied to and managed by a specific service. when that service instance is deleted, the identity is deleted with it. user-assigned managed identity - not owned by a specific service. lifecycle is fully managed by you. can be assigned to multiple services.   Azure Durable Functions documentation - lets you write stateful functions in a serverless compute environment. Similar to AWS Step Functions, but implemented as language level library. shared access signature (SAS) URLs for granting limited access. Similar to S3 signed URLs. See Grant limited access to data with shared access signatures (SAS) - Azure Storage  A shared access signature is a signed URI that points to one or more storage resources. The URI includes a token that contains a special set of query parameters. The token indicates how the resources may be accessed by the client. One of the query parameters, the signature, is constructed from the SAS parameters and signed with the key that was used to create the SAS. This signature is used by Azure Storage to authorize access to the storage resource.\n   Resources  Triggers and bindings in Azure Functions Create a JavaScript function from the command line - Azure Functions Azure Functions scale and hosting - covers limits and constraints Using Managed Identity between Azure Functions and Azure Storage - Code Samples How to use managed identities for App Service and Azure Functions Configure function app settings in Azure Functions Secure App Settings variables in Azure Functions Source Application Settings from Key Vault  ","permalink":"https://brianpfeil.com/post/azure-functions/","postedOnDate":" January 25, 2021","tags":["azure","azure-functions","serverless"],"title":"Azure Functions"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/sam-lambda-layers-playground  learn SAM lambda layers\nRunning Example cd lambda-layer-python sam build # run lambda with layer locally # `--force-image-build` to clear out layer cache sam local invoke --force-image-build # start local api endpoint sam local start-api --force-image-build curl http://127.0.0.1:3000/ # deploy sam deploy --guided # run lambda behind api gateway endpoint curl https://hl6u5bubr4.execute-api.us-east-1.amazonaws.com/Prod/ Resources  Working with AWS Lambda and Lambda Layers in AWS SAM  ","permalink":"https://brianpfeil.com/post/sam-lambda-layers/","postedOnDate":" January 8, 2021","tags":["sam","lambda","aws"],"title":"SAM Lambda Layers"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/click-cli-playground  learn Click\n a python package for creating beautiful command line interfaces in a composable way with as little code as necessary\n see main.py\nRunning pipenv install pipenv shell python main.py Resources  Click  ","permalink":"https://brianpfeil.com/post/click-cli/","postedOnDate":" January 7, 2021","tags":["cli"],"title":"Click CLI"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-data-wrangler-playground  learn AWS Data Wrangler\n python initiative that extends the power of Pandas library to AWS connecting DataFrames and AWS data related services (Amazon Redshift, AWS Glue, Amazon Athena, Amazon Timestream, Amazon EMR, Amazon QuickSight, etc).\n Running Examples # install venv and deps pipenv install # activate venv pipenv shell # run examples python main.py See https://github.com/awslabs/aws-data-wrangler/tree/master/tutorials for example usages.\nLambda Layer Can be used via a lambda layer.\nResources  https://aws-data-wrangler.readthedocs.io/ awslabs/aws-data-wrangler AWS Data Wrangler| API Reference https://github.com/awslabs/aws-data-wrangler/tree/master/tutorials - notebooks with examples  ","permalink":"https://brianpfeil.com/post/aws-data-wrangler/","postedOnDate":" January 6, 2021","tags":["aws","data","python"],"title":"AWS Data Wrangler"},{"categories":[],"contents":" Definition(s) Key Questions Organization Considerations Quality Attributes Patterns  event-sourcing  Resources   Hexagonal  Resources     Topics / Concepts / Terms  Database Shuffle Sharding Constant Work Canary   Resources  Books (oreilly.com) Websites Decks Videos      let business value guide all architecture decisions evolutionary architectures are needed to support rapid rate of business and technology change  Definition(s)  “Architecture is about the important stuff. Whatever that is” the decisions you wish you could get right early in a project the shared understanding that the expert developers have of the system design how the components are assembled and organized. This will be done in a way that meets the quality attributes. significant design decisions that shape a system, where significant is measured by cost of change - Grady Booch  Key Questions  who are the users what devices and form factors will be used what is the context of their usage scale and growth who are the main actors in the system (domain objects - e.g. orders, products, etc.) data classifications (pii) data types and sizes (relation records, documents, media files, etc.) what is the time frame for delivery is there an existing product / SaaS / open-source / etc. that provides the solution or a portion / components of it Capacity estimation \u0026amp; Constraints Functional Requirements Non Functional Requirements - Latency, Consistency, Availability, High Throughput, etc. Out of scope organization and teams structure   see https://medium.com/partha-pratim-sanyal/system-design-doordash-a-prepared-food-delivery-service-bf44093388e2 for good reference\n Organization Considerations  engineering (application \u0026amp; platform) operations (application \u0026amp; platform)  Quality Attributes  reliability - ability to continue to operate under predefined conditions availability - ratio of the available system time to the total working time scalability - ability of the system to handle load increases without decreasing performance efficiency performance security cost interoperability correctness maintainability readability extensibility testability   Patterns event-sourcing  Capture all changes to an application state as a sequence of events.\n Core Design Decisions\n Domain Entities and Events  popular method is via Event Storming   Event Content  each event stores delta state each event stores full state  idempotent is easy to solve for duplicate events     Total Ordering (ordered stream of events - ledger)  ensure all event are processed in order. this is needed for causal relationships. e.g. ordering matters for two messages related to the same entity    Resources  Scaling Event Sourcing for Netflix Downloads, Episode 1 Scaling Event Sourcing for Netflix Downloads, Episode 2 InfoQ | Scaling Event Sourcing for Netflix Downloads | Video + Presentation - shows in detail how they implemented event sourcing backed by cassandra matrinfowler.com | Event Sourcing Pattern: Event sourcing EventBridge Storming — How to build state-of-the-art Event-Driven Serverless Architectures - approach to defining the Events, Boundaries and Entities in your business domain Decomposing the Monolith with Event Storming   Hexagonal Allow an application to equally be driven by users, programs, automated test or batch scripts, and to be developed and tested in isolation from its eventual run-time devices and databases.\nResources  Hexagonal Architecture: three principles and an implementation example Hexagonal architecture   Topics / Concepts / Terms Database   CAP theorem\n Consistency: Every read receives the most recent write or an error Availability: Every request receives a (non-error) response, without the guarantee that it contains the most recent write Partition tolerance: The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes    Serializability\n  Snapshot isolation\n  Multiversion concurrency control\n  Things I Wished More Developers Knew About Databases\n   Shuffle Sharding limits / isolates tenants in a multi-tenant system so they don\u0026rsquo;t negatively impact other tenants. method of assigning tenant to resources.\nResources\n Workload isolation using shuffle-sharding AWS Well-Architected Labs | Fault isolation with shuffle sharding  Constant Work overprovision resources to the point where it would operate correctly even if an availability zone were to be unavailable\nIf AZ becomes unavailable, no new resources need to be provisioned, just a quick re-routing. you are essentially always operating the infrastructure for failure mode (active-active)\nResources\n Static stability using Availability Zones Reliability, constant work, and a good cup of coffee   Canary  A canary release is a technique to reduce the risk from deploying a new version of software into production. A new version of software, referred to as the canary, is deployed to a small subset of users alongside the stable running version. Traffic is split between these two versions such that a portion of incoming requests are diverted to the canary. This approach can quickly uncover any problems with the new version without impacting the majority of users.\n Resources\n Automated Canary Analysis at Netflix with Kayenta   Resources Books (oreilly.com)  The Software Architect Elevator Fundamentals of Software Architecture Clean Architecture: A Craftsman\u0026rsquo;s Guide to Software Structure and Design, First Edition Software Architecture Patterns Building Evolutionary Architectures Clean Architecture: A Craftsman\u0026rsquo;s Guide to Software Structure and Design, First Edition Domain-Driven Design: Tackling Complexity in the Heart of Software Microservices Patterns Patterns of Enterprise Application Architecture Refactoring: Improving the Design of Existing Code Design Patterns: Elements of Reusable Object-Oriented Software Designing Distributed Systems Designing Distributed Control Systems: A Pattern Language Approach (Wiley Software Patterns Series) Distributed Tracing in Practice Making Sense of Stream Processing I Heart Logs Streaming Systems  Organization Architecture\n Accelerate: Building and Scaling High Performing Technology Organizations The Phoenix Project  Websites  The System Design Primer - great real life architecture and design examples martinfowler.com  martinfowler.com | Software Architecture Guide   AWS Architecture Center AWS Architecture Blog Amazon Builders' Library Azure Architecture Center medium | software architecture C4 model for visualizing software architecture  Decks  Scalability, Availability \u0026amp; Stability Patterns  Videos  The elephant in the architecture - Martin Fowler  ","permalink":"https://brianpfeil.com/post/architecture-notes-and-resources/","postedOnDate":" December 11, 2020","tags":["architecture"],"title":"Architecture Notes and Resources"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/python-playground  learn and experiment with python, it\u0026rsquo;s libraries, and packages\nadd test_*.py file to tests/unit directory with code to test, learn, experiment with language, library, package, etc.\n# clone and cd into this repo # activate venv pipenv shell # install deps (e.g. nodemon) npm install # run tests npm run test # run tests and watch for changes to re-run npm run test:watch ","permalink":"https://brianpfeil.com/post/python/","postedOnDate":" November 20, 2020","tags":["python"],"title":"Python"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/serverless-flask-playground  Example of running python Flask app on Lambda + API Gateway via serverless framework. Based on Build a Python REST API with Serverless, Lambda, and DynamoDB.\nArchitecture Prerequisites  serverless framework Docker Desktop Python 3.8 pipenv  Running # ensure python venv loaded in shell pipenv shell # install npm deps for serverless npm install # run flash app locally. server reloads on file change. still need to refresh page in browser npm run dev # deploy. (docker must be running to build python packages for linux target / lambda) npm run deploy Resources  The Official Guide to Serverless Flask Build a Python REST API with Serverless, Lambda, and DynamoDB  ","permalink":"https://brianpfeil.com/post/serverless-flask/","postedOnDate":" November 13, 2020","tags":["serverless","flask","aws","python","lambda","api-gateway"],"title":"Serverless Flask"},{"categories":["Shell","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/dynamodb-export-to-s3-and-query-with-athena-playground  example exporting dynamodb table to S3 and then querying via athena\nFiles  template.yaml main.sh example-export/ - example contents of export (copied from S3)  Running sam deploy --guided # note: seed data is generated as part of deploy via cfn custom resource `Custom::SeedData` # which triggers a lambda which populates the dynamodb table # update `STACK_NAME` variable in ./main.sh # run export table to s3 script ./main.sh aws dynamodb list-exports # in progress { \u0026#34;ExportSummaries\u0026#34;: [ { \u0026#34;ExportArn\u0026#34;: \u0026#34;arn:aws:dynamodb:us-east-1:529276214230:table/dynamodb-export-to-s3-and-query-with-athena-playground-v2-MyTable-1WGSJ3W2WJWPK/export/01605130432834-8a918b87\u0026#34;, \u0026#34;ExportStatus\u0026#34;: \u0026#34;IN_PROGRESS\u0026#34; } ] } aws dynamodb list-exports # completed { \u0026#34;ExportSummaries\u0026#34;: [ { \u0026#34;ExportArn\u0026#34;: \u0026#34;arn:aws:dynamodb:us-east-1:529276214230:table/dynamodb-export-to-s3-and-query-with-athena-playground-v2-MyTable-1WGSJ3W2WJWPK/export/01605130432834-8a918b87\u0026#34;, \u0026#34;ExportStatus\u0026#34;: \u0026#34;COMPLETED\u0026#34; } ] } Example export file contents (line delimited json items)\ngzcat example-export/demo_prefix/AWSDynamoDB/01605130432834-8a918b87/data/vajn3deidy4svdja3fgej2ynay.json.gz\n{\u0026#34;Item\u0026#34;:{\u0026#34;pk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;pk001-1605121017583\u0026#34;},\u0026#34;sk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;sk001\u0026#34;}}} {\u0026#34;Item\u0026#34;:{\u0026#34;pk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;pk002-1605121017583\u0026#34;},\u0026#34;sk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;sk002\u0026#34;}}} Access Exported Data in S3 via Athena\n-- Create external table in athena pointing to exported S3 data CREATEEXTERNALTABLEIFNOTEXISTSddb_exported_table(Itemstruct\u0026lt;pk:struct\u0026lt;S:string\u0026gt;,sk:struct\u0026lt;S:string\u0026gt;\u0026gt;)ROWFORMATSERDE\u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39;LOCATION\u0026#39;s3://dynamodb-export-to-s3-and-query-with-exportbucket-103kukqwmab7n/demo_prefix/AWSDynamoDB/01605130432834-8a918b87/data/\u0026#39;TBLPROPERTIES(\u0026#39;has_encrypted_data\u0026#39;=\u0026#39;true\u0026#39;);-- issues SELECT query SELECTItem.pk.Saspk,Item.sk.SasskFROMddb_exported_tableScreenshot from Athena Console\nResources  New – Export Amazon DynamoDB Table Data to Your Data Lake in Amazon S3, No Code Writing Required Now you can export your Amazon DynamoDB table data to your data lake in Amazon S3 to perform analytics at any scale Exporting DynamoDB table data to Amazon S3 AWS CloudFormation custom resource creation with Python, AWS Lambda, and crhelper  ","permalink":"https://brianpfeil.com/post/dynamodb-export-to-s3-and-query-with-athena/","postedOnDate":" November 11, 2020","tags":["dynamodb","s3","aws","athena"],"title":"DynamoDB Export to S3 and Query with Athena"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-database-migration-service-playground  Concepts AWS DMS connects to the source data store, reads the source data, and formats the data for consumption by the target data store. It then loads the data into the target data store\nAt a high level, when using AWS DMS you do the following:\n Create a replication server. Create source and target endpoints that have connection information about your data stores. Create one or more migration tasks to migrate data between the source and target data stores.  A task can consist of three major phases:\n  The full load of existing data\n  The application of cached changes (change data capture, CDC)\n  Ongoing replication\n  Pricing - Pay for ec2 replication instances and log storage\n   Resources  AWS Database Migration Service AWS Schema Conversion Tool  ","permalink":"https://brianpfeil.com/post/aws-database-migration-service/","postedOnDate":" November 1, 2020","tags":["aws"],"title":"AWS Database Migration Service"},{"categories":["Shell","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-cloudwatch-logs-insights-playground  learn CloudWatch Logs Insights\nRunning Example Query via AWS CLI see main.sh\n# run script containing query ./main.sh # OR # re-run on change make dev Example Queries fields @timestamp, detail.eventSource, detail.eventName, @message | sort @timestamp desc | limit 100 fields @timestamp, detail.eventSource, detail.eventName, @message | filter detail.eventSource = \u0026#34;logs.amazonaws.com\u0026#34; | sort @timestamp desc | limit 100 fields @timestamp, detail.requestParameters.bucketName, detail.eventSource, detail.eventName, @message | filter detail.eventSource like /s3.amazonaws.com/ | sort @timestamp desc | limit 100 # sts assume role CloudTrail events fields @timestamp, source, `detail.eventName`, detail.requestParameters.roleArn, detail.userIdentity.userName, @message | filter detail.eventSource = \u0026#39;sts.amazonaws.com\u0026#39; | sort @timestamp desc # CodePipeline pipeline and stage change events fields @timestamp, `detail-type`, detail.pipeline, detail.stage, detail.state, @message | filter source = \u0026#39;aws.codepipeline\u0026#39; | sort @timestamp desc Resources  CloudWatch Logs Insights Query Syntax Sample Queries - Amazon CloudWatch Logs  ","permalink":"https://brianpfeil.com/post/aws-cloudwatch-logs-insights/","postedOnDate":" October 30, 2020","tags":["aws","cloudwatch"],"title":"AWS CloudWatch Logs Insights"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/dynamic-nodejs-code-execution-playground  example(s) of dynamically executing nodejs code. see index.js\nRunning node index.js ","permalink":"https://brianpfeil.com/post/dynamic-nodejs-code-execution/","postedOnDate":" October 28, 2020","tags":["nodejs"],"title":"Dynamic Nodejs Code Execution"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-kendra-playground  learn Amazon Kendra, intelligent search service powered by machine learning\nConcepts   Index - two types. document (unstructured) and FAQ (structured)\n You can add documents directly to an index using the BatchPutDocument operation You can add questions and answers (FAQs) directly to your index using the console or the CreateFaq operation    Data Source - s3, salesforce documents, sharepoint, custom\n  Documents - html, ppt, doc, pdf, txt\n custom fields - can define custom fields of types: Date, Number, String, String List    Queries - natural language (NLP), keyword queries, Factoid questions — Simple who, what, when, or where questions.\n Facets are scoped views of a set of search results By default, Query returns all search results. To filter responses, you can perform logical operations on the document attributes.    Tags - can assign tags to indexes, data sources, and FAQs\n  default encryption at rest with customer of AWS KMS keys\n  General Steps  create index add data sources for index synchronize the data source query/search the index  Editions  Developer Enterprise  You specify Edition: DEVELOPER_EDITION | ENTERPRISE_EDITION when you create an index\n Creating Example Index see main.py\nsam deploy --guided # copy outputs into `.env` python main.py Resources  Amazon Kendra Docs Getting started (AWS SDK for Python (Boto3)) - Amazon Kendra - shows create index, create data source for index, sync data source, all while waiting for each step to complete in between Deploying Amazon Kendra - pre-built react frontend for kendra. provides \u0026lt;search /\u0026gt; react component  https://kendrasamples.s3.amazonaws.com/kendrasamples.zip   aws-samples/enterprise-search-with-amazon-kendra-workshop Kendra | Using a custom data source  ","permalink":"https://brianpfeil.com/post/aws-kendra/","postedOnDate":" October 27, 2020","tags":["aws","kendra","search","machine-learning"],"title":"AWS Kendra"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-javascript-sdk-v3-playground  learn AWS JavaScript SDK v3\n index.js index.test.js   New Features v3 Commands  commands for each AWS Service package to enable you to perform operations for that AWS Service. After you install an AWS Service, you can browse the available commands in your project\u0026rsquo;s node-modules/@aws-sdk/client-PACKAGE_NAME/commands folder\n middleware stack  can use a new middleware stack to control the lifecycle of an operation call\n  Each middleware stage in the stack calls the next middleware stage after making any changes to the request object. This also makes debugging issues in the stack much easier, because you can see exactly which middleware stages were called leading up to the error.\n Use Cases\n debugging logging request updates instrumentation  Example middleware args\nDynamoDB ListTablesCommand\n{ middlewareStack: { add: [Function: add], addRelativeTo: [Function: addRelativeTo], clone: [Function: clone], use: [Function: use], remove: [Function: remove], removeByTag: [Function: removeByTag], concat: [Function: concat], applyToStack: [Function: cloneTo], resolve: [Function: resolve] }, input: {}, request: HttpRequest { method: \u0026#39;POST\u0026#39;, hostname: \u0026#39;dynamodb.us-east-1.amazonaws.com\u0026#39;, port: undefined, query: {}, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/x-amz-json-1.0\u0026#39;, \u0026#39;X-Amz-Target\u0026#39;: \u0026#39;DynamoDB_20120810.ListTables\u0026#39;, \u0026#39;user-agent\u0026#39;: \u0026#39;aws-sdk-nodejs-v3-@aws-sdk/client-dynamodb/1.0.0-rc.2 darwin/v12.16.1\u0026#39;, \u0026#39;content-length\u0026#39;: \u0026#39;2\u0026#39; }, body: \u0026#39;{}\u0026#39;, protocol: \u0026#39;https:\u0026#39;, path: \u0026#39;/\u0026#39; } }  Running # run tests that exercise new features npm run test -- --watch Resources  aws/aws-sdk-js-v3 AWS SDK for JavaScript | Developer Guide for SDK Version 3 Modular AWS SDK for JavaScript – Release Candidate  ","permalink":"https://brianpfeil.com/post/aws-javascript-sdk-v3/","postedOnDate":" October 26, 2020","tags":["aws","sdk","javascript"],"title":"AWS JavaScript SDK V3"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-transfer-family-playground  learn AWS Transfer Family, file transfer to Amazon S3 using SFTP, FTPS, and FTP\nResources  aws-samples/transfer-for-sftp-logical-directories - complete cfn provisioning example. sftp server, custom IdP via API Gateway, generates sample data, logical directory to s3 path mappings, etc. AWS Transfer Family User Guide AWS Transfer Family resource type reference - AWS CloudFormation Working with custom identity providers github advanced search \u0026lsquo;\u0026ldquo;AWS::Transfer::Server\u0026rdquo; language:YAML\u0026rsquo; - find cfn examples in github Jerry Hargrove - Cloud Diagrams \u0026amp; Notes | AWS Transfer Family Jerry Hargrove - Cloud Diagrams \u0026amp; Notes | AWS Transfer for SFTP  ","permalink":"https://brianpfeil.com/post/aws-transfer-family/","postedOnDate":" October 23, 2020","tags":["aws","aws-transfer-family","sftp","ftps","ftp"],"title":"AWS Transfer Family"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-appconfig-playground  learn AWS AppConfig\n create, manage, and quickly deploy application configurations. AWS AppConfig supports controlled deployments to applications of any size and includes built-in validation checks and monitoring. You can use AWS AppConfig with applications hosted on EC2 instances, AWS Lambda, containers, mobile applications, or IoT devices.\n Concepts Domain\n Application (myapp) Environment (dev, test, demo, prod) Configuration Profile - versioned configuration data. text, json, yaml, S3 object, SSM Document, SSM Parameter, CodePipeline Deployment - types: AllAtOnce, Linear50PercentEvery30Seconds, Canary10Percent20Minutes  Functional\n deploy configuration changes from a central location rules to validate your configuration. configurations that aren\u0026rsquo;t valid can\u0026rsquo;t be deployed.  validation types: JSON schema, Lambda. see About validators     Example(s) get configuration via cli\naws appconfig get-configuration \\  --application \u0026#39;app01\u0026#39; \\  --environment \u0026#39;dev\u0026#39; \\  --configuration \u0026#39;config-profile-01\u0026#39; \\  --client-id \u0026#39;test\u0026#39; \\  appconfig.json # view results in specified output file `appconfig.json` cat appconfig.json output\n AWS Console Screenshots Configuration profile source types\nExample JSON configuration profile\nDeployment Strategy Types\nStart Deployment\nDeployment\nResources  AWS AppConfig Documentation Deploying application configuration to serverless: introducing the AWS AppConfig Lambda extension - blog post on how to use AppConfig Lambda extension AWS AppConfig integration with Lambda extensions - sessions-with-aws-sam/appconfig-lambda-extensions/README.md - good complete reference implementation on how to effectively use with lambda sthulb/appconfig-demo  ","permalink":"https://brianpfeil.com/post/aws-appconfig/","postedOnDate":" October 20, 2020","tags":["aws","appconfig","configuration","deployment","lambda"],"title":"AWS AppConfig"},{"categories":["Shell","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/bash-shell-script-playground  learn and experiment with bash shell scripts\nDevelopment Workflow main.sh\n# re-run on changes to main.sh. run in own shell / blocks make dev # edit main.sh ","permalink":"https://brianpfeil.com/post/bash-shell-script/","postedOnDate":" October 13, 2020","tags":["bash","shell"],"title":"Bash Shell Script"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/powershell-playground  # connects to Azure with an authenticated account for use with cmdlets from the # Az PowerShell modules Connect-AzAccount Get-AzADUser -ObjectId \u0026#34;user@example.com\u0026#34;| fl Resources  Installing PowerShell on macOS Azure PowerShell documentation Yes you can! Use PowerShell in MacOS to connect to Microsoft Azure Microsoft Graph PowerShell Preview - Now on PowerShell Gallery  Scratch ","permalink":"https://brianpfeil.com/post/powershell/","postedOnDate":" October 12, 2020","tags":["powershell"],"title":"PowerShell"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-cloud9-playground   learn AWS Cloud9 setup remote development environment  Enabling SSH Connectivity  add SSH inbound rule to Security Group  add ~/.ssh/id_rsa.pub to /home/ec2-user/.ssh/authorized_keys. do this via Cloud9 IDE shell  ssh -i ~/.ssh/id_rsa ubuntu@dev01.brianpfeil.com  Troubleshooting  may need to connect via Cloud9 IDE to \u0026ldquo;wake up\u0026rdquo;/start instance due to \u0026ldquo;auto stop\u0026rdquo; of EC2 instance after X minutes. May need to remote remote host in ~/.ssh/known_hosts on client if the following error @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the ECDSA key sent by the remote host is SHA256:\u0026lt;deleted\u0026gt; Please contact your system administrator. Add correct host key in ~/.ssh/known_hosts to get rid of this message. Offending ECDSA key in ~/.ssh/known_hosts:37 ECDSA host key for dev01.brianpfeil.com has changed and you have requested strict checking. Host key verification failed.   VS Code Remote Development on Cloud9  perform \u0026ldquo;Enabling SSH Connectivity\u0026rdquo; steps see vscode | Remote development over SSH  vscode remotely SSH connected screenshot\nResources  VS Code Remote Development vscode | Remote development over SSH  ","permalink":"https://brianpfeil.com/post/aws-cloud9/","postedOnDate":" October 5, 2020","tags":["aws","cloud9"],"title":"AWS Cloud9"},{"categories":["Jupyter Notebook","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/boto3-playground  learn boto3, the Amazon Web Services (AWS) SDK for Python\nConcepts Clients provide a low-level interface to AWS whose methods map close to 1:1 with service APIs. All service operations are supported by clients. Clients are generated from a JSON service definition file.\nResources represent an object-oriented interface to Amazon Web Services (AWS). They provide a higher-level abstraction than the raw, low-level calls made by service clients. To use resources, you invoke the resource() method of a Session and pass in a service name:\nSession manages state about a particular configuration. By default, a session is created for you when needed. However, it\u0026rsquo;s possible and recommended that in some scenarios you maintain your own session. Sessions typically store the following:\n Credentials AWS Region Other configurations related to your profile  Collection provides an iterable interface to a group of resources. A collection seamlessly handles pagination for you, making it possible to easily iterate over all items from all pages of data.\nPaginators\nSome AWS operations return results that are incomplete and require subsequent requests in order to attain the entire result set. The process of sending subsequent requests to continue where a previous request left off is called pagination. Paginators are a feature of boto3 that act as an abstraction over the process of iterating over an entire result set of a truncated API operation.\n Developing # install virtual env and dependencies pipenv install # (optional) install additional pip package pipenv install \u0026lt;package\u0026gt; # activate python virtual env (optional) pipenv shell # run on change make dev # --- running via jupyter notebook --- # in vscode # click on `main.ipynb`. this will automatically start jupyter notebook and connect # ctrl+enter to run cell # ctrl+space for intellisense # see [How to use Pipenv with Jupyter and VSCode](https://towardsdatascience.com/how-to-use-pipenv-with-jupyter-and-vscode-ae0e970df486) # manually run jupyter notebook pipenv run jupyter notebook # access via browser manually (auto opens via above command) open http://localhost:8888/tree # convert notebook to python. generates `main_notebook.py` jupyter nbconvert --to script main.ipynb --output main_notebook Notes for vscode, install Pylance - Visual Studio Marketplace extension\nResources  Boto3 documentation boto/boto3 boto3-stubs - for code completion Working with Jupyter Notebooks in Visual Studio Code How to use Pipenv with Jupyter and VSCode Big Upgrades are coming to VSCode Jupyter Notebooks  ","permalink":"https://brianpfeil.com/post/boto3/","postedOnDate":" October 5, 2020","tags":["boto","python"],"title":"Boto3"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-systems-manager-automation-playground  learn AWS Systems Manager Automation\nSSM Automation document\n contains one or more steps that run in sequential order can specify parameters Each step is built around a single action Output from one step can be used as input in a later step json or yaml documents can run python or powershell scripts via aws:executeScript (max execution time is 10 min) invoke aws:invokeLambdaFunction can specify execution role via AutomationAssumeRole parameter. if not specified, uses the security context of calling principal can trigger based on EventBridge rule can reference parameters in Parameter Store within an SSM doc via {{ssm:parameter-name}} ssm document types (yaml or json)  automation (renamed to runbooks) - command - remotely and securely manage the configuration of your managed instances (ec2 or on-prem)   aws:executeScript stdout/stderr can be sent to CloudWatch logs. see https://docs.aws.amazon.com/systems-manager/latest/userguide/automation-action-logging.html   Examples # create an ssm document aws ssm create-document \\  --content file://path/to/file/documentContent.json \\  --name \u0026#34;document-name\u0026#34; \\  --document-type \u0026#34;Command\u0026#34; \\  --tags \u0026#34;Key=tag-key,Value=tag-value\u0026#34; # run an ssm document (max execution time is 10 min) aws ssm start-automation-execution \\ --document-name \u0026#34;AWS-UpdateLinuxAmi\u0026#34; \\ --parameters \u0026#34;AutomationAssumeRole=arn:aws:iam::123456789012:role/SSMAutomationRole,SourceAmiId=ami-EXAMPLE,IamInstanceProfileName=EC2InstanceRole\u0026#34; # run `command` type document (runs on EC2 instances) aws ssm send-command \\  --instance-ids \u0026#34;instance-ID\u0026#34; \\  --document-name \u0026#34;AWS-RunShellScript\u0026#34; \\  --comment \u0026#34;IP config\u0026#34; \\  --parameters commands=ifconfig \\  --output text  Resources  AWS Systems Manager Automation AWS Systems Manager documents - describes the various document types (e.g. command, automation, etc.) Custom Automation document samples AWS Management and Governance Tools Workshop | AWS SYSTEMS MANAGER awslabs/aws-systems-manager - examples Use the power of script steps in your Systems Manager Automation runbooks | Amazon Web Services Automation actions reference - actions that you can specify in an AWS Systems Manager Automation document  aws:executeScript – Run a script - runtimes: python3.6 | python3.7 | PowerShell Core 6.0, as of 2020-10-02 max duration of 10 min (600 secs) aws:executeAwsApi – Call and run AWS API actions   Walkthrough: Using Automation with Jenkins ceshihao/ssm-public-documents - example ssm automation documents How To Create AWS SSM Automation Workflow | CloudAffaire - goo walkthrough how to create automation doc and run via aws cli  ","permalink":"https://brianpfeil.com/post/aws-systems-manager-automation/","postedOnDate":" October 2, 2020","tags":["aws"],"title":"AWS Systems Manager Automation"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/github-cli-playground  learn GitHub CLI\nResources  GitHub CLI GitHub CLI | Manual  ","permalink":"https://brianpfeil.com/post/github-cli/","postedOnDate":" October 2, 2020","tags":["cli","git","github"],"title":"GitHub CLI"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/diagrams-as-code-playground  learn Diagrams(Diagram as Code), lets you draw the cloud system architecture in Python code\nDiagram Authoring Workflow pipenv install # install deps pipenv shell # correct python env make dev # re-runs on file changes / live reload # split vscode window. put .py on left and *.png in right # edit and save .py Screenshots ","permalink":"https://brianpfeil.com/post/diagrams-as-code/","postedOnDate":" October 1, 2020","tags":["diagrams","visualize","architecture"],"title":"Diagrams As Code"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/s3-access-points-playground  learn S3 Access Points\n Be sure to review Access points restrictions and limitations before considering for a use case.\n Feature Overview  Access points are unique hostnames enforce distinct permissions and network controls for any request made through the access point. Customers with shared data sets scale access for hundreds of applications by creating individualized access points with names and permissions customized for each application. access point can be restricted to a VPC to firewall S3 data access within customers’ private networks AWS Service Control Policies can be used to ensure all access points are VPC restricted. no longer have to manage a single, complex bucket policy with hundreds of different permission rules that need to be written, read, tracked, and audited. With S3 Access Points, you can now create application-specific access points permitting access to shared data sets with policies tailored to the specific application.  Example Policy limit access to partner-01 role\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllObjectActions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::529276214230:role/partner-01\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:*Object\u0026#34;, \u0026#34;Resource\u0026#34;: [\u0026#34;arn:aws:s3:us-east-1:529276214230:accesspoint/partner-01-read-write/object/*\u0026#34;] } ] } Access Point Hostname\nhttps://partner-01-read-write-529276214230.s3-accesspoint.us-east-1.amazonaws.com\nExample Usage # get `a.c` using `partner-01` role aws --profile partner-01 s3api get-object --key a.c --bucket \u0026#39;arn:aws:s3:us-east-1:529276214230:accesspoint/partner-01-read-write\u0026#39; - Resources  S3 | Access Points Easily Manage Shared Data Sets with Amazon S3 Access Points Access points restrictions and limitations Amazon S3 Access Points - Tutorials Dojo  Screenshots get via access point example\naccess point details\naccess point policy\npartner-01 role (requires S3 read permissions)\nScratch cd ~/tmp aws s3 cp a.c s3://s3-access-points-playground/ # verify assume role works aws --profile partner-01 sts get-caller-identity aws --profile partner-01 s3api get-object --key a.c --bucket \u0026#39;arn:aws:s3:us-east-1:529276214230:accesspoint/partner-01-read-write\u0026#39; - aws --profile partner-01 sts get-caller-identity ","permalink":"https://brianpfeil.com/post/s3-access-points/","postedOnDate":" October 1, 2020","tags":["s3","aws"],"title":"S3 Access Points"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/mdx-deck-playground  learn jxnblk/mdx-deck\n examples/example01/deck.mdx examples/example01/package.json:scripts  build/serve static site, export to PDF    Export to PDF # run in own shell. blocks npm start # run in different shell npm run pdf Resources  mdx-deck | Theming mdx-deck | Exporting  ","permalink":"https://brianpfeil.com/post/mdx-deck/","postedOnDate":" September 28, 2020","tags":["react","markdown","presentation"],"title":"MDX Deck"},{"categories":[],"contents":"Feedback on serverless usage on AWS. Based on working with and observations of the teams that leverage the set of AWS \u0026ldquo;serverless\u0026rdquo; services. Feedback format is Challenge and Suggestion for a given topic, concept, service, or feature.\nTable of Contents  Serverless at AWS: General  Challenge: Skill Set / Developer Accessibility Suggestion: Skill Set / Developer Accessibility Challenge: Developer Experience (DX) Suggestion: Developer Experience (DX) Challenge: Cost Forecasting Suggestion: Cost Forecasting Challenge: Non-AWS Core Enterprise Tools Suggestion: Non-AWS Core Enterprise Tools   IAM  Challenge: Skill Set / Developer Accessibility Suggestion: Skill Set / Developer Accessibility   CloudFormation  Challenge: Deployment Time Suggestion: Deployment Time   Lambda  Challenge: Lambda or Container Decision Suggestion: FaaS or Container Decision Challenge: Cost vs. Performance Tuning Suggestion: Cost vs. Performance Tuning   DynamoDB  Challenge: Learning Curve Suggestion: Learning Curve   Amplify CLI  Challenge: Enterprise Support Suggestion: Enterprise Support Challenge: Uncomfortable Level of Magic Suggestion: Uncomfortable Level of Magic   AppSync  Challenge: GraphQL Centered Development Learning Curve Suggestion: GraphQL Centered Development Learning Curve   API Gateway  Challenge: Limited Service Support for HTTP API -\u0026gt; AWS Service Integrations Suggestion: Limited Service Support for HTTP API -\u0026gt; AWS Service Integrations Challenge: VTL Mapping Templates Suggestion: VTL Mapping Templates   EventBridge  Challenge: Security Model Suggestion: Security Model Challenge: Observability Suggestion: Observability Challenge: Real-time and High Volume Event Rates Suggestion: Real-time and High Volume Event Rates   X-Ray  Challenge: Effort to Enable Suggestion: Effort to Enable   AWS Serverless Application Model (SAM)  Challenge: Infrastructure Resource to Code Locality Suggestion: Infrastructure Resource to Code Locality     Serverless at AWS: General Challenge: Skill Set / Developer Accessibility Serverless skill set has less to do with coding and more knowing the capabilities of each service and how they can be integrated and composed together. The role of the architect becomes central to building effective serverless solutions. This is increasingly so, because the integrations between services are trending more towards configuration over code.\n\u0026ldquo;Traditional\u0026rdquo; application developers see the next step as containers because it\u0026rsquo;s familiar / closer to what they\u0026rsquo;re used to (long-lived processes running on an OS vs. a transient run-time environment). It\u0026rsquo;s hard to make the leap directly to serverless and bypass the containers and k8s space.\nSuggestion: Skill Set / Developer Accessibility This is where education / resources / etc. are the main tools. Continue and accelerate the creation of content on the AWS blogs, twitch channel, youtube channels, podcasts, Developer Advocates on social media, etc.\nAmplify suite of tools and services is helping in this area for easing the on-boarding those new to serverless development on AWS.\n Challenge: Developer Experience (DX) The path to \u0026ldquo;serverless\u0026rdquo; adoption has shifted from the foundational technologies being in place to improving developer experience. Everyone is sold on serverless being the right thing, now it\u0026rsquo;s enabling it\u0026rsquo;s usage and making accessible to the huge pool of developers who only have experience with \u0026ldquo;traditional\u0026rdquo; application development.\nSuggestion: Developer Experience (DX) SAM and Amplify tooling are quickly addressing the gaps. Accelerate what\u0026rsquo;s already being done.\n Challenge: Cost Forecasting Currently difficult to estimate cost with serverless solutions because usually composed of many services. It\u0026rsquo;s a good deal of effort to understand all the cost contributing dimensions across all the used services. Then assemble.\nSuggestion: Cost Forecasting An \u0026ldquo;Cost Profiler\u0026rdquo; feature by exercising a solution while \u0026ldquo;recording\u0026rdquo; it, then extrapolating to give a cost per \u0026ldquo;user\u0026rdquo; transaction / time (for sustained transactions) / etc.. \u0026ldquo;Cost Profiler\u0026rdquo; similar to a performance profiler.\nThis has similarities and maybe could leverage X-Ray distributed traces + the already captured default CloudWatch metrics per service.\n Challenge: Non-AWS Core Enterprise Tools Building an effective CI/CD pipeline at a large enterprise involves leveraging non-AWS already established tooling. For example, Bitbucket, Jenkins, and Artifactory.\nThis leads to \u0026ldquo;lowest common denominator\u0026rdquo; pipelines that don\u0026rsquo;t meet the vision of CI/CD. They are dependant on the availability of adapters/integrations/etc. for specific clouds that the cloud agnostic tools provide.\nAWS has a corresponding solution for each of these that eases building a CI/CD pipeline when the target is AWS. Integrated security via IAM threaded through all the service interactions is the biggest win as security is usually the sticking point. We lose \u0026ldquo;potential\u0026rdquo; value as a result of using these non-AWS equivalents over the flexibility it provides the company to support it\u0026rsquo;s current multi-cloud (aws,azure,gcp, etc.) position.\nSuggestion: Non-AWS Core Enterprise Tools This is driven by the \u0026ldquo;non all-in\u0026rdquo; stance of many large enterprises for multi-cloud. More education in this area about explicitly acknowledging a single cloud approach for given enterprise areas, and understanding and documenting the cost to switch to a different cloud is enough to mitigate the \u0026ldquo;perceived\u0026rdquo; risk.\n IAM Challenge: Skill Set / Developer Accessibility Security is inherently hard and involves many complex entities and their relationships. To be effective and successful on AWS, a customer needs to know this. This is table stakes. IAM continues to be the largest barrier to entry I see with AWS users. It is necessary and robust, but a new concept to \u0026ldquo;traditional\u0026rdquo; developers. The closest thing to it that many devs have experience with is RDBMS permissions.\nSuggestion: Skill Set / Developer Accessibility AWS is leveraging Amplify suite as an on-boarding mechanism for those new to AWS. It currently \u0026ldquo;handles\u0026rdquo; all the IAM concerns via automation / codegen / etc. Maybe helpful to add features that allow developers to take more ownership in this area. Similar to what SAM CLI does with AWS SAM Policy Templates\n CloudFormation Challenge: Deployment Time A challenge I\u0026rsquo;ve observed with serverless development, is slowed down iterative workflow due to the length of time it takes for a CloudFormation deployment to run. Developers are used to live reload level of speed to see dev changes reflected back to them.\nSuggestion: Deployment Time Faster deployment times :)\n Lambda Challenge: Lambda or Container Decision Lambda has grown to have a lot of features and configuration options. Lambda feature set is converging towards Fargate and vice versa. There is already a decision to be made on which to choose. This convergence could make it even more unclear which to pick. Or if one goes away and they are merged, the migration path.\nSuggestion: Lambda or Container Decision  More tools similar to Well-Architected to help decide. Converge Lambda and Container functionality into single service   Challenge: Cost vs. Performance Tuning The external community has solutions such as lambda power tuning to automate finding the right compute/memory configuration for a given applications priority balance between performance and cost.\nSuggestion: Cost vs. Performance Tuning AWS has all the information and metrics about the container environment through the duration of the run. Would be nice to have this as a service. Maybe \u0026ldquo;Lambda tuning suggestions\u0026rdquo; that is purely informational and someone has to take action to apply configuration changes. This helps customers, but AWS also with it\u0026rsquo;s own efficiency goals via underlying resource scheduling (e.g. scheduling, workload placement, container packing, etc.)\n DynamoDB Challenge: Learning Curve  the default serverless database. NoSQL does not have standards like the RDBMS and extended SQL family. You are learning an AWS specific DB and how to interact with it via an API. * There is no smoothing / accessibility layer like SQL.  This is a DB where to use effectively, you need to learn it. I\u0026rsquo;ve observed devs try to lean on language/library/framework ORMs, but that only gets them so far. In order to dev, debug, deploy, operationalize, and troubleshoot it, you need to learn it.\nSuggestion: Learning Curve Continue with tools like NoSQL Workbench for DynamoDB GUI Client and education resources.\nThere is a lot of content on single table vs. multi-table design for a single application. I\u0026rsquo;ve observed developers go down the \u0026ldquo;expert\u0026rdquo; path of single table design, but once it was operational and had to be supported, the support team has to learn the \u0026ldquo;advanced\u0026rdquo; single table concepts. They made errors, etc., and we eventually split into multi-table design because it was more supportable.\n Amplify CLI Challenge: Enterprise Support Amplify in it\u0026rsquo;s current form poses some challenges for use in enterprises. This is due to the amount of automation around the creation of IAM resource types on behalf of the developer. You need a large set of permissions to use including those to create new IAM resource types, which becomes an application partitioning/firewalling issue in shared accounts in addition to the increased security concerns around IAM.\nSuggestion: Enterprise Support Add various IAM role/policy/etc. parameters to configure.\nIt\u0026rsquo;s aim to stay simple for the target audience may make this extra/advanced usage an product impedance mismatch, and therefore out of scope for the product.\n Challenge: Uncomfortable Level of Magic Amplify CLI is making AWS more accessible to \u0026ldquo;traditional\u0026rdquo; developers. Makes it really easy to get started by automating all of the resource provisioning pieces. Once you need to go outside the \u0026ldquo;happy path\u0026rdquo; / debug / troubleshoot / deal with IAM, etc., devs need to understand these concepts. The amount of infrastructure code and source code it generates for the developer has the \u0026ldquo;feel\u0026rdquo; of too much magic. All those extra artifacts that get checked into the repo makes it \u0026ldquo;feel\u0026rdquo; prone to breakage as the CLI evolves.\nSuggestion: Uncomfortable Level of Magic To address the users that want to break out of \u0026ldquo;beginner\u0026rdquo; mode on rails, and take more control of resource provisioning, allow the one-way \u0026ldquo;ejection\u0026rdquo; from Amplify CLI to SAM CLI. Similar to what create-react-app | npm run eject. This enables a natural learning and skills transition for devs to take on and understand more AWS concepts, and therefore more effective us of the AWS platform.\n AppSync Challenge: GraphQL Centered Development Learning Curve Great service and there are clear benefits to graphql centric development.\nThere is a necessary steep learning curve inherent to graphql. Many \u0026ldquo;new\u0026rdquo; concepts for devs to learn. API, Schema, DataSource, Resolver, Resolver Function, Resolver Pipeline. New graphql schema language to learn, and to use effectively, AWS specific schema directives.\nFeels vendor lockin-y, but traded for the auto provisioned DB, configurable security (e.g. Cognito UserPools), generated client side code.\nSuggestion: GraphQL Centered Development Learning Curve Looking at other tech of the past and their evolution, community standardization around GraphQL managed services would be the next likely step. The value AppSync provides is much more than graphql itself. It builds on the benefit of the schema via tooling like Amplify CLI for strong typing, auto provision storage backend (AWS graphql directives), client-side code generation, etc. All these things are AWS specific and don\u0026rsquo;t yet have standards or a generalized community name. Maybe they never will, and it\u0026rsquo;s similar to DynamoDB as a unique only at AWS cloud differentiating super-service, but if not, AWS could be a part of that future body and drive standardization along with other cloud vendors.\n API Gateway Challenge: Limited Service Support for HTTP API -\u0026gt; AWS Service Integrations HTTP API -\u0026gt; AWS Service Integrations are great for simplified and removing lambda as a simple glue layer. There is currently a limited set of services supported.\nSuggestion: Limited Service Support for HTTP API -\u0026gt; AWS Service Integrations Keep the momentum with adding service support.\n Challenge: VTL Mapping Templates I have observed with developers I\u0026rsquo;ve worked with that VTL mapping templates cause a lot of confusion. Should they become a expert at VTL and put the logic to transform a payload in it? Another legacy language to learn that has limited returns on investment. Should they just do it in lambda with a language they are familiar with? It \u0026ldquo;feels\u0026rdquo; like it\u0026rsquo;s something that should not be exposed to customer and only used internally. The Java-ness heritage of verbosity, and yet another language to learn and know, is an implementation detail/concern being surfaced to the customer.\nSuggestion: VTL Mapping Templates Phase out / deprecate usage. Introduce a way to express via simplified, declarative only (no control constructs trying to be a general purpose programming language), yaml/json.\n EventBridge EventBridge seems like it\u0026rsquo;s on the way to being a centerpiece service of serverless solutions. As core to serverless as lambda is.\nChallenge: Security Model The security model around events \u0026ldquo;feels\u0026rdquo; a bit off at the moment. It almost feels like it\u0026rsquo;s bypassing security. If I can subscribe to events on a given bus, especially \u0026ldquo;default\u0026rdquo; account bus, I can access information coming from a whole host of services. It similar to the sensitivity at which CloudTrail requires. This sensitivity means more concerns around security, which limits adoption.\nSuggestion: Security Model It is covered by IAM Policy Conditions, but it doesn\u0026rsquo;t feel like first class support. Less than ideal DX. IAM policy conditions is an already overloaded mechanism where concepts that don\u0026rsquo;t cleanly fit into the Resources and Actions entity concepts are put.\nThe naive answer would be a new IAM concept, like \u0026ldquo;Events\u0026rdquo; and corresponding \u0026ldquo;Producers\u0026rdquo; and \u0026ldquo;Consumers\u0026rdquo; (Actions, Resources, Events, Producers, Consumers and Condition Keys for AWS Services). Similar to Resources, Events could benefit from first class IAM entity concepts like Events, Producers, Consumers to align with developer expectations around event based systems.\n Challenge: Observability Events in general are challenging when it comes to observability. EventBridge is no different.\nSuggestion: Observability  event retention per bus. similar to kinesis 7 day max. native event replay / event time travel to help with dev debugging, app state transitions, event schema evolution.   Challenge: Real-time and High Volume Event Rates Also some hook into the trend of client-side event based state solutions feels natural for EventBridge (e.g. React Redux). Maybe it\u0026rsquo;s in the form of a library that fits into Amplify since it\u0026rsquo;s aligned to client-side web and mobile tech.\nGiven events in many systems can be high volume and high rates, exposing a native websocket API for the publishing and consumption of events would be helpful. There are already projects in the community doing this, which validates the need for it.\nSuggestion: Real-time and High Volume Event Rates  native websocket api for high volume and real-time without having the added complexity of AppSync or API Gateway.   X-Ray Challenge: Effort to Enable Observability and distributed tracing is required for almost any serverless solution since there are many services involved. This is the \u0026ldquo;serverless\u0026rdquo; version of a \u0026ldquo;traditional\u0026rdquo; stack trace and/or local application log. These are essential tools for developers.\nThe following are friction points with the service:\n Instrumenting code with the x-ray sdk configuring to turn on/off in different way for each service that supports it having to understand and make decisions around sampling rates learning each services equivalent of a header to put a correlation/trace id in that doesn\u0026rsquo;t interfere with the \u0026ldquo;core\u0026rdquo; payload, etc.  Suggestion: Effort to Enable Ideally it would be on by default across all services, baked into each services pricing, and the customer would not have the choice to turn off. These are plumbing level, distributed systems, \u0026ldquo;undifferentiated heavy lifting\u0026rdquo; types of concerns. The ones AWS is best at handling.\nThe view is that aws runs all the services, and I as the customer shouldn\u0026rsquo;t need to do anything, but use the services to get this visibility.\n AWS Serverless Application Model (SAM) Challenge: Infrastructure Resource to Code Locality The linkage from a SAM template to local code via a directory path/s3 location/etc. suffers the locality of code problem. Infrastructure and code are clearly separated (you can do inline code up to char limit), when it should be converging and feel natural. A future state being infrastructure usage as part of a solution feels like a first class concept of the language or a library where you offload language level single process control constructs to infrastructure that is distributed, scalable, and elastic (e.g. step fn, EventBridge, SNS, SQS, etc.). To the point where I\u0026rsquo;m not thinking about the infrastructure at all. I only express it through code. Has a feeling of \u0026ldquo;shifting gears\u0026rdquo;.\nSuggestion: Infrastructure Resource to Code Locality With the introduction of the CDK, the lines between application code and infrastructure provisioning code is merging. This \u0026ldquo;feels\u0026rdquo; like the more natural path for SAM to adopt the CDK style.\nIf you extend CDK to the next level of evolution in abstraction, it\u0026rsquo;s a cloud specific programming language. Infrastructure as a whole is \u0026ldquo;undifferentiated heavy lifting\u0026rdquo; and not of concern to an end user of a solution. A current means to an end. Something like \u0026ldquo;CloudScript\u0026rdquo;?, but already taken by MS :)\n","permalink":"https://brianpfeil.com/post/aws-serverless-feedback/","postedOnDate":" September 11, 2020","tags":["aws","serverless"],"title":"AWS Serverless Feedback"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-appflow-veeva-vault-to-s3-playground  AWS AppFlow example of Veeva Vault data -\u0026gt; AppFlow -\u0026gt; S3.\nNotes  no events from Vault. only poll / query existing data manually/on demand or schedule.  at the time (2020-09-08) EventBridge was not available as a destination.  available destinations: redshift, s3, salesforce    Screenshot Tour veeva vault data source general information\nveeva vault org\nveeva vault connection\nsource -\u0026gt; destination\nmapping\ncreated\nrun history\ndata landed in s3\nResources  AppFlow Saas Applications | Veeva Vault https://developer.veevavault.com/  ","permalink":"https://brianpfeil.com/post/aws-appflow-veeva-vault-to-s3/","postedOnDate":" September 8, 2020","tags":["aws","appflow","s3"],"title":"AWS AppFlow Veeva Vault to S3"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/product-development-playground  product, product development, strategy\n Wardley Mapping  A Wardley Map is a representation of the landscape in which a business operates. It consists of a value chain (activities needed to fulfill user needs) graphed against evolution (how individual activities change over time under supply and demand competition). A Wardley Map represents the situational awareness and shared assumptions being made about a context and hints at what strategic options are available.\n Concise summary of process at Understand context and diminish risk: How to build your first Wardley Map with Miro\nKey Points\n use mapping as a way to quickly validate solutions and avoid costly mistakes – to identify what to build, buy and outsource map minimizes the chance that I’ll miss something important a more evolved component can be outsourced and treated like a building block, while a less evolved component usually needs to be built from scratch or given other special consideration (money, time and energy). The real danger is in mistreating a more evolved component by building it from scratch. Outsourcing highly evolved components is a critical aspect of building cost-effective solutions. Since you have limited resources, it makes sense to save them for the components that actually need special treatment.  Map\n Y-axis - value chain. invisible (bottom) to visible (top). user at top X-axis - genesis (new, uncertain, failure-prone), custom, product, commodity (old, boring, reliable)  Example(s)\n\nVideo Showing the Process\nhttps://www.youtube.com/embed/84vV8fj4Ljg\nResources  wardley-map-powerpoint-template.potx wardley-maps-community.github.io/awesome-wardley-maps˝ medium.com/wardleymaps Wardley map - Wikipedia Intro to Wardley Mapping Understand context and diminish risk: How to build your first Wardley Map with Miro https://twitter.com/swardley https://twitter.com/dvassallo  ","permalink":"https://brianpfeil.com/post/product-development/","postedOnDate":" September 3, 2020","tags":[],"title":"Product Development"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/ant-design-pro-playground  learn And Design Pro\n Ant Design Pro is a production-ready solution for admin interfaces. Built on the design principles developed by Ant Design, this project introduces higher level components; we have developed templates, components, and a corresponding design kit to improve the user and development experience for admin interfaces.\n see myApp based on Ant Design Pro | Getting Started\n","permalink":"https://brianpfeil.com/post/ant-design-pro/","postedOnDate":" September 2, 2020","tags":[],"title":"Ant Design Pro"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/antd-react-playground  learn Ant Design (antd) for React\nFiles and Directories  src/App.js src/App.css  Resources  Use in create-react-app - Ant Design   This project was bootstrapped with Create React App.\nAvailable Scripts In the project directory, you can run:\nyarn start Runs the app in the development mode.\nOpen http://localhost:3000 to view it in the browser.\nThe page will reload if you make edits.\nYou will also see any lint errors in the console.\nyarn test Launches the test runner in the interactive watch mode.\nSee the section about running tests for more information.\nyarn build Builds the app for production to the build folder.\nIt correctly bundles React in production mode and optimizes the build for the best performance.\nThe build is minified and the filenames include the hashes.\nYour app is ready to be deployed!\nSee the section about deployment for more information.\nyarn eject Note: this is a one-way operation. Once you eject, you can’t go back!\nIf you aren’t satisfied with the build tool and configuration choices, you can eject at any time. This command will remove the single build dependency from your project.\nInstead, it will copy all the configuration files and the transitive dependencies (webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except eject will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.\nYou don’t have to ever use eject. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.\nLearn More You can learn more in the Create React App documentation.\nTo learn React, check out the React documentation.\nCode Splitting This section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting\nAnalyzing the Bundle Size This section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size\nMaking a Progressive Web App This section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app\nAdvanced Configuration This section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration\nDeployment This section has moved here: https://facebook.github.io/create-react-app/docs/deployment\nyarn build fails to minify This section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify\n","permalink":"https://brianpfeil.com/post/antd-react/","postedOnDate":" September 1, 2020","tags":["react","design","ui","framework","ui-components"],"title":"Antd React"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-appflow-salesforce-eventbridge-playground  AWS AppFlow example of salesforce event -\u0026gt; AppFlow -\u0026gt; EventBridge -\u0026gt; CloudWatch Logs. Followed steps in Building Salesforce integrations with Amazon EventBridge and Amazon AppFlow | Amazon Web Services post.\nNotes  observed low latency - AppFlow flow runs within 2 seconds of event being generated in salesforce. only fields specified in mapping are passed to EventBridge as properties of detail. Private Amazon AppFlow flows is available for salesforce that uses AWS PrivateLink to route data over AWS infrastructure without exposing it to the public internet  Screenshot Tour Turn on Change Data Capture for the relevant objects in salesforce Error when CDC is not turned on in salesforce for the object AppFlow leverages already installed/available \u0026ldquo;Amazon AppFlow Embedded Login App\u0026rdquo; Connected App in salesforce\nRun History Event in CloudWatch Logs AppFlow Mapping Resources  Building Salesforce integrations with Amazon EventBridge and Amazon AppFlow | Amazon Web Services  ","permalink":"https://brianpfeil.com/post/aws-appflow-salesforce-eventbridge/","postedOnDate":" August 27, 2020","tags":["aws","appflow","salesforce","eventbridge"],"title":"AWS AppFlow Salesforce EventBridge"},{"categories":["Makefile","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-api-gateway-aws-service-integration-playground   shows how an API Gateway endpoint can directly invoke an aws service like EventBridge, DynamoDB, etc. No lambda in the middle (reduces latency and costs).\n HTTP REST APIs are the most common integration pattern. API Gateway is AWS managed service for creating REST APIs. It allows us to apply security, throttling, logging, etc. to our APIs. In some cases an API is simply a passthrough to a backend AWS service. The typical approach is to have API Gateway invoke a lambda, which then contains the code to call th target AWS service. If you don\u0026rsquo;t need to perform any additional logic to the request prior to calling the backend AWS service, you may be able to use an API Gateway AWS service integration, which can directly invoke the AWS service. This simplifies the architecture, reduces request latency and reduces costs.\n Demo Prerequisites\n An AWS account AWS Command Line Interface SAM CLI  Running\n# clone repo git clone https://github.com/pfeilbr/aws-api-gateway-aws-service-integration-playground cd aws-api-gateway-aws-service-integration-playground # deploy make deploy # test make test example output\n{ \u0026#34;Entries\u0026#34;: [ { \u0026#34;EventId\u0026#34;: \u0026#34;58c635b4-21aa-09d8-0ad3-0874b7dc0a39\u0026#34; } ], \u0026#34;FailedEntryCount\u0026#34;: 0 } # teardown make teardown  Details invoking the EventBridge PutEvents action with the request payload using the APIGatewayEventBridgeAccessRole role.\nIntegration:Type:AWSCredentials:!GetAtt APIGatewayEventBridgeAccessRole.ArnIntegrationHttpMethod:POSTUri:!Sub \u0026#34;arn:aws:apigateway:${AWS::Region}:events:action/PutEvents\u0026#34;setting the required headers to invoke the PutEvents action\nRequestTemplates:application/json:|$input.json(\u0026#34;$\u0026#34;) #set($context.requestOverride.header.X-Amz-Target =\u0026#34;AWSEvents.PutEvents\u0026#34;) #set($context.requestOverride.header.Content-Type =\u0026#34;application/x-amz-json-1.1\u0026#34;)Resources  Use API Gateway as a Proxy for Another AWS Service AWS::ApiGateway::Method.Integration to dynamodb Query example PutEvents - Amazon EventBridge CloudFormation Resources Generated By SAM API Gateway integration problem  ","permalink":"https://brianpfeil.com/post/aws-api-gateway-aws-service-integration/","postedOnDate":" August 20, 2020","tags":["aws","api-gateway","eventbridge","api"],"title":"AWS API Gateway AWS Service Integration"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-comprehend-playground  learn Amazon Comprehend [Medical]\nFiles and Directories of Interest  src/index.js src/index.test.js src/fixtures src/example-responses  Running # while developing npm test -- --watch Resources  Amazon Comprehend - Natural Language Processing (NLP) and Machine Learning (ML) Comprehend - Amazon Comprehend Amazon Comprehend Medical - Amazon Comprehend  ","permalink":"https://brianpfeil.com/post/aws-comprehend/","postedOnDate":" August 18, 2020","tags":["aws","machine-learning","javascript"],"title":"AWS Comprehend"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/graphviz-playground  learn Graphviz - Graph Visualization Software\n example01.dot  Developing # vscode \u0026#34;Graphviz Interactive Preview\u0026#34; extension was not working with images # use the following to create .png image on .dot file change # open vscode in split view with .dot in one and .png in the other. # .png view will refresh when the file is updated. fswatch -o example01.dot | xargs -n1 -I{} dot -Tpng example01.dot -oexample01.png  Screenshots vscode example with \u0026ldquo;Graphviz Interactive Preview\u0026rdquo;\nResources  Graphviz Interactive Preview - Visual Studio Marketplace Create diagrams with code using Graphviz  ","permalink":"https://brianpfeil.com/post/graphviz/","postedOnDate":" August 18, 2020","tags":["tools","diagram","architecture"],"title":"Graphviz"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/mage-playground  learn mage, a make/rake-like build tool using Go. You write plain-old go functions, and Mage automatically uses them as Makefile-like runnable targets.\nInstall git clone https://github.com/magefile/mage cd mage go run bootstrap.go Demo git clone https://github.com/pfeilbr/mage-playground cd mage-playground go mod init mage-playground # NOTE: `go.mod` must exist in same directory as `magefile.go` # show targets mage # run \u0026#34;hello\u0026#34; target mage hello ","permalink":"https://brianpfeil.com/post/mage/","postedOnDate":" August 18, 2020","tags":["golang","build","tools"],"title":"Mage"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-sam-step-functions-playground  learn and experiment with using AWS SAM to define and deploy AWS Step Functions.\nsee template.yaml and data/event-bus-events.json\nRunning # deploy sam deploy --guided # trigger step fn via EventBridge rule aws events put-events --cli-input-json file://data/event-bus-events.json # e.g. output # { # \u0026#34;FailedEntryCount\u0026#34;: 0, # \u0026#34;Entries\u0026#34;: [ # { # \u0026#34;EventId\u0026#34;: \u0026#34;369fc438-8a99-bc45-7d79-46788420dbf8\u0026#34; # } # ] # } # trigger via API Gateway. starts step fn then returns (does not wait for step fn to complete) curl https://4cakde2i15.execute-api.us-east-1.amazonaws.com/Prod/start # e.g. output # { # \u0026#34;executionArn\u0026#34;: \u0026#34;arn:aws:states:us-east-1:529276214230:execution:SimpleStateMachine-zIFFWgUF6O6D:53313d15-1005-44d0-84a0-ea57b66d1ac3\u0026#34;, # \u0026#34;startDate\u0026#34;: 1.597426336318E9 # } # teardown aws cloudformation delete-stack --stack-name \u0026#34;aws-sam-step-functions-playground\u0026#34; --region \u0026#34;us-east-1\u0026#34; Resources  Simplifying application orchestration with AWS Step Functions and AWS SAM [aws | events | put-events]](https://docs.aws.amazon.com/cli/latest/reference/events/put-events.html#examples)  ","permalink":"https://brianpfeil.com/post/aws-sam-step-functions/","postedOnDate":" August 14, 2020","tags":["aws","sam","step-functions"],"title":"AWS SAM Step Functions"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-sam-golang-playground  An example API and Worker written in Golang using the Amazon Serverless Application Model (AWS SAM).\n modified version of cpliakas/aws-sam-golang-example. switched to use go modules, added the use of local environment variables, and run sam local assuming lambda function role.\n Overview Go is arguably one of the easiest languages in which to write a RESTful API. With the addition of Go support for AWS Lambda coupled with the maturity of tooling around the AWS Serverless Application Model, deploying Golang-based APIs to serverless infrastructure is becoming much more straightforward, too. Thanks to the APEX Gateway, you can even write APIs in a familiar manner without changing how the code is structured.\nThe purpose of this project is to give a slightly more complicated example than the \u0026ldquo;hello world\u0026rdquo; ones provided by Amazon with a toolchain that supports both local development and deployment to AWS as well as design patterns that facilitate unit testing.\nPrerequisites  An AWS account Golang dep Docker Node.js AWS Command Line Interface SAM CLI jq (optional)  Installation With a correctly configured Go toolchain:\ngit clone https://github.com/pfeilbr/aws-sam-golang-example Usage Run the API Locally :warning: Make sure to install all the Prerequisites. On Mac OSX and Windows, ensure that the Docker VM is running.\nBuild the API and run it locally:\nGOARCH=amd64 GOOS=linux go build -o api ./service/api sam local start-api or \u0026hellip;\nmake run You can now consume the API using your tool of choice. HTTPie is pretty awesome.\nhttp localhost:3000/ HTTP/1.1 200 OK Content-Length: 28 Content-Type: application/json; charset=utf8 Date: Sat, 03 Feb 2018 20:12:07 GMT { \u0026#34;message\u0026#34;: \u0026#34;Hello, world!\u0026#34; } Deploy to AWS First, set the following environment variables replacing \u0026lt;MY-BUCKET-NAME\u0026gt; and \u0026lt;MY-STACK-NAME\u0026gt; as appropriate:\nexport S3_BUCKET=\u0026#34;\u0026lt;MY-BUCKET-NAME\u0026gt;\u0026#34; export STACK_NAME=\u0026#34;\u0026lt;MY-STACK-NAME\u0026gt;\u0026#34; Now build, package, and deploy the application:\nGOOS=linux GOARCH=amd64 go build -o api ./service/api GOOS=linux GOARCH=amd64 go build -o error ./service/error GOOS=linux GOARCH=amd64 go build -o worker ./service/worker sam package --template-file template.yaml --s3-bucket $S3_BUCKET --output-template-file packaged.yaml sam deploy --stack-name $STACK_NAME --template-file packaged.yaml --capabilities CAPABILITY_IAM or \u0026hellip;\nmake deploy Consume the Endpoint The API endpoint is captured in the CloudFormation stack\u0026rsquo;s Endpoint output key. Either view the output value via the AWS Management Console, or run the following command assuming the jq tool is installed:\naws cloudformation describe-stacks --stack-name $STACK_NAME | jq -r \u0026#39;.Stacks[0].Outputs[0].OutputValue\u0026#39; Again, HTTPie is a pretty awesome tool.\nView AWS Logs Run the following command to get the CloudWatch logs for the API.\nsam logs -n Api --stack-name $STACK_NAME Replace Api with Worker or Error to get logs for the Lambda functions in those resources as well.\n:warning: The sam tool will throw a nasty stack trace if you try to view the logs before the Lambda function has been invoked. Only run this command after you have made requests to the corresponding handlers.\nSession example development session\nexport S3_BUCKET=\u0026#34;${S3_SAM_DEPLOY_BUCKET}\u0026#34; export STACK_NAME=\u0026#34;$(basename $(pwd))\u0026#34; # test make test # build make build # build make deploy # start SAM local API sam local start-api --profile my-lambda-role --env-vars env-vars.json # GET curl -X POST http://127.0.0.1:3000 # POST a job curl -X POST http://127.0.0.1:3000/job -d \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;my job\u0026#34;}\u0026#39; # tail the logs for the worker that processes SQS messages lumigo-cli tail-cloudwatch-logs --namePrefix \u0026#34;/aws/lambda/aws-sam-golang-example-Worker\u0026#34; --region \u0026#34;us-east-1\u0026#34; ","permalink":"https://brianpfeil.com/post/aws-sam-golang/","postedOnDate":" July 30, 2020","tags":["aws","sam","golang","iam","testing"],"title":"AWS SAM Golang"},{"categories":["aws","sam","lambda"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-sam-golang-playground  AWS Serverless Application Model (SAM) allows you to develop and test your lambda backed API Gateway endpoints locally via sam local start-api. By default, your function is invoked with the default credentials you have configured for the AWS CLI. If your function accesses other AWS services, it may encounter permission issues. It\u0026rsquo;s ideal to have your lambda run under as close to the same security context locally as it would when deployed. In the example below, lambda sends a message to a SQS worker queue. The permissions for the queue are configured to allow the lambda role to send a message to it. The following details how to achieve this.\nAllowing Our Lambda Role to be Assumed In our scenario, we have a local user profile named admin stored in ~/.aws/credentials\n[admin] aws_access_key_id = YOUR_ACCESS_KEY aws_secret_access_key = YOUR_SECRET_ACCESS_KEY This user needs to be able to assume our my-lambda-role role. We define the following Role Trust policy to enable:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;lambda.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::xxxxxxxxxxxx:user/admin\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] Configure Assume Role via AWS CLI Next we need to configure the AWS CLI to assume a role. We can do so by adding the following to ~/.aws/config\n# ~/.aws/config [profile my-lambda-role] role_arn = arn:aws:iam::xxxxxxxxxxxx:role/my-lambda-role source_profile = admin output = json region = us-east-1 Note the source_profile = admin line. This identifies the profile in ~/.aws/credentials that will be used to assume the role.\n See How do I assume an IAM role using the AWS CLI? for full details on options.\n We can test with the following:\naws --profile my-lambda-role sts get-caller-identity If successful, the response will look like.\n{ \u0026#34;UserId\u0026#34;: \u0026#34;AROAXWO2SDPLLBS55Q345:botocore-session-1596129185\u0026#34;, \u0026#34;Account\u0026#34;: \u0026#34;xxxxxxxxxxxx\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:sts::529276214230:assumed-role/my-lambda-role/botocore-\u0026#34; } Running SAM Local The SQS queue URL is provided to the lambda via an environment variable. This is defined in the SAM template\ntemplate.yaml\nEnvironment:Variables:QUEUE_URL:!Ref QueueWe need QUEUE_URL to be available to our function running locally. To do that we can create an environment variable .json file and pass as a parameter for sam local to use.\nenv-vars.json\n{ \u0026#34;Parameters\u0026#34;: { \u0026#34;QUEUE_URL\u0026#34;: \u0026#34;https://sqs.us-east-1.amazonaws.com/xxxxxxxxxxxx/aws-sam-golang-example-Queue-Q12J860AETTS\u0026#34; } } We can now start the local SAM API server and test our endpoint\nsam local start-api --profile my-lambda-role --env-vars env-vars.json curl -X POST http://127.0.0.1:3000/job -d \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;my job\u0026#34;}\u0026#39; Conclusion We\u0026rsquo;ve seen how to run a lambda locally with the same security context as when deployed. SAM provides a great development workflow to allow quick iterations. The local environment provided via docker tries to be as true to the AWS environment, but you should test with the real services as early as possible.\nOne point to note, you must have the AWS resources your lambda is interacting with provisioned. For example, the SQS queue must exist. SAM does not provide a locally running SQS service.\nThe source for this example is written in Go, which has a great workflow. Our focus wasn\u0026rsquo;t on the code, but if you want more Go + SAM + Lambda, be sure to check out the AWS GO SERVERLESS! workshop by AWS Serverless Developer Advocate Rob Sutter. It covers the details and workflow of using Go with SAM.\n","permalink":"https://brianpfeil.com/post/aws-sam-local-invoke-with-lambda-role/","postedOnDate":" July 30, 2020","tags":["aws","sam","lambda"],"title":"AWS SAM Local Invoke with Lambda Role"},{"categories":["architecture","aws","serverless"],"contents":"A serverless architecture is \u0026ldquo;typically\u0026rdquo; composed of many services. The following covers the key considerations and configuration options for the most common AWS services leveraged for serverless architectures.\n  Relevant Patterns Lambda SNS SQS Kinesis EventBridge DynamoDB Step Functions API Gateway CloudFront Route53 Global Accelerator WAF   Relevant Patterns common cloud native patterns to consider in the context of serverless architectures of scale\n event sourcing circuit breaker - trip circuit to prevent downstream systems overload load shedding - prevent backlog buildup handle poison messages - prevent kinesis and dynamodb streams from progressing prevent distributed transactions. e.g. lambda send job to SQS and stores status in dynamodb. break it up. lambda put job status in dynamo -\u0026gt; dynamo stream -\u0026gt; lambda send job to SQS   Lambda   synchronous vs asynchronous vs poll based (poll based is sync) - impacts automatic retries, stuck messages due to poison message, etc.\n see Understanding the Different Ways to Invoke Lambda Functions    if lambda is strictly a glue passthrough for API Gateway to call a backend AWS service, look to use API Gateway Service Proxies to remove lambda. simpler/cheaper/etc.\n  memory\n  DLQ\n  lambda destinations (only for async invokes)\n  reserved concurrency - concurrency allocated for a specific function. e.g. i always want fn X to be able to run 10 lambda invokes concurrently\n  provisioned concurrency - pre-warmed lambda instances / no cold starts. good for latency sensitive needs\n can optionally use auto scaling to adjust on based on metrics and/or schedule. will spill over to on-demand scaling (lambda default) Provisioned Concurrency comes out of your regional concurrency limit    concurrent executions (throttles) - 1000 per account\n  timeout - 15min\n set code timeouts based on remaining invocation time provided in context    burst concurrency - 500 - 3000\n  burst - 500 new instances / min\n  poll based options (kinesis, dynamodb, SQS)\n on-failure destination (SNS or SQS) retry attempts max age of record - use to implement load shedding (prioritize newer messages) split batch on error concurrent batches per shard    SNS  fan out to address scale KMS to encrypt payloads  SQS  batch size - batch fails as unit visibility timeout - set to 6x lambda timeout message retention period delivery delay - max 15min types - standard vs FIFO  standard - at least once delivery. need to ensure idempotent   alarm on queue depth KMS  Kinesis  partition key - choose wisely as order is guaranteed per shard and pk determines the shard the message lands on poison messages (retry until success - can cause backlog) KMS to encrypt payloads enhanced fan-out via AWS::Kinesis::StreamConsumer. each consumer gets 2 MiB per second for every shard you subscribe to. can subscribe a max of 5 consumers per stream.  EventBridge  put events - 2400 requests per second per region invocation quota - 4500 requests per second per region (invocation is an event matching a rule and being sent on to the rule’s targets)  DynamoDB  global tables - for resilient active-active architectures throttles streams - 24hr data retention. poison messages (retry until success - can cause backlog) partition key - distribute data among nodes to minimize hot partitions TTL - can the data be removed automatically  Step Functions  Standard Workflows vs Express Workflows saga pattern for rollback parallel map opportunities - run tasks in parallel  API Gateway  REST API vs HTTP API (cheaper) caching - fixed cost based on time / no pay per use throttles timeout - 29s auth - cognito, JWT, IAM (aws sigv4), custom lambda auth OpenAPI specs for payload validation service proxies - no need for lambda glue in middle custom domains websockets  CloudFront  origin access identity to force traffic through CloudFront and removes direct access to S3 website domain URL signed URLs or cookies lambda@edge - headers only requests, rewrite URLs, server-side rendering (SSR), auth, etc. cache invalidations non GET HTTP methods support. must explicitly turn on support for PUT, POST, PATCH, etc. WAF in front  Route53  Geoproximity routing for global solutions serving multiple regions  Global Accelerator  uses the AWS global network to optimize the path from your users to your applications, improving the performance of your traffic by as much as 60%\n WAF  can put in front of API Gateway or CloudFront API Gateway provides overlapping functionality with WAF. Need to determine the appropriate service to use.  ","permalink":"https://brianpfeil.com/post/serverless-architecture-key-considerations-per-service/","postedOnDate":" July 20, 2020","tags":["architecture","aws","serverless"],"title":"Serverless Architecture: Key Service Considerations"},{"categories":["architecture","cloud"],"contents":"A personal cheatsheet/reference for cloud native software architecture.\narchitecture\n how the components are assembled and organized. This will be done in a way that meets the quality attributes.\n   Key Questions Organization Considerations Quality Attributes (*ities and friends) Patterns  event-sourcing  Core Design Decisions Resources   Hexagonal  Resources     Topics / Concepts / Terms  Database Shuffle Sharding Constant Work Canary   Resources  Books (oreilly.com) Websites     Key Questions  who are the users? what devices and form factors will be used? what is the context of their usage? scale and growth? who are the main actors in the system (domain objects - e.g. orders, products, etc.)? data classifications (PII)? data types and sizes (relation records, documents, media files, etc.)? what is the time frame for delivery? is there an existing product / SaaS / open-source / etc. that provides the solution or a portion / components of it capacity estimation \u0026amp; constraints? functional requirements? Non Functional Requirements - Latency, Consistency, Availability, High Throughput, etc. what is explicitly out of scope organization and teams structure   see System Design: DoorDash — a prepared food delivery service for good reference\n  Organization Considerations  engineering (application \u0026amp; platform) operations (application \u0026amp; platform)   Quality Attributes (*ities and friends)  reliability - ability to continue to operate under predefined conditions availability - ratio of the available system time to the total working time scalability - ability of the system to handle load increases without decreasing performance efficiency performance security cost interoperability correctness maintainability readability extensibility testability  Patterns modern cloud native architecture patterns as of July 2020\n event-sourcing  Capture all changes to an application state as a sequence of events.\n Core Design Decisions  Domain Entities and Events  popular method is via Event Storming   Event Content  each event stores delta state each event stores full state  idempotent is easy to solve for duplicate events     Total Ordering (ordered stream of events - ledger)  ensure all event are processed in order. this is needed for causal relationships. e.g. ordering matters for two messages related to the same entity    Resources  Scaling Event Sourcing for Netflix Downloads, Episode 1 Scaling Event Sourcing for Netflix Downloads, Episode 2 InfoQ | Scaling Event Sourcing for Netflix Downloads | Video + Presentation - shows in detail how they implemented event sourcing backed by cassandra matrinfowler.com | Event Sourcing Pattern: Event sourcing EventBridge Storming — How to build state-of-the-art Event-Driven Serverless Architectures - approach to defining the Events, Boundaries and Entities in your business domain Decomposing the Monolith with Event Storming   Hexagonal the ports and adapters architecture. decouples core domain logic from specific storage, database, protocol, etc.\nResources  Hexagonal Architecture: three principles and an implementation example   Topics / Concepts / Terms Database  CAP theorem  Consistency: Every read receives the most recent write or an error Availability: Every request receives a (non-error) response, without the guarantee that it contains the most recent write Partition tolerance: The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes   Serializability Snapshot isolation Multiversion concurrency control Things I Wished More Developers Knew About Databases   Shuffle Sharding limits / isolates tenants in a multi-tenant system so they don\u0026rsquo;t negatively impact other tenants. method of assigning tenant to resources.\nResources\n Workload isolation using shuffle-sharding  Constant Work  overprovision resources to the point where it would operate correctly even if an availability zone were to be unavailable if AZ becomes unavailable, no new resources need to be provisioned, just a quick re-routing. you are essentially always operating the infrastructure for failure mode (active-active)  Resources\n Static stability using Availability Zones   Canary  A canary release is a technique to reduce the risk from deploying a new version of software into production. A new version of software, referred to as the canary, is deployed to a small subset of users alongside the stable running version. Traffic is split between these two versions such that a portion of incoming requests are diverted to the canary. This approach can quickly uncover any problems with the new version without impacting the majority of users.\n Resources\n Automated Canary Analysis at Netflix with Kayenta   Resources Books (oreilly.com)   Fundamentals of Software Architecture\n  Clean Architecture: A Craftsman\u0026rsquo;s Guide to Software Structure and Design, First Edition\n  Software Architecture Patterns\n  Building Evolutionary Architectures\n  Clean Architecture: A Craftsman\u0026rsquo;s Guide to Software Structure and Design, First Edition\n  Domain-Driven Design: Tackling Complexity in the Heart of Software\n  Microservices Patterns\n  Patterns of Enterprise Application Architecture\n  Refactoring: Improving the Design of Existing Code\n  Design Patterns: Elements of Reusable Object-Oriented Software\n  Designing Distributed Systems\n  Designing Distributed Control Systems: A Pattern Language Approach (Wiley Software Patterns Series)\n  Websites  martinfowler.com AWS Architecture Center AWS Architecture Blog Amazon Builders' Library Azure Architecture Center medium | articles tagged with \u0026ldquo;software architecture\u0026rdquo; C4 model for visualizing software architecture  ","permalink":"https://brianpfeil.com/post/cloud-native-software-architecture/","postedOnDate":" July 18, 2020","tags":["architecture","cloud"],"title":"Cloud Native Software Architecture"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/lumigo-cli-playground  lumigo-CLI is a command line tool that contains a collection of helpful commands for working with AWS Lambda and the serverless AWS services it integrates with.\nIt\u0026rsquo;s an invaluable tool for serverless development on AWS. It contains commands that let you work with individual services line sending messages to SNS, SQS, and Kinesis. Tailing changes to CloudWatch Logs, DynamoDB, Kinesis, EventBridge, SNS, SQS. Automatically tune lambda for the optimal memory configuration, measure lambda cold starts.\nEasy to install via global npm package (npm install lumigo-cli -g).\nExample Usage # display contents of gzipped cloudfront log file to stdout # see S3 SQL reference @ https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-glacier-select-sql-reference-select.html lumigo-cli s3-select-batch \\  --region=\u0026#34;us-east-1\u0026#34; \\  --bucket=\u0026#34;com.brianpfeil.cloudfront.logs\u0026#34; \\  --prefix=\u0026#34;brianpfeil.com/E2IL5HY5XTHLNW.2019-09-17-21.66bbda6b.gz\u0026#34; \\  --expression=\u0026#34;SELECT * FROM S3Object s\u0026#34; \\  --fileType=\u0026#34;CSV\u0026#34; \\  --compressionType=\u0026#34;GZIP\u0026#34; # list Lambda functions in ALL regions lumigo-cli list-lambda ","permalink":"https://brianpfeil.com/post/lumigo-cli/","postedOnDate":" July 17, 2020","tags":["cli"],"title":"Lumigo CLI"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-interactive-video-service-playground   learn Amazon Interactive Video Service based on Getting Started with Amazon Interactive Video Service  Running # create channel via https://docs.aws.amazon.com/ivs/latest/userguide/GSIVS.html # streaming an existing video via ffmpeg VIDEO_FILEPATH=\u0026#34;/Users/pfeilbr/Downloads/tailer.mp4\u0026#34; # fortnite game trailer STREAM_KEY=\u0026#34;sk_us-east-1_LvBpPyJZzkix_yMQ6LPLZ7PDr6dYsI0zqM4H2oZTL31\u0026#34; INGEST_ENDPOINT=\u0026#34;0f426742eaf2.global-contribute.live-video.net\u0026#34; ffmpeg -re -stream_loop -1 -i $VIDEO_FILEPATH -r 30 -c:v libx264 -pix_fmt yuv420p -profile:v main -preset veryfast -x264opts \u0026#34;nal-hrd=cbr:no-scenecut\u0026#34; -minrate 3000 -maxrate 3000 -g 60 -c:a aac -b:a 160k -ac 2 -ar 44100 -f flv rtmps://$INGEST_ENDPOINT/app/$STREAM_KEY # view in AWS Console | Amazon IVS | Live Channels Screenshots Resources  Introducing Amazon Interactive Video Service (Amazon IVS) Amazon Interactive Video Service – Add Live Video to Your Apps and Websites Amazon Interactive Video | Docs  ","permalink":"https://brianpfeil.com/post/aws-interactive-video-service/","postedOnDate":" July 16, 2020","tags":["aws"],"title":"AWS Interactive Video Service"},{"categories":["PHP","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/bref-php-lambda-playground  learn bref, deploy and run serverless PHP applications\nPrerequisites  PHP serverless framework  Running # install composer require bref/bref # init vendor/bin/bref init # edit `index.php` # deploy serverless deploy # test / invoke serverless invoke -f \u0026#34;function\u0026#34; # test / invoke with event data serverless invoke --function \u0026#34;function\u0026#34; --data \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;foo\u0026#34;}\u0026#39; Resources  bref | Installation  ","permalink":"https://brianpfeil.com/post/bref-php-lambda/","postedOnDate":" July 13, 2020","tags":["php","lambda"],"title":"Bref PHP Lambda"},{"categories":["HTML","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/heroku-node-worker-playground  example of running a long lived worker process on heroku that is not a web app/server\nPrerequisites  heroku account Heroku CLI  Running # clone git clone https://github.com/pfeilbr/heroku-node-worker-playground.git # change to root directory cd heroku-node-worker-playground # create heroku app heroku create # \u0026gt;\u0026gt;\u0026gt; make changes to `worker.js`, install packages, etc. # test locally npm run worker # commit changes git commit -a -m \u0026#34;my awesome changes\u0026#34; # deploy / push changes to heroku git push heroku master # if worker is already running, this push will kill it and start the new one # run worker only / stop web dyno heroku ps:scale web=0 worker=1 # verify running heroku ps # view logs heroku logs -t # stop worker heroku ps:scale worker=0 # start worker heroku ps:scale worker=1 Resources  Background Jobs in Node.js with Redis Run Non-web Java Dynos on Heroku  ","permalink":"https://brianpfeil.com/post/heroku-node-worker/","postedOnDate":" July 13, 2020","tags":["heroku"],"title":"Heroku Node Worker"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/strapi-playground  learn strapi, the open-source headless CMS\nPrerequisites  docker desktop  Session # create app npx create-strapi-app my-project --quickstart # local docker install / run via https://strapi.io/documentation/v3.x/installation/docker.html # pull docker-compose pull # run docker-compose up -d # open web ui open http://localhost:1337/admin Screenshots Resources  Strapi Documentation  ","permalink":"https://brianpfeil.com/post/strapi/","postedOnDate":" July 10, 2020","tags":["cms","javascript"],"title":"Strapi"},{"categories":["Makefile","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/php-lambda-layer-playground  learn stackery/php-lambda-layer for running PHP on lambda\nPrerequisites\n php 7.x composer installed globally (used by makefile)  Key Files\n src/php/index.php src/php/php.ini - for enabled extensions template.yaml packaged.yaml - generated via sam  Session\nsee Makefile for details and make changes to variables as necessary.\n# deploy stack make deploy # test api gateway endpoint URL make test # delete stack make delete Resources  Introducing the new Serverless LAMP stack Introducing the serverless LAMP stack – part 2 relational databases aws-samples/php-examples-for-aws-lambda - github repo for article. AWS Lambda Custom Runtime for PHP: A Practical Example - older article, but covers low level details AWS SDK for PHP  ","permalink":"https://brianpfeil.com/post/php-lambda-layer/","postedOnDate":" July 2, 2020","tags":["php","lambda"],"title":"PHP Lambda Layer"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/serverless-golang-playground  see myservice/README.md for build and deploy steps\nNOTE\n this is based on serverless framework from Jan 2018 (just adding as repo now June 2020)\n  see golang.serverlessworkshops.io for more modern example (go modules) using AWS SAM\n ","permalink":"https://brianpfeil.com/post/serverless-golang/","postedOnDate":" June 17, 2020","tags":["serverless","golang"],"title":"Serverless Golang"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-eventbridge-playground  learn AWS EventBridge\n# put events on default event bus aws events put-events --entries file://sample-events/my-custom-app-events.json Resources  https://github.com/jbesw/s3-to-lambda/blob/master/eventbridge/README.md - examples using AWS::Events::Rule in SAM to map event sources to targets (e.g. lambda, kinesis, etc.)  ","permalink":"https://brianpfeil.com/post/aws-eventbridge/","postedOnDate":" May 19, 2020","tags":["aws","eventbridge"],"title":"AWS EventBridge"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/goreleaser-playground  learn GoReleaser release automation tool for Go projects.\nsee https://goreleaser.com/quick-start/\nSession goreleaser --snapshot --skip-publish --rm-dist export GITHUB_TOKEN=\u0026#39;GITHUB_TOKEN\u0026#39; # tag. release name is based on it git tag -a v0.1.0 -m \u0026#34;First release\u0026#34; git push origin v0.1.0 # run locally without publishing to github goreleaser --snapshot --rm-dist # build and publish goreleaser ","permalink":"https://brianpfeil.com/post/goreleaser/","postedOnDate":" April 16, 2020","tags":["golang","continuous-delivery"],"title":"GoReleaser"},{"categories":["aws"],"contents":"AWS Services The following services are commonly used for AWS solutions. Each service specifies key considerations and features per service for architecture and design.\n Serverless Services Serverless Benefits Relevant Patterns Deployment Types Networking and Content Delivery  VPC ELB/ALB PrivateLink / VPC Endpoint Route 53 Cloud Map Global Accelerator CloudFront API Gateway AppSync   Compute  EC2 ECS ECR Fargate Batch EKS LightSail Elastic Beanstalk Lambda Lambda@Edge   Storage  S3 Glacier EFS (Elastic File System) FSx for Windows File Server Storage Gateway EBS Transfer   Database  DynamoDB DocumentDB (MongoDB compatibility) RDS Redshift ElastiCache ElasticSearch Neptune Timestream Cloud Directory SSM Parameter Store   Application Integration  AppFlow Step Functions SNS SQS SES EventBridge Kinesis   Analytics  Kinesis Data Analytics Pinpoint EMR Data Pipelines Glue Glue DataBrew Athena QuickSight Lake Formation   Management \u0026amp; Governance  Well-Architected Framework Control Tower Organizations CloudFormation Serverless Application Repository (SAR) Service Catalog Config AppConfig CloudWatch Logs CloudWatch Events (see EventBridge) CloudWatch Insights CloudWatch Metrics CloudWatch Alarms CloudWatch Synthetics (Canaries) CloudTrail Proton   Developer Tools  Cloud9 CodeCommit CodeBuild CodeDeploy CodePipeline CodeArtifact X-Ray AWS CLI Amplify SAM (Serverless Application Model) CDK AWS SDKs   Migration \u0026amp; Transfer  AWS DataSync AWS DMS (Database Migration Service)   Machine Learning  SageMaker Comprehend Polly Rekognition Textract Translate Transcribe Forecast Personalize Lex Kendra   Security, Identity, and Compliance  IAM Cognito Secrets Manager WAF Certificate Manager (ACM) KMS Directory Service   Media Services  Amazon Interactive Video Service    Serverless Services  Route53 Global Accelerator WAF Cognito CloudFront API Gateway AppSync Amplify Lambda DynamoDB S3 SNS SQS SES Kinesis EventBridge Glue Step Functions Athena SSM Parameter Store Secrets Manager AppConfig AWS Config CloudWatch Synthetics (Canaries) CloudWatch Metrics and Alarms CloudWatch Logs CloudFormation Serverless Application Repository (SAR) SAM (Serverless Application Model) CDK X-Ray  Serverless Benefits  less things to own less/no ops costs - pay-per-use elastic / limits scaling concerns deliver value quicker scale teams / org fit durability/resiliency - services built-in replication across AZs or regions every service has soft limits for protection   Relevant Patterns  event sourcing circuit breaker - trip circuit to prevent downstream systems overload load shedding - prevent backlog buildup handle poison messages - prevent kinesis and dynamo streams from progressing prevent distributed transactions. e.g. lambda send job to SQS and stores status in dynamodb. break it up. lambda put job status in dynamo -\u0026gt; dynamo stream -\u0026gt; lambda send job to SQS strangler - migrate from monolith to serverless. e.g. DB - run RDS and dynamodb in parallel and update both for a period of time   Deployment Types  all-at-once blue/green canary - traffic shift percentages with metrics linear - changing the amount of traffic split to the new version incrementally according to a percentage that is provided when configured.   Networking and Content Delivery VPC  virtual private cloud Subnets, route tables, internet gateways, elastic ips, nat gateways, network ACLs, security groups, prefix lists  ELB/ALB   Elastic Load Balancing (TCP)\n  ALB application load balancer — Layer 7 (HTTP/HTTPS traffic), Flexible\n  NLB network load balancer — Layer 4 (TLS/TCP/UDP traffic), Static IPs\n  CLB classic load balancer — Layer 4/7 (HTTP/TCP/SSL traffic), Legacy, Avoid\n  The NLB forwards requests whereas the ALB examines the contents of the HTTP request header to determine where to route the request. So, the ALB is performing content based routing.\n  PrivateLink / VPC Endpoint  connect to AWS services from VPC without going through internet enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection gateway endpoint - S3 and DynamoDB. via VPC route table.  gateway that you specify as a target for a route in your route table for traffic destined to a supported AWS service   interface endpoint - all other services. via DNS resolver for VPC/subnets  an elastic network interface with a private IP address from the IP address range of your subnet that serves as an entry point for traffic destined to a supported service specify subnets, security groups, IAM policy doc, enable private DNS    Route 53  managed DNS main service for reliability / DR public and private domains (hosted zones) route to aws services - CloudFront, API Gateway, ELB, RDS, S3 bucket, EC2, VPC Interface Endpoint record sets, TTL health checks - public endpoints or via CloudWatch metrics (e.g. for private endpoints)  can associate a health check with recordset. e.g. Route 53 failover recordset.   load balancing via DNS routing policies - latency Based Routing, Geo DNS, Geoproximity, and Weighted Round Robin domain registration geo routing, geoproximity routing alias record type (aws specific. used for root/bare/naked domains) AWS Route53 — Cheat Sheet(In 2 Minutes)  Cloud Map  name and discover your cloud resources via API or DNS  Global Accelerator  uses the highly available and congestion-free AWS global network to direct internet traffic from your users to your applications on AWS fixed entry point to your applications through static IP addresses allocates static Anycast IP addresses that are globally unique for your application and do not change  CloudFront  CDN POP / edge servers - traffic over AWS global infrastructure price classes ACM for TLS/SSL certs cache policies. cookie, headers, querystring, TTLs configs origin access identity origin custom headers signed URLs or cookies origin groups - primary origin and a second origin to failover to custom error responses - http error codes mapped to response page paths georestrictions lambda@edge - headers only requests, rewrite URLs, server-side rendering (SSR), auth, etc. cloudfront functions - run lightweight JavaScript code  no network and file system access. max run time - run less than 1 ms. Where a Lambda@Edge is deployed to one of the 13 regional edge locations, Cloudfront Functions are deployed even further down and closer to the viewer at one of the 280+ edge locations   cache invalidations non GET HTTP methods support. must explicitly turn on support for PUT, POST, PATCH, etc. WAF association can point to Object Lambda Access Point  API Gateway  REST API vs HTTP API (cost). see Choosing between HTTP APIs and REST APIs edge (cloudfront) and regional endpoints API Keys caching (memcached) (fixes cost based on time / no pay per use) API Keys Usage Plans / quotas client certificates - ensure requests to backend are from APIG throttles with WAF in front, you can set up rate-based rules to specify the number of web requests that are allowed by each client IP in a trailing, continuously updated, 5-minute period. no API Key required for this timeout - 29s request (POST) payload limits (10 MB). no response size limits. (tested with proxy integration for 200 MB video file download) auth - cognito, JWT, IAM (aws sigv4), custom lambda auth OpenAPI / Swagger specs for payload validation service integrations - no need for lambda glue in middle velocity templates (vtl) - request/response mapping custom domains private endpoints websockets lambda integration. point to lambda alias for deployments. stages mock integrations / responses  AppSync  GraphQL managed service integrates with Amazon DynamoDB, Amazon Elasticsearch, and Amazon Lambda resolvers resolver mapping templates via velocty (vtl) Real-time subscriptions aws specific graphql schema @directives for model (ddb), auth (cognito), GraphiQL javascript for vtl coming (2021-03-28)   Compute EC2  AMI elastic IPs ASGs (launch templates) UserData - script to run on instance start EC2 metadata service  ECS  containers task definitions  Fargate and EC2 launch types   Service - maintain a specified number of instances of a task definition  Service load balancing - distribute traffic evenly across the tasks in your service Service auto scaling - via Application Auto Scaling service. CPU/memory utilization CW metrics   EFS or EBS for persistent storage  EFS is recommended. Can be mounted by multiple ECS tasks for parallel access EBS can be used but is tied to a hosting EC2 instance. Not supported on fargate.    ECR  container registry concepts  Registry - can create image repositories in your registry and store images in them Authorization token - client must authenticate to Amazon ECR registries as an AWS user before it can push and pull images Repository - contains your Docker images, Open Container Initiative (OCI) images, and OCI compatible artifacts Repository policy - can control access to your repositories and the images within them with repository policies Image - push and pull container images to your repositories  can use them in ECS task definitions and EKS pod specifications     ECR public resource-based permissions using AWS IAM Announcing Pull Through Cache Repositories for Amazon Elastic Container Registry  Fargate Docs | Amazon ECS on AWS Fargate\n containers task definitions run containers without having to manage servers or clusters removes the need to choose server types, decide when to scale your clusters, or optimize cluster packing. When you run your tasks and services with the Fargate launch type, you package your application in containers, specify the CPU and memory requirements, define networking and IAM policies, and launch the application. Amazon ECS tasks for Fargate can authenticate with private image registries, including Docker Hub, using basic authentication. When you enable private registry authentication, you can use private Docker images in your task definitions. Fargate Spot - you can run interruption tolerant Amazon ECS tasks at a discounted rate compared to the Fargate price. Fargate Spot runs tasks on spare compute capacity. When AWS needs the capacity back, your tasks will be interrupted with a two-minute warning.  Batch  run batch computing jobs using containers concepts:  Compute Environments - set of managed or unmanaged compute resources that are used to run jobs. Fargate or EC2. specify the minimum, desired, and maximum number of vCPUs for the environment. Job Queues - backed by 1 or more compute envs, assign priority Job Definitions - cpu and memory requirements, iam role for access to other aws resources Jobs - things that run on fargate or ec2. shell script, a Linux executable, or a Docker container image  Array Jobs - run parallel jobs such as Monte Carlo simulations, parametric sweeps, or large rendering jobs. AWS_BATCH_JOB_ARRAY_INDEX is passed to each job as an env var to represent the current index Automated Job Retries Job Dependencies      EKS  managed Kubernetes automates the deployment, scaling, and management of containerized applications  LightSail  Virtual servers, storage, databases, and networking for a low, predictable price. backed by EC2, but easier to use similar to DigitalOcean  Elastic Beanstalk  PaaS with language runtime + docker containers heroku-like  Lambda  synchronous vs asynchronous vs poll based/stream processing (poll based is sync. via event-source mappings) memory - single knob for memory and CPU DLQ lambda destinations (only for async invokes) reserved concurrency - concurrency allocated for a specific function. e.g. i always want fn X to be able to run 10 lambda invokes concurrently provisioned concurrency - pre-warmed lambda instances / no cold starts. good for latency sensitive needs  can optionally use auto scaling to adjust on based on metrics and/or schedule. will spill over to on-demand scaling (lambda default) Provisioned Concurrency comes out of your regional concurrency limit   concurrent executions (throttles) - 1000 per account timeout - 15min  set code timeouts based on remaining invocation time provided in context   burst concurrency - 500 - 3000 burst - 500 new instances / min poll based options (kinesis, dynamodb, SQS)  on-failure destination (SNS or SQS) retry attempts max age of record - use to implement load shedding (prioritize newer messages) split batch on error concurrent batches per shard   APIG -\u0026gt; lambda ALB -\u0026gt; lambda service integrations - Using AWS Lambda with other services - AWS Lambda lambda private endpoints - access lambda from VPC without going over internet Lambda Extensions - executables in /opt/extensions that conform to the Lambda Extensions API Container Images  Runtime interface clients  runtime interface client in your container image manages the interaction between Lambda and your function code Lambda provides an open source runtime interface client for each of the supported Lambda runtimes. e.g. node.js, python, etc.   Lambda Runtime Interface Emulator  allows customers to locally test their Lambda function packaged as a container image web-server that converts HTTP requests to JSON events and maintains functional parity with the Lambda Runtime API   max image size: 10 GB   Lambda Wrapper Scripts | Modifying the runtime environment - customize the runtime startup behavior of your Lambda function. e.g. set env vars, add/update parameters.  code example aws-samples/aws-lambda-environmental-variables-from-aws-secrets-manager   AWS Lambda Operator Guide  Lambda@Edge  feature of Amazon CloudFront that lets you run code closer to users of your application, which improves performance and reduces latency   Storage S3  object/blob storage versioned buckets presigned URLs for private content (download or upload) S3 batch operations S3 select batch operations - perform operation on list of objects specified in manifest. e.g. lambda, copy, etc. storage classes lifecycle rules - moving between storage tiers for cost savings access points - managing data access at scale, access points are unique hostnames, enforce distinct permissions and network controls for any request made through the access point, scale to many applications accessing bucket with own set of permissions.  addresses pain point- Managing access to this shared bucket requires a single bucket policy that controls access for dozens to hundreds of applications with different permission levels Multi-Region access points   S3 event notifications - notification destinations are SNS, SQS, lambda Use Amazon S3 Event Notifications with Amazon EventBridge replication - cross-region, same-region S3 object lambda - process data retrieved from S3 with lambda before returning it to an application. lambda calls writeGetObjectResponse to send modified object contents back to GET request. Create S3 Access Point, then Object Lambda Access Point.  Glacier  low cost/long-term object/blob storage  EFS (Elastic File System)  elastic file system for Linux-based workloads for use with AWS Cloud services and on-premises resources. can mount as NFS v4 e.g. shared file system. many EC2 instances can mount same efs file system. can mount to lambda local filesystem  FSx for Windows File Server  fully managed native windows file system SMB, NTFS, AD integration  Storage Gateway  NFS or SMB interface to S3, FSx, volume/tape gateways compute runs on once of following: ec2, kvm, VMware, Hyper-V, or appliance if SMB, need to Configuring Microsoft Active Directory access VPC support. network traffic between compute and AWS Service goes over VPC endpoint VPC endpoint enabled, all VPC endpoint communication from your gateway to AWS services occurs through the public service endpoint using your VPC in AWS Creating a VPC endpoint for Storage Gateway  EBS  block level storage volumes for use with EC2 instances. EBS volumes behave like raw, unformatted block devices  Transfer  SFTP to S3 enables the transfer of files directly into and out of S3 using SFTP   Database DynamoDB  concepts - tables, items, queries, scans, indexes global tables - for resilient active-active architectures DAX - DynamoDB Accelerator - in memory cache in front GSI (Global Secondary Indexes), LSI (Local Secondary Indexes) transactions throttles point-in-time recovery (PITR) streams - 24hr data retention. poison messages (retry until success - can cause backlog) partition key - distribute data among nodes to minimize hot partitions TTL - can the data be removed automatically parallelization factor for DDB streams processed by lambda single table designs fine grained item (dynamodb:LeadingKeys) and attribute level IAM (dynamodb:Attributes). enables multi-tenant isolation. Amazon DynamoDB Encryption Client PartiQL - A SQL-Compatible Query Language for Amazon DynamoDB - Amazon DynamoDB dynamodb table export to s3 DynamoDB Standard-IA table class  you will save up to 60 percent in storage costs as compared to using the DynamoDB Standard table class. However, DynamoDB reads and writes for this new table class are priced higher than the Standard tables\n   DocumentDB (MongoDB compatibility) RDS  Aurora, PostgreSQL, MySql, MariaDB, Oracle, SQL Sever DB Instance (contains 1 or more dbs), Instance Classes (compute+memory), Instance Storage HA Multi-AZ  Redshift  managed data warehouse service. postgres foundation RA3 instances - Scale compute and storage independently for fast query performance and lower costs UDFs - lambda backed, Redshift Data API - http based (no JDBC or ODBC). async so can retrieve results later. query results stored for 24 hrs redshift spectrum - SQL queries on data stored in S3  ElastiCache  managed redis and memcached  ElasticSearch  cluster kibana - integrated with IAM IAM for granular es api operations  Neptune  graph database. query languages Apache TinkerPop Gremlin and SPARQL (RDF)  Timestream  time series database InfluxDB, Prometheus, Riak  Cloud Directory  cloud-native directory that can store hundreds of millions of application-specific objects with multiple relationships and schemas  SSM Parameter Store  Systems Manager Parameter Store provides secure, hierarchical storage for configuration data management and secrets management   Application Integration AppFlow  managed integration (ETL) service securely transfer data between SaaS applications (Salesforce, Marketo, Slack, etc.), and AWS services (S3, Redshift, EventBridge, etc.) concepts - flow, source, destination, flow trigger (on demand, event, schedule), map fields from source to destination (formula transforms, value validations), filters (determine records to transfer) Flow notifications - flow start|complete|deactivated events sent to CloudWatch Events/EventBridge (\u0026quot;source\u0026quot;: \u0026quot;aws.appflow\u0026quot;) security  encryption at rest - connection data stored in secrets manger using AWS managed or Customer managed CMK Encryption in Transit (TLS 1.2) - choose either an AWS managed CMK or a customer managed CMK. When executing a flow, Amazon AppFlow stores data temporarily in an intermediate S3 bucket and encrypts it using this key. This intermediate bucket is deleted after 24 hours, using a bucket lifecycle policy.   Actions defined by Amazon AppFlow  Step Functions  Standard Workflows vs Express Workflows orchestration with many built-in integrations to aws services Step Functions AWS SDK Service Integrations saga pattern for rollback parallel map opportunities - run tasks in parallel service integrations - request/response, run a job (.sync), callback with task token (.waitForTaskToken) Step Functions Visual Designer in AWS Console JSONPath expressions Data flow simulator  SNS  pub/sub message filtering with subscription push notifications standard topic  at least once delivery best effort ordering - ensure downstream consumers are idempotent   FIFO topic  strict ordering Strict deduplication: Duplicate messages aren\u0026rsquo;t delivered. Deduplication happens within a 5-minute interval, from the message publish time.   fan out subscription filters destination types  SQS lambda http/s mobile push notifications SMS messages email   DLQ configuration KMS encryption  SQS  managed message queuing service batch size - batch fails as unit visibility timeout - set to 6x lambda timeout message retention period delivery delay - max 15min types - standard vs FIFO  standard - at least once delivery. need to ensure idempotent FIFO - strict ordering. exactly-once processing   alarm on queue depth KMS encryption DLQ for redrive for messages that can\u0026rsquo;t be delivered to target SQS queue  SES  send or receive emails verify domain (DNS txt) and/or email addresses (confirmation email) - verify that you own the email address or domain that you plan to send from understand Service quotas max message size - 10 MB per message (after base64 encoding). sending identity - domain or an email address send emails via SMTP or API (AWS CLI, AWS SDK) connect to a URL that provides an endpoint for the Amazon SES API or SMTP interface (e.g. email-smtp.us-east-1.amazonaws.com:587) DKIM support - DKIM works by adding a digital signature to the headers of an email message. This signature can then be validated against a public cryptographic key that is located in the organization\u0026rsquo;s DNS record SPF support - SPF establishes a method for receiving mail servers to verify that incoming email from a domain was sent from a host authorized by that domain’s administrators IAM to control user access to email sending (e.g. ses:SendEmail) Configuration sets - groups of rules that you can apply to the emails you send using Amazon SES. can publish email sending events to CWL, Firehose, SNS Event types - Send, Reject, Delivery, Bounce, Complaint, Click Open Rendering Failure store inbound emails in S3 trigger lambdas based on inbound emails publish your email sending events to CWLs or kinesis firehose Sending personalized email via email templates. templates contain placeholder values. based on Handlebars template system list management  customers can manage their own mailing lists, known as contact lists. can create topics, associate topic preferences to a contact and specify OPT_[IN|OUT] for the topic.   Global Suppression List  includes a global suppression list. When any Amazon SES customer sends an email that results in a hard bounce, Amazon SES adds the email address that produced the bounce to a global suppression list. The global suppression list is global in the sense that it applies to all Amazon SES customers. In other words, if a different customer attempts to send an email to an address that\u0026rsquo;s on the global suppression list, Amazon SES accepts the message, but doesn\u0026rsquo;t send it, because the email address is suppressed. enabled by default for all Amazon SES accounts. You can\u0026rsquo;t disable it.   reputation dashboard to track bounce and complaint rates Dedicated IP Addresses IP pool management – If you lease dedicated IP addresses to use with Amazon SES, you can create groups of these addresses, called dedicated IP pools. You can then associate these dedicated IP pools with configuration sets SES sandbox - all new accounts.  only send mail to verified email addresses and domains only send mail from verified email addresses and domains send a maximum of 200 messages per 24-hour period send a maximum of 1 message per second   need to request production access to move out of sandbox VPC endpoint support - see New – Amazon Simple Email Service (SES) for VPC Endpoints  EventBridge  pub/sub with many built-in integrations integrate with external SaaS or any custom application bus-to-bus routing within same account + region, x-account, and x-region. dlq for eb rules. if fails to deliver to target, goes in sqs queue e.g. can log all events in account including CloudTrail to CloudWatch Log Group put events - 2400 requests per second per region AWS service rule targets at-least-once event delivery to targets (ensure idempotent behavior) no ordering guarantees schema registry - helps with managing and versioning event schemas for evolution. Codegen code for handling events in various languages. can auto discover schemas by observing events on the bus. based on json schema invocation quota - 4500 requests per second per region (invocation is an event matching a rule and being sent on to the rule’s targets) DLQ EventBridge resource policies archive and replay events IAM - resource-based and identity-based policies. owner of EB resources (bus, rules, etc.) is an AWS root account. supports sending and recieving events across accounts SaaS Partner Integrations  Kinesis  collect, process, and analyze real-time, streaming data kafka alternative partition key shard count Kinesis Data Streams On-Demand Mode - charged per gigabyte of data written, read, and stored in the stream, in a pay-per-throughput fashion ordering guaranteed for messages per shard dynamic partitioning - continuously partition streaming data in Kinesis Data Firehose using keys within data like “customer_id” or “transaction_id” and deliver data grouped by these keys into corresponding Amazon Simple Storage Service (Amazon S3) prefixes lambda - lambda polls per shard  batch size batch window parallelization factor  Concurrent batches per shard – Process multiple batches from the same shard concurrently.   enhanced fan-out via AWS::Kinesis::StreamConsumer. each consumer gets 2 MiB per second for every shard you subscribe to. can subscribe a max of 5 consumers per stream. Starting position - Latest, Trim horizon, At timestamp On-failure destination Retry attempts Maximum age of record – The maximum age of a record that Lambda sends to your function. Split batch on error   poison messages (retry until success - can cause backlog) KMS aggregate multiple records into one while staying under size limits to increase throughput. see https://github.com/awslabs/kinesis-aggregation no autoscaling around shards. requires management/ops. consider SQS first as there\u0026rsquo;s less to manage and see if it can meet the need   Analytics Kinesis Data Analytics analyze streaming data with SQL\n real-time analysis supports SQL applications (aws specific) and apache flink applications concepts - application, input steam -\u0026gt; application code (SQL statements) -\u0026gt; output stream time based windows. tumbling windows. pump  Pinpoint usage, customer, and engagement analytics\nEMR hadoop, spark, and friends\n Amazon EMR Serverless  part of the job specification, you can provide the minimum and maximum number of concurrent workers, and the vCPU, memory, and storage for each worker charged for aggregate vCPU, memory, and storage resources used from the time workers start executing till the time they terminate, rounded up to the nearest second with a one-minute minimum.    Data Pipelines data processing workloads\n AWS Data Pipeline, you can regularly access your data where it’s stored, transform and process it at scale, and efficiently transfer the results to AWS services such as Amazon S3, Amazon RDS, Amazon DynamoDB, and Amazon EMR.\n Glue  catalog / metadata (hive metadata catalog) crawlers autodiscover schema data sources - S3, RDS, JDBC, dynamodb, mongodb, documentdb data targets - S3, RDS, JDBC, mongodb, documentdb jobs job types - Spark, Streaming ETL (kinesis, kafka via spark structured streaming (micro batches)), and Python shell  python shell job start-up time - 7-30 secs (based on usage observations)   languages - [py]spark and scala concepts - Data Catalog, Classifier, Connection, Crawler, Database, Table, Dynamic Frame (extend spark RDD), Job, Transform, Trigger (time based or event) glue notebook (Jupyter/Zeppelin) - interactive development and testing of your ETL scripts on a development endpoint partitions AWS Data Wrangler - excellent integration library to use with glue via python shell jobs  Glue DataBrew  visual data preparation service extract, clean, normalize, transform, combine, data at scale target audience: non-technical Data Analyst serverless. pay for what you use concepts  datasets recipes - steps to apply/take on dataset job - recipe + dataset run project - visual workspace for working with data interactively. can apply changes and visually see the results in UI. you specify a sampling of the data to work with.    Athena  serverless querying of S3 data federated query - run SQL queries across data stored in relational, non-relational, object, and custom data sources. CTAS - create table as select query S3 data in place. pay per query / data accessed. integrated with glue catalog Presto is underlying tech  QuickSight Lake Formation  Management \u0026amp; Governance Well-Architected Framework  describes the key concepts, design principles, and architectural best practices for designing and running workloads in the cloud 5 pillars - Operational Excellence, Security, Reliability, Performance, Cost Optimization Well-Architected Tool - provides guidance by answer questions Lens - serverless, analytics, ML, SaaS, etc.  Control Tower set up and govern a new, secure multi-account AWS environment. builders can provision new AWS accounts in a few clicks, while you have peace of mind knowing your accounts conform to your company-wide policies\nOrganizations  account management service that lets you consolidate multiple AWS accounts into an organization that you create and centrally manage.  CloudFormation  declarative provisioning of AWS infrastructure/resource parameters, mappings, conditionals intrinsic functions change sets nested stacks stack drift stacksets - deploy stack to multiple regions. For DR, active-active, etc. max resources declared in stack (500) custom resources - backed by lambda macros - lambda performs the template processing / transform modules - package resource configurations for inclusion across stack templates, in a transparent, manageable, and repeatable way CloudFormation Registry  Serverless Application Repository (SAR)  enables teams, organizations, and individual developers to find, deploy, publish, share, store, and easily assemble serverless architectures\n  any cfn can be used for SAR app iam for access to SAR app  Service Catalog  create and manage catalogs of IT services that are approved for use on AWS concepts:  products are cloudformation templates portfolio is collection of products  access to portfolios is via IAM users, groups, roles   IT administrator creates products and portfolios and grants access End user accesses products and deploys them   approved self-service products from Solution Factory  e.g. Oracle RDS DB with all security, tags, etc. in place e.g. static web site. S3 + CloudFormation + WAF + ACM (certificate) + Route 53 (hosted zone, domain)   Service Actions - enable end users to perform operational tasks, troubleshoot issues, run approved commands, or request permissions in AWS Service Catalog via SSM docs.  Config  monitor, notify, quarantine, remediate based on resource changes. RDK - rule development kit. Config triggers lambda on resource changes. AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations. define rules that get evaluated when any change is made (e.g. resource provisioned) conformance - collection of Config rules and remediation actions. portable. can be applied across multiple accounts and regions there are aws managed rules that are part of the service and you can define custom ones via lambda  AppConfig  feature flags, Update applications without interruptions, Control deployment of changes across your application a capability of AWS Systems Manager, to create, manage, and quickly deploy application configurations. AppConfig supports controlled deployments to applications of any size and includes built-in validation checks and monitoring. You can use AppConfig with applications hosted on EC2 instances, AWS Lambda, containers, mobile applications, or IoT devices. JSON Schema Validators - ensure that new or updated configuration settings conform to the best practices required by your application e.g. a JSON doc with application configuration can be sourced from S3, parameter store  CloudWatch Logs  centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service concepts - log groups, log streams subscriptions - real-time feed of log events from CloudWatch Logs (Kinesis [stream|firehose], elasticsearch, Lambda) Creating Metrics From Log Events Using Filters encrypt with KMS  CloudWatch Events (see EventBridge)  cron triggers  CloudWatch Insights  query log groups CWL Query Syntax  CloudWatch Metrics  time series data metric - time-ordered set of data points that are published to CloudWatch concepts - namespace, dimensions (name/value pairs), units (Bytes, Seconds, Count, and Percent), time stamp, resolution (granularity) statistics - sum, max, min, average, sample count, percentile (pNN) (metric data aggregations over specified periods of time) metrics retention Dashboards - for Visualizations Creating Metrics From Log Events Using Filters Embedded Metric Format - generate metrics from structured (json) log messages  CloudWatch Alarms  notify via email, SNS topics create a CloudWatch alarm that watches a single CloudWatch metric or the result of a math expression based on CloudWatch metrics An alarm watches a single metric over a specified time period, and performs one or more specified actions, based on the value of the metric relative to a threshold over time. The action is a notification sent to an Amazon SNS topic or an Auto Scaling policy. You can also add alarms to dashboards. composite alarms Alarm States - OK, ALARM, INSUFFICIENT_DATA (missing data points) EventBridge integration - CloudWatch sends events to Amazon EventBridge whenever a CloudWatch alarm changes alarm state.  CloudWatch Synthetics (Canaries)  supports monitoring your REST APIs, URLs, and website content every minute, 24x7, and alerts you when your application endpoints don’t behave as expected. Node.js or python based. bundles in Puppeteer + Chromium to the runtime trigger types - cron (1 min smallest freq), run once can run in VPC can also used in any workloads requiring general browser automation creates several CloudWatch metrics in CloudWatchSynthetics namespace EventBridge support. See monitoring canary events with Amazon EventBridge CloudFormation support via AWS::Synthetics::Canary   create canaries, configurable scripts that run on a schedule, to monitor your endpoints and APIs. Canaries follow the same routes and perform the same actions as a customer, which makes it possible for you to continually verify your customer experience even when you don\u0026rsquo;t have any customer traffic on your applications. By using canaries, you can discover issues before your customers do.\n CloudTrail  logs all recording AWS API and Management Console actions to S3 can query via Athena  Proton  self-serve for platform enabling teams enables the standardization of cross cutting concerns for microservices based solutions (composition of many microservices). e.g. the following is needed for each microservice and should be consistent/aligned with standards and best practices: compute, DNS, load balancing, code deployment pipeline, monitoring and alarms similar goals as Netflix\u0026rsquo;s Spinnaker  k8s ecosystem\n Developer Tools Cloud9  cloud/browser based compute environment and IDE. dev machine (ec2 amzn linux) in the cloud with browser based IDE and terminal  CodeCommit  fully-managed source control service that hosts secure Git-based repositories  CodeBuild  managed build service provides prepackaged build environments continuous integration service that compiles source code, runs tests, and produces software packages like Jenkins, Travis, CircleCI concepts - build project - environment (linux/windows, container image to use, etc.), buildspec.yml - phases, env vars, artifacts can be used to run ad-hoc workloads over lambda when need to run longer than 15 min  CodeDeploy  automates software deployments to a variety of compute services such as Amazon EC2, AWS Fargate, AWS Lambda, and your on-premises servers  CodePipeline  continuous delivery service that helps you automate your release pipelines orchestrates CodeBuild and CodeDeploy sources: github, CodeCommit, S3  CodeArtifact  fully managed software artifact repository service that makes it easy for organizations of any size to securely store, publish, and share packages used in their software development process artifactory competitor  X-Ray  distributed tracing instrument code similar to zipkin, jaeger  AWS CLI  ~/.aws/[config|credentials] --generate-cli-skeleton - e.g. aws codebuild start-build --generate-cli-skeleton \u0026gt; build.json -\u0026gt; aws codebuild start-build --cli-input-json file://start-build.json  Amplify  CLI to provision resources (Auth (cogntio), API (API Gateway), GraphQL (AppSync), Storage (S3, DynamoDB)) client-side javascript/typescript, iOS, Android libraries and UI components Amplify Console. CI/CD static site hosting.  SAM (Serverless Application Model)  higher-level cfn resource types (transformed via cfn macro on backend) SAM CLI local development features via docker (apig endpoint  CDK  express resources using general purpose programming languages (ts/js/python/java/C#) constructs - cfn (L1), CDK (L2), pattern/solution (L3) synth to cfn cloud assemblies - cfn + source code, docker images, assets (s3) aspects - ability to visit each node/resource in stack and apply changes Application -\u0026gt; Stacks -\u0026gt; Constructs Runtime context [tf|k8s] CDKsnc jsii - core/foundational tech for multi-language/polyglot support. bind any language to underlying typescript implementation. CDK pipelines for CI/CD  AWS SDKs  built in retries, timeouts can configure timeouts (e.g. AWS.config.update({maxRetries: 2, httpOptions: { timeout: 2 * 1000, connectTimeout: 3 * 1000, },}))   Migration \u0026amp; Transfer AWS DataSync copy data between NFS, SMB, S3, EFS, FSx, HDFS\nconcepts\n  transfer types\n Data transfer between self-managed storage and AWS  need to install an agent that can access self-managed storage   Data transfer between AWS storage services  no need to install an agent      agent\n VM that runs the sync software. can run on EC2 or hypervisors (VMware ESXi, KVM, and Microsoft Hyper-V hypervisors)    scheduled transfers\n  Data transfer between self-managed storage and AWS\nData transfer between AWS storage services\n\nAWS DMS (Database Migration Service)  migrate RDBS, data warehouses, nosql dbs, etc. in cloud, between combos of cloud and on-prem it\u0026rsquo;s a server (EC2) in the cloud that runs replication software (replication engine). DMS replication instance types create source and target connections schedule task on server to move data pay-as-you-go model data at rest is encrypted SSL / TLS encrypts data in -flight HA with multi-AZ deployment can provision DMS resources using CloudFormation. migration types: one-time, ongoing replication (CDC) AWS DMS doesn\u0026rsquo;t perform schema or code conversion  you can use the AWS Schema Conversion Tool (AWS SCT)   create endpoints to access source or target data store. endpoint properties  Endpoint type – Source or target. Engine type – Type of database engine, such as Oracle or PostgreSQL.. Server name – Server name or IP address that AWS DMS can reach. Port – Port number used for database server connections. Encryption – Secure Socket Layer (SSL) mode, if SSL is used to encrypt the connection. Credentials – User name and password for an account with the required access rights.   At a high level, when using AWS DMS you do the following:  Create a replication server. Create source and target endpoints that have connection information about your data stores. Create one or more migration tasks to migrate data between the source and target data stores.   A replication task can consist of three major phases:  The full load of existing data The application of cached changes Ongoing replication     At the start of the ongoing replication phase, a backlog of transactions generally causes some lag between the source and target databases. The migration eventually reaches a steady state after working through this backlog of transactions.\n    If your migration is heterogeneous (between two databases that use different engine types), you can use the AWS Schema Conversion Tool (AWS SCT) to generate a complete target schema for you.\n  Depending on the Amazon EC2 instance class you select, your replication instance comes with either 50 GB or 100 GB of data storage public and private replication instances  You use a private instance when both source and target databases are in the same network that is connected to the replication instance\u0026rsquo;s VPC. The network can be connected to the VPC by using a VPN, AWS Direct Connect, or VPC peering.   DMS Replication Process  Replication    Machine Learning SageMaker  build, train, and deploy machine learning models prebuilt containers for common machine learning frameworks—such as Tensorflow, Pytorch, and MxNet provides a suite of built-in algorithms (via docker containers) can provide custom containers model serving endpoints jupyter notebooks SageMaker notebook instance is a machine learning (ML) compute instance running the Jupyter Notebook App  Comprehend  NLP (natural language processing) By utilizing NLP, you can extract important phrases, sentiment, syntax, key entities such as brand, date, location, person, etc., and the language of the text find insights and relationships in text use case e.g.: gauge whether customer sentiment is positive, neutral, negative, or mixed based on the feedback you receive via support calls, emails, social media, and other online channels  Polly  text-to-speech (TTS) supports MP3, Vorbis, and raw PCM audio stream formats Neural Text-to-Speech (NTTS) voices  Rekognition  API to analyze any image or video file identify the objects, people, text, scenes, and activities, as well as detect any inappropriate content.  Textract  extracts text and data from scanned documents supports PNG, JPEG, and PDF formats. For synchronous APIs, you can submit images either as an S3 object or as a byte array. For asynchronous APIs, you can submit S3 objects  Translate  neural machine translation service for translating text to and from English across a breadth of supported languages  Transcribe  audio to text transcription services for your audio files. It uses advanced machine learning technologies to recognize spoken words and transcribe them into text.  Forecast  managed deep learning service for time-series forecasting. By providing Amazon Forecast with historical time-series data, you can predict future points in the series.  Personalize  create individualized recommendations for customers using their applications e.g. use cases  Personalized recommendations Similar items Personalized re-ranking i.e. re-rank a list of items for a user Personalized promotions/notifications    Lex  conversational interfaces into any application using voice and text. Amazon Lex provides the advanced deep learning functionalities of automatic speech recognition (ASR) for converting speech to text, and natural language understanding (NLU) to recognize the intent of the text chat bots  Kendra  intelligent search service (ML powered) concepts - index, documents (html, pdf, word, ppt, txt), data sources (S3, confluence, OneDrive, etc.), query point indexer to files in S3 pre-built faceted search UI component (web based) supports custom data sources. e.g. salesforce attachments data source can create custom document attributes developer and enterprise editions   Security, Identity, and Compliance IAM  terms - Resources, Identities, Entities, Principals (person or application), Actions authentication, authorization actions and operations on resources policy docs - AWS managed policies, Customer managed policies, Inline policies Identity-based (e.g. users, groups, roles) and resource-based policies (e.g. bucket policy, lambda permissions, sns topic policy, sqs queue policy) STS - temp security credentials assume role identity federation - Federated users and roles (via OIDC, SAML2, Cognito) Attribute-based access control (ABAC) - defines permissions based on attributes (tags) permission boundaries sigv4 requests account root user MFA IAM Access Analyzer - validate policies, generate policies (based on CT logs, role or user, and timeframe)  Cognito  UserPool IdentityPool - exchange UserPool.Identity for temporary IAM credentials  unauthenticated and authenticated roles   Built-in IdP Providers - amazon, google, twitter, facebook. Federation - OIDC, SAML API Gateway authorizer provided login UIs  Secrets Manager WAF  web application firewall associate with ALB, CloudFront, API Gateway  Certificate Manager (ACM)  provision, manage, and deploy public and private Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates for use with AWS services and your internal connected resources.  KMS  key management service  Directory Service  provides multiple ways to set up and run Amazon Cloud Directory, Amazon Cognito, and Microsoft AD with other AWS services. Amazon Cloud Directory provides a highly scalable directory store for your application’s multihierarchical data. Amazon Cognito helps you create a directory store that authenticates your users either through your own user pools or through federated identity providers. AWS Directory Service for Microsoft Active Directory (Enterprise Edition), also known as Microsoft AD, enables your directory-aware workloads and AWS resources to use a managed Active Directory in the AWS Cloud.   Media Services Amazon Interactive Video Service  Amazon Interactive Video Service (Amazon IVS) is a managed live streaming solution that is quick and easy to set up, and ideal for creating interactive video experiences. Send your live streams to Amazon IVS using standard streaming software like Open Broadcaster Software (OBS) and the service does everything you need to make low-latency live video available to any viewer around the world, letting you focus on building interactive experiences alongside the live video.\n ","permalink":"https://brianpfeil.com/post/aws-services/","postedOnDate":" March 29, 2020","tags":["aws"],"title":"AWS Services"},{"categories":["HTML","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/http-live-streaming-hls-playground  example of creating an HTTP Live Stream video stream from an h.264 video file.\nPrerequisites  download and install \u0026ldquo;HTTP Live Streaming Tools\u0026rdquo; from https://developer.apple.com/download/more/?=HLS (binaries are installed to /usr/local/bin)  need to login with apple developer account\n   Running # create segments for HTTP Live Streaming from media file mediafilesegmenter \\  -f ./public \\  ./assets/video/SampleVideo_1280x720_10mb.mp4 cd public python -m SimpleHTTPServer 8000 open http://localhost:8000/  public/index.html - include js code for video playback assets/video/SampleVideo_1280x720_10mb.mp4 - sample video  Resources  How can I play a m3u8 (file) video using the HTML5  element? sample-videos.com HTTP Live Streaming  ","permalink":"https://brianpfeil.com/post/http-live-streaming-hls/","postedOnDate":" March 23, 2020","tags":["streaming","http"],"title":"HTTP Live Streaming HLS"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/react-async-playground  learn React Async, a React component and hook for declarative promise resolution and data fetching\nsee src/App.js\n This project was bootstrapped with Create React App.\nAvailable Scripts In the project directory, you can run:\nyarn start Runs the app in the development mode.\nOpen http://localhost:3000 to view it in the browser.\nThe page will reload if you make edits.\nYou will also see any lint errors in the console.\nyarn test Launches the test runner in the interactive watch mode.\nSee the section about running tests for more information.\nyarn build Builds the app for production to the build folder.\nIt correctly bundles React in production mode and optimizes the build for the best performance.\nThe build is minified and the filenames include the hashes.\nYour app is ready to be deployed!\nSee the section about deployment for more information.\nyarn eject Note: this is a one-way operation. Once you eject, you can’t go back!\nIf you aren’t satisfied with the build tool and configuration choices, you can eject at any time. This command will remove the single build dependency from your project.\nInstead, it will copy all the configuration files and the transitive dependencies (webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except eject will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.\nYou don’t have to ever use eject. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.\nLearn More You can learn more in the Create React App documentation.\nTo learn React, check out the React documentation.\nCode Splitting This section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting\nAnalyzing the Bundle Size This section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size\nMaking a Progressive Web App This section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app\nAdvanced Configuration This section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration\nDeployment This section has moved here: https://facebook.github.io/create-react-app/docs/deployment\nyarn build fails to minify This section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify\n","permalink":"https://brianpfeil.com/post/react-async/","postedOnDate":" March 19, 2020","tags":["react"],"title":"React Async"},{"categories":["CSS","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-pipelines-playground  learn azure pipelines\n azure-pipelines-playground  Description Infrastructure Provisioning Steps Website Content Publishing Steps Deprovisioning Architecture Key Files and Directories Screenshots TODO Completed / Cancelled Notes Scratch     Description Pipeline performs an atomic deploy of static content from a github repo to a static site (Rout53 + ACM + WAF CloudFront + S3 when) a tag (release) is applied to the repo\nInfrastructure Provisioning Steps  create route 53 hosted zone for your domain name (e.g. mydomain.com) update DOMAIN_NAME parameter in scripts/stack.sh with the hosted zone name provision aws resources ./scripts/stack.sh create Check ACM to confirm Certificate validation via DNS validation has completed. May need to add DNS validation records to route53 hosted zone. update pipeline variables  REGION - default is us-east-1 STACK_NAME - defined in scripts/stack.sh AWS_ACCESS_KEY_ID - AccessKey output in ./tmp/${STACK_NAME}-outputs.json AWS_SECRET_ACCESS_KEY - SecretKey output in ./tmp/${STACK_NAME}-outputs.json    Website Content Publishing Steps  ensure you have develop branch checked out (this corresponds to staging environment) update website content in public directory and push to github. (optional) update redirect rules in routing-rules/routing-rules.txt push your commit(s) to remote (github) publish will run. can take up to 20 minutes to complete due CloudFront distribution update. verify updated content by visiting https://staging.mydomain.com to publish staging to production, checkout master branch and merge in develop push your commit(s) to remote (github) verify updated content by visiting https://mydomain.com and https://www.mydomain.com  Deprovisioning  deprovision aws resources ./scripts/stack.sh delete (optional) manually delete S3 website and CloudFront logs buckets.  these are not deleted because they still contain objects\n  (optional) run ./scripts/stack.sh delete again to permanently delete stack   Architecture  Key Files and Directories  cfn-templates/resources.yaml - CloudFormation stack for provisioning AWS resources.  S3 bucket(s) for static content (staging + production) CloudFront distribution(s) (staging + production) lambda@edge function for basic auth for staging site WAF Web ACL for CloudFront distribution(s) aws secrets manager secret (json doc) to store basic auth users S3 bucket for CloudFront access logs SSL Certificate (ACM) route53 root domain ALIAS record to CloudFront distribution route53 staging and www CNAME records to CloudFront distribution IAM user for CI/CD automation used by the azure pipeline   public - static web content scripts/stack.sh - provisions AWS resources tmp/automation-outputs.json - stack outputs stored here. file gets created when stack is provisioned. scripts/tag-and-trigger-publish.sh - tags and pushes the tag to github to trigger the publish pipeline scripts/publish.sh - publishes a new version of the static site based on git tag. this is used by pipeline azure-pipelines.yml - pipeline definition that get triggered on tag to publish to site   Screenshots Pipeline Variables\n TODO  route53 CNAME record to point directly to S3 bucket website domain. used to troubleshoot/bypass cache issues.  e.g. https://bucket.mysite.com -\u0026gt; https://bucket.s3-website-us-east-1.amazonaws.com research basic auth options  ok not to have basic auth?      Completed / Cancelled  add WAF ACL and associate to CF dist(s)  see Web ACL created om WAF V2 not accessible on CloudFront   add API origin to CF distribution for requests to /api/* path  precedence to 1, forward query strings, cookies, all all HTTP methods this is IMPORTANT You can indeed put CF dist in front of APIG, the trick is to force HTTPS only \u0026ldquo;Viewer Protocol Policy\u0026rdquo; AND to NOT forward the HOST header because APIG needs SNI. see How do you add CloudFront in front of API Gateway How to use API Gateway with CloudFront   add staging CloudFront distribution  options  separate bucket s3://stage s3://prod single bucket with prefix s3://bucket/stage/* s3://bucket/prod/*     update s3 redirect/routing rules for deploy version prefix  e.g. domain.com/oldlink would point to /v0.0.1/newlink in the bucket. the /v0.0.1 prefix need to be updated in all redirect rules on deploy see https://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-website.html   more reliable method of picking the origin path to update since there are two origins create IAM policy and role for resource provisioning  look at CloudFormation | Stack | Resources view for resource types specify resource name prefix and suffix as variable to allow for change specify role-arn for cloudformation cli   redirects  options  via lambda@edge check if WAF supports S3 bucket routing rules (AWS::S3::Bucket RoutingRule) s3 object metadata header. see (Optional) Configuring a Webpage Redirect and x-amz-website-redirect-location  If the bucket is configured as a website, redirects requests for this object to another object in the same bucket or to an external URL. Amazon S3 stores the value of this header in the object metadata.\n  trailing slashes: see the following on how to handle Re: S3 make a non-trailing slash URL send a 301 instead of a 302       basic auth on staging cloudfront dist  options  lambda@edge WAF rule for Authorization header     update scripts/publish.sh with proper cache control for index.html (no-cache) aws s3 sync --cache-control \u0026#39;max-age=604800\u0026#39; --exclude index.html build/ s3://mywebsitebucket/ aws s3 sync --cache-control \u0026#39;no-cache\u0026#39; build/ s3://mywebsitebucket/  deny requests directly to s3. must use domain. remove OAI and add this. this will allows redirects in S3 to work.  see How do I use CloudFront to serve a static website hosted on Amazon S3? for details. TLDR; the referer is set on the CloudFront distribution and is a secret. the S3 bucket policy only allows requests from this referer I’m using an S3 REST API endpoint as the origin of my CloudFront distribution. Why am I getting 403 Access Denied errors? I’m using an S3 website endpoint as the origin of my CloudFront distribution. Why am I getting 403 Access Denied errors? { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;http referer policy ${DomainName}\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Allow get requests referred by ${DomainName}\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::${BUCKET}/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringLike\u0026#34;: { \u0026#34;aws:Referer\u0026#34;: [ \u0026#34;http://${DomainName}/*\u0026#34;, \u0026#34;https://${DomainName}/*\u0026#34; ] } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;Explicit deny to ensure requests are allowed only from specific referer.\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::${BUCKET}/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotLike\u0026#34;: { \u0026#34;aws:Referer\u0026#34;: [ \u0026#34;http://${DomainName}/*\u0026#34;, \u0026#34;https://${DomainName}/*\u0026#34; ] } } } ] }      Notes  pipeline is running in azure DevOps tied to personal gmail account   Scratch # delete all remote tags git tag -l | xargs -n 1 git push --delete origin # delete all local tags git tag | xargs git tag -d #REDIRECT_LOCATION=\u0026#34;https://allthecloudbits.com/products/product02/\u0026#34; REGION=\u0026#34;us-east-1\u0026#34; STACK_NAME=\u0026#34;dev-agency-website\u0026#34; BUCKET=$(aws cloudformation describe-stacks --region \u0026#34;${REGION}\u0026#34; --stack-name \u0026#34;${STACK_NAME}\u0026#34; --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;WebsiteBucketName\u0026#39;].OutputValue\u0026#34; --output text) PREFIX=\u0026#34;v0.0.1\u0026#34; TARGET=\u0026#34;${PREFIX}/about\u0026#34; REDIRECT_LOCATION=\u0026#34;/about/\u0026#34; aws --profile automation-user s3api put-object \\  --bucket \u0026#34;${BUCKET}\u0026#34; \\  --key \u0026#34;${TARGET}\u0026#34; \\  --website-redirect-location \u0026#34;${REDIRECT_LOCATION}\u0026#34; \\  --content-length \u0026#34;0\u0026#34; aws --profile automation-user s3api head-object \\  --bucket \u0026#34;${BUCKET}\u0026#34; \\  --key \u0026#34;${TARGET}\u0026#34; aws --profile automation-user s3api delete-object \\  --bucket \u0026#34;${BUCKET}\u0026#34; \\  --key \u0026#34;${TARGET}\u0026#34; aws --profile automation-user s3api list-objects \\  --bucket \u0026#34;${BUCKET}\u0026#34; policy components\n{ \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;arn:aws:iam::529276214230:user/admin\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::dev-agency-website-s3bucketforwebsitecontent-11u56g1n9u9oo/*\u0026#34;, }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::dev-agency-website-s3bucketforwebsitecontent-11u56g1n9u9oo/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringLike\u0026#34;: { \u0026#34;aws:Referer\u0026#34;: \u0026#34;79011a81-c048-4877-84f4-efe9577d7250\u0026#34; } } }, { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::dev-agency-website-s3bucketforwebsitecontent-11u56g1n9u9oo/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotLike\u0026#34;: { \u0026#34;aws:Referer\u0026#34;: \u0026#34;79011a81-c048-4877-84f4-efe9577d7250\u0026#34; } } } create_routing_rule() { bucket=$1 prefix=$2 target=$3 redirect_location=$4 aws s3api put-object \\ --bucket \u0026#34;${bucket}\u0026#34; \\ --key \u0026#34;${prefix}${target}\u0026#34; \\ --website-redirect-location \u0026#34;${redirect_location}\u0026#34; \\ --content-length \u0026#34;0\u0026#34; } create_routing_rules() { bucket=$1 prefix=$2 IFS=$\u0026#39;\\r\\n\u0026#39; GLOBIGNORE=\u0026#39;*\u0026#39; rules=($(cat routing-rules/routing-rules.txt)) for rule in \u0026#34;${rules[@]}\u0026#34; do components=($(echo $rule | tr \u0026#34; \u0026#34; \u0026#34;\\r\\n\u0026#34;)) target=\u0026#34;${components[1]}\u0026#34; redirect_location=\u0026#34;${components[2]}\u0026#34; # echo \u0026#34;target=${target}, redirect_location=${redirect_location}\u0026#34; create_routing_rule \u0026#34;${bucket}\u0026#34; \u0026#34;${prefix}\u0026#34; \u0026#34;${target}\u0026#34; \u0026#34;${redirect_location}\u0026#34; done } create_routing_rules \u0026#34;dev-agency-website-s3bucketforwebsitecontent-1fbv8htrn7nna\u0026#34; \u0026#34;v0.0.1\u0026#34; # on tag BUILD_SOURCEBRANCHNAME=v0.0.1 BUILD_SOURCEBRANCH=refs/tags/v0.0.1 BUILD_SOURCEVERSION=f302ed7e007e57c118a8835f378ddd04f63e105c BUILD_SOURCEVERSIONMESSAGE=output env variables # on develop branch BUILD_SOURCEBRANCHNAME=develop BUILD_SOURCEBRANCH=refs/heads/develop BUILD_SOURCEVERSION=e59a3dfea5bd88be3808f46b48da7ddd83e8b809 BUILD_SOURCEVERSIONMESSAGE=output env variables # pipeline environment variables LEIN_HOME=/usr/local/lib/lein BUILD_QUEUEDBY=GitHub AGENT_HOMEDIRECTORY=/home/vsts/agents/2.165.0 M2_HOME=/usr/share/apache-maven-3.6.3 BOOST_ROOT=/usr/local/share/boost/1.69.0 SYSTEM_STAGEDISPLAYNAME=__default AGENT_VERSION=2.165.0 SYSTEM_JOBATTEMPT=1 GOROOT_1_11_X64=/usr/local/go1.11 ANDROID_HOME=/usr/local/lib/android/sdk JAVA_HOME_11_X64=/usr/lib/jvm/zulu-11-azure-amd64 SYSTEM_TEAMFOUNDATIONSERVERURI=https://dev.azure.com/brianpfeil/ ImageVersion=20200301.1 AGENT_TOOLSDIRECTORY=/opt/hostedtoolcache SYSTEM_DEFINITIONID=1 AGENT_DISABLELOGPLUGIN_TESTFILEPUBLISHERPLUGIN=true LANG=C.UTF-8 AGENT_WORKFOLDER=/home/vsts/work AZURE_EXTENSION_DIR=/opt/az/azcliextensions SYSTEM_DEFINITIONNAME=pfeilbr.azure-pipelines-playground AGENT_TEMPDIRECTORY=/home/vsts/work/_temp INVOCATION_ID=71a915879cc04391a20e7d2867d21806 JAVA_HOME_12_X64=/usr/lib/jvm/zulu-12-azure-amd64 AWS_SECRET_ACCESS_KEY=*** BUILD_REQUESTEDFOR=Brian Pfeil SYSTEM_PHASENAME=Job ANDROID_SDK_ROOT=/usr/local/lib/android/sdk SYSTEM_JOBIDENTIFIER=Job.__default SYSTEM_PULLREQUEST_ISFORK=False JAVA_HOME=/usr/lib/jvm/zulu-8-azure-amd64 SYSTEM_JOBPARALLELISMTAG=Private DOTNET_SKIP_FIRST_TIME_EXPERIENCE=1 USER=vsts BUILD_REASON=IndividualCI AGENT_OS=Linux SYSTEM_ISSCHEDULED=False BUILD_SOURCEVERSION=f302ed7e007e57c118a8835f378ddd04f63e105c ENDPOINT_URL_SYSTEMVSSCONNECTION=https://dev.azure.com/brianpfeil/ BUILD_SOURCEBRANCH=refs/tags/v0.0.1 GRADLE_HOME=/usr/share/gradle SYSTEM_WORKFOLDER=/home/vsts/work BUILD_QUEUEDBYID=a399e9b2-ba17-47ed-9005-8c263530afdf AGENT_DISABLELOGPLUGIN_TESTRESULTLOGPLUGIN=true AGENT_ROOTDIRECTORY=/home/vsts/work PWD=/home/vsts/work/1/s ImageOS=ubuntu18 HOME=/home/vsts AGENT_ID=8 GOROOT=/usr/local/go1.12 JOURNAL_STREAM=9:31906 SYSTEM_TOTALJOBSINPHASE=1 SYSTEM_COLLECTIONURI=https://dev.azure.com/brianpfeil/ RUNNER_TOOLSDIRECTORY=/opt/hostedtoolcache JAVA_HOME_8_X64=/usr/lib/jvm/zulu-8-azure-amd64 AGENT_OSARCHITECTURE=X64 SYSTEM_CULTURE=en-US SYSTEM_TEAMPROJECTID=398b5300-9203-4d2c-957c-82eedb6aea92 VSTS_AGENT_PERFLOG=/home/vsts/perflog CONDA=/usr/share/miniconda PIPELINE_WORKSPACE=/home/vsts/work/1 GOROOT_1_13_X64=/usr/local/go1.13 BOOST_ROOT_1_69_0=/usr/local/share/boost/1.69.0 SYSTEM_JOBPOSITIONINPHASE=1 DEBIAN_FRONTEND=noninteractive SYSTEM_JOBID=12f1170f-54f2-53f3-20dd-22fc7dff55f9 AGENT_JOBNAME=Job AGENT_ACCEPTTEEEULA=True SYSTEM_STAGEATTEMPT=1 SYSTEM_PIPELINESTARTTIME=2020-03-05 22:20:12+00:00 STACK_NAME=dev-agency-website BUILD_REPOSITORY_URI=https://github.com/pfeilbr/azure-pipelines-playground AGENT_READONLYVARIABLES=true BUILD_REPOSITORY_PROVIDER=GitHub SYSTEM_TASKINSTANCENAME=CmdLine GOROOT_1_12_X64=/usr/local/go1.12 GECKOWEBDRIVER=/usr/local/share/gecko_driver SYSTEM_PLANID=b5cbb7c3-6a1c-4c2f-85da-7cd89b56bfcc BUILD_DEFINITIONVERSION=13 TASK_DISPLAYNAME=deploy SYSTEM_HOSTTYPE=build CHROMEWEBDRIVER=/usr/local/share/chrome_driver BUILD_STAGINGDIRECTORY=/home/vsts/work/1/a MSDEPLOY_HTTP_USER_AGENT=VSTS_1cc55890-46d6-40c1-9714-8220ddd17bd5_build_1_0 BUILD_REQUESTEDFOREMAIL=brian.pfeil@gmail.com TF_BUILD=True AZURE_HTTP_USER_AGENT=VSTS_1cc55890-46d6-40c1-9714-8220ddd17bd5_build_1_0 BUILD_REPOSITORY_LOCALPATH=/home/vsts/work/1/s SYSTEM_PHASEDISPLAYNAME=Job BUILD_REPOSITORY_NAME=pfeilbr/azure-pipelines-playground BUILD_ARTIFACTSTAGINGDIRECTORY=/home/vsts/work/1/a SYSTEM_TASKDEFINITIONSURI=https://dev.azure.com/brianpfeil/ BUILD_REPOSITORY_GIT_SUBMODULECHECKOUT=False BUILD_SOURCEVERSIONAUTHOR=Brian Pfeil SYSTEM_TASKDISPLAYNAME=deploy SYSTEM_STAGENAME=__default VSTS_PROCESS_LOOKUP_ID=vsts_f104e61b-5db9-493c-8204-4ffeb8973a65 BUILD_REPOSITORY_ID=pfeilbr/azure-pipelines-playground BUILD_SOURCEVERSIONMESSAGE=output env variables SYSTEM=build SYSTEM_PHASEATTEMPT=1 VCPKG_INSTALLATION_ROOT=/usr/local/share/vcpkg SYSTEM_JOBNAME=__default REGION=us-east-1 SYSTEM_PHASEID=3a3a2a60-14c7-570b-14a4-fa42ad92f52a AGENT_MACHINENAME=fv-az755 COMMON_TESTRESULTSDIRECTORY=/home/vsts/work/1/TestResults agent.jobstatus=Succeeded JAVA_HOME_7_X64=/usr/lib/jvm/zulu-7-azure-amd64 BUILD_DEFINITIONNAME=pfeilbr.azure-pipelines-playground AWS_ACCESS_KEY_ID=AKIAXWO2SDPLDE43XM4W SYSTEM_ARTIFACTSDIRECTORY=/home/vsts/work/1/a SHLVL=2 BUILD_REQUESTEDFORID=5d5ba760-cdcf-6c15-8d80-c37de4cf7631 AGENT_NAME=Hosted Agent BUILD_BUILDNUMBER=20200305.5 BUILD_SOURCEBRANCHNAME=v0.0.1 SYSTEM_JOBDISPLAYNAME=Job BUILD_SOURCESDIRECTORY=/home/vsts/work/1/s LEIN_JAR=/usr/local/lib/lein/self-installs/leiningen-2.9.2-standalone.jar BUILD_BUILDURI=vstfs:///Build/Build/53 SYSTEM_SERVERTYPE=Hosted SYSTEM_TIMELINEID=b5cbb7c3-6a1c-4c2f-85da-7cd89b56bfcc AGENT_RETAINDEFAULTENCODING=false SYSTEM_TASKINSTANCEID=9c939e41-62c2-5605-5e05-fc3554afc9f5 SYSTEM_DEFAULTWORKINGDIRECTORY=/home/vsts/work/1/s AGENT_JOBSTATUS=Succeeded ANT_HOME=/usr/share/ant BUILD_REPOSITORY_CLEAN=False SYSTEM_TEAMPROJECT=project01 PATH=/usr/share/rust/.cargo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin SELENIUM_JAR_PATH=/usr/share/java/selenium-server-standalone.jar CHROME_BIN=/usr/bin/google-chrome SYSTEM_COLLECTIONID=1cc55890-46d6-40c1-9714-8220ddd17bd5 BUILD_CONTAINERID=5246219 SYSTEM_TEAMFOUNDATIONCOLLECTIONURI=https://dev.azure.com/brianpfeil/ GIT_TERMINAL_PROMPT=0 AGENT_BUILDDIRECTORY=/home/vsts/work/1 SYSTEM_STAGEID=96ac2280-8cb4-5df5-99de-dd2da759617d SYSTEM_ENABLEACCESSTOKEN=SecretVariable BUILD_BINARIESDIRECTORY=/home/vsts/work/1/b BUILD_BUILDID=53 ${BUILD_REPOSITORY_URI}/tree/${BUILD_SOURCEBRANCHNAME} ${BUILD_REPOSITORY_URI}/commit/${BUILD_SOURCEVERSION} # athena create table for CloudFront logs CREATE EXTERNAL TABLE IF NOT EXISTS default.cloudfront_logs_stagingallthecloudbits ( `date` DATE, time STRING, location STRING, bytes BIGINT, request_ip STRING, method STRING, host STRING, uri STRING, status INT, referrer STRING, user_agent STRING, query_string STRING, cookie STRING, result_type STRING, request_id STRING, host_header STRING, request_protocol STRING, request_bytes BIGINT, time_taken FLOAT, xforwarded_for STRING, ssl_protocol STRING, ssl_cipher STRING, response_result_type STRING, http_version STRING, fle_status STRING, fle_encrypted_fields INT, c_port INT, time_to_first_byte FLOAT, x_edge_detailed_result_type STRING, sc_content_type STRING, sc_content_len BIGINT, sc_range_start BIGINT, sc_range_end BIGINT ) ROW FORMAT DELIMITED FIELDS TERMINATED BY \u0026#39;\\t\u0026#39; LOCATION \u0026#39;s3://dev-agency-website-cloudfrontlogsbucket-jf9ykpajh7n1/cloudfront/logs/staging.allthecloudbits.com/\u0026#39; TBLPROPERTIES ( \u0026#39;skip.header.line.count\u0026#39;=\u0026#39;2\u0026#39; ) # query SELECT * FROM \u0026#34;default\u0026#34;.\u0026#34;cloudfront_logs_stagingallthecloudbits\u0026#34; limit 10 # CF dist WAF association myDistribution Type AWS::CloudFront::Distribution Properties: DistributionConfig: WebACLId: !Ref : MyWebACL # aws managed rule groups https://docs.aws.amazon.com/waf/latest/developerguide/aws-managed-rule-groups-list.html AWS::WAFv2::WebACL Type: AWS::WAFv2::WebACL Properties: Name: waf-webacl Scope: CLOUDFRONT Description: CloudFront WAF WebACL DefaultAction: Allow: {} VisibilityConfig: SampledRequestsEnabled: true CloudWatchMetricsEnabled: true MetricName: ExampleWebACLMetric Rules: - Name: RuleWithAWSManagedRules Priority: 0 OverrideAction: Count: {} VisibilityConfig: SampledRequestsEnabled: true CloudWatchMetricsEnabled: true MetricName: RuleWithAWSManagedRulesMetric Statement: ManagedRuleGroupStatement: VendorName: AWS Name: AWSManagedRulesCommonRuleSet ExcludedRules: [] ","permalink":"https://brianpfeil.com/post/azure-pipelines/","postedOnDate":" February 26, 2020","tags":["azure"],"title":"Azure Pipelines"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/flask-playground  flask-playground learn flask, the python web application framework\n server.py - flask server client.py - http client. uses requests to POST the image.jpeg image file load-test.sh - load test via parallel requests  Prerequisites  pipenv for python environment/packages  Running # install all dependencies pipenv install --dev # load python enviroment pipenv shell # run server in debug (livereload - reload on file changes) mode FLASK_DEBUG=1 FLASK_RUN_PORT=5000 FLASK_APP=server.py flask run # run client python client.py # load test chmod +x load-test.sh ./load-test.sh ","permalink":"https://brianpfeil.com/post/flask/","postedOnDate":" February 15, 2020","tags":["flask"],"title":"Flask"},{"categories":["Shell","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/bash-script-date-and-time-playground  examples of working with formatted dates in bash including time operations such as adding time\nsee main.sh\nRunning chmod a+x main.sh fswatch -o main.sh | xargs -n1 -I{} sh main.sh ","permalink":"https://brianpfeil.com/post/bash-script-date-and-time/","postedOnDate":" February 10, 2020","tags":["bash"],"title":"Bash Script Date and Time"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/multipass-playground  learn multipass - command line interface to launch, manage and generally fiddle about with instances of Linux\n multipass | docs Working with Multipass instances  Session # install brew cask install multipass # set to use virtualbox instead of hyperkit, which is the default on macOS (ran into issues with hyperkit) sudo multipass set local.driver=virtualbox # launch default ubuntu instance multipass launch # set the primary instance. if you don\u0026#39;t specify the instance a command, this is the instance used multipass set client.primary-name=capital-tapir # list instances multipass ls # open shell (uses ssh under the covers) multipass shell # execute command and exit multipass exec capital-tapir -- ls # mount local host folder into instance # /Users/pfeilbr/tmp (host) =\u0026gt; /Users/pfeilbr/tmp (instance) multipass mount ~/tmp capital-tapir # unmount mounts multipass unmount capital-tapir # list info about instance multipass info capital-tapir multipass suspend capital-tapir multipass restart capital-tapir multipass stop capital-tapir multipass delete capital-tapir # purge all deleted instances permanently multipass purge ","permalink":"https://brianpfeil.com/post/multipass/","postedOnDate":" February 9, 2020","tags":["linux","virtualization"],"title":"Multipass"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/python-async-await-playground  learn python async await\nPrerequisites  Pipenv  Running  git clone pipenv install pipenv run python main.py  ","permalink":"https://brianpfeil.com/post/python-async-await/","postedOnDate":" February 5, 2020","tags":["python"],"title":"Python Async Await"},{"categories":["CSS","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/tailwindcss-playground  learn tailwindcss\nResources  https://dev.to/hagnerd/setting-up-tailwind-with-create-react-app-4jd    create-react-app README.md below\n  This project was bootstrapped with Create React App.\nAvailable Scripts In the project directory, you can run:\nyarn start Runs the app in the development mode.\nOpen http://localhost:3000 to view it in the browser.\nThe page will reload if you make edits.\nYou will also see any lint errors in the console.\nyarn test Launches the test runner in the interactive watch mode.\nSee the section about running tests for more information.\nyarn build Builds the app for production to the build folder.\nIt correctly bundles React in production mode and optimizes the build for the best performance.\nThe build is minified and the filenames include the hashes.\nYour app is ready to be deployed!\nSee the section about deployment for more information.\nyarn eject Note: this is a one-way operation. Once you eject, you can’t go back!\nIf you aren’t satisfied with the build tool and configuration choices, you can eject at any time. This command will remove the single build dependency from your project.\nInstead, it will copy all the configuration files and the transitive dependencies (Webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except eject will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.\nYou don’t have to ever use eject. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.\nLearn More You can learn more in the Create React App documentation.\nTo learn React, check out the React documentation.\nCode Splitting This section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting\nAnalyzing the Bundle Size This section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size\nMaking a Progressive Web App This section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app\nAdvanced Configuration This section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration\nDeployment This section has moved here: https://facebook.github.io/create-react-app/docs/deployment\nyarn build fails to minify This section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify\n","permalink":"https://brianpfeil.com/post/tailwindcss/","postedOnDate":" January 16, 2020","tags":["css","framework"],"title":"TailwindCSS"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/go-modules-playground  learn using golang modules\nResources  https://blog.golang.org/using-go-modules golang/go/wiki/Modules  Session # run tests recursively on change fswatch -o . | xargs -n1 -I{} go test -v ./... # run main on change fswatch -o . | xargs -n1 -I{} go run main.go ","permalink":"https://brianpfeil.com/post/go-modules/","postedOnDate":" January 15, 2020","tags":["golang"],"title":"Go Modules"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/go-sdl2-playground  learn go-sdl2, the SDL2 wrapped for Go users\nResources  veandco/go-sdl2-examples  ","permalink":"https://brianpfeil.com/post/go-sdl2/","postedOnDate":" January 13, 2020","tags":["golang"],"title":"Go SDL2"},{"categories":["Makefile","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/make-playground  learn make\nResources  GNU make manual The GNU Make Book purpose of .PHONY  # run `make` whenever Makefile changes fswatch -o Makefile | xargs -n1 -I{} make ","permalink":"https://brianpfeil.com/post/make/","postedOnDate":" January 13, 2020","tags":["make"],"title":"Make"},{"categories":["C++","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/googletest-playground  learn Googletest, Google Testing and Mocking Framework with CMake\nbased on https://raymii.org/s/tutorials/Cpp_project_setup_with_cmake_and_unit_tests.html\n# begin: one-time setup to add googletest dependency mkdir lib pushd lib git clone https://github.com/google/googletest/ popd # end: one-time setup #clean ./run.sh clean # build ./run.sh buildandtest # run tests ./run.sh test # build and run tests when file changes under src/ and tst/ ./run.sh watch # build main binary ./run.sh buildmain # run main binary ./run.sh main googletest command line examples # run all tests ./build/tst/app_tst # list tests ./build/tst/app_tst --gtest_list_tests # run specific test ./build/tst/app_tst --gtest_filter=MyLib.adhoc # run all tests in MyLib ./build/tst/app_tst --gtest_filter=\u0026#39;MyLib.*\u0026#39; # list command line options ./build/tst/app_tst --help ","permalink":"https://brianpfeil.com/post/googletest/","postedOnDate":" January 2, 2020","tags":["testing","cpp"],"title":"Googletest"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/react-bootstrap-playground  Available Scripts In the project directory, you can run:\nyarn start Runs the app in the development mode.\nOpen http://localhost:3000 to view it in the browser.\nThe page will reload if you make edits.\nYou will also see any lint errors in the console.\nyarn test Launches the test runner in the interactive watch mode.\nSee the section about running tests for more information.\nyarn build Builds the app for production to the build folder.\nIt correctly bundles React in production mode and optimizes the build for the best performance.\nThe build is minified and the filenames include the hashes.\nYour app is ready to be deployed!\nSee the section about deployment for more information.\nyarn eject Note: this is a one-way operation. Once you eject, you can’t go back!\nIf you aren’t satisfied with the build tool and configuration choices, you can eject at any time. This command will remove the single build dependency from your project.\nInstead, it will copy all the configuration files and the transitive dependencies (Webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except eject will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.\nYou don’t have to ever use eject. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.\nLearn More You can learn more in the Create React App documentation.\nTo learn React, check out the React documentation.\nCode Splitting This section has moved here: https://facebook.github.io/create-react-app/docs/code-splitting\nAnalyzing the Bundle Size This section has moved here: https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size\nMaking a Progressive Web App This section has moved here: https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app\nAdvanced Configuration This section has moved here: https://facebook.github.io/create-react-app/docs/advanced-configuration\nDeployment This section has moved here: https://facebook.github.io/create-react-app/docs/deployment\nyarn build fails to minify This section has moved here: https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify\n","permalink":"https://brianpfeil.com/post/react-bootstrap/","postedOnDate":" December 29, 2019","tags":["react"],"title":"React Bootstrap"},{"categories":["C","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/glib-playground  learn GNOME | GLib\nsee main.c\nPrerequisites brew install cmake brew install glib brew install pkg-config Build and Run mkdir -p build \u0026amp;\u0026amp; cd build cmake .. \u0026amp;\u0026amp; make # run ./glib-playground output\nResources  Manage C data using the GLib collections GNOME | GLib GNOME/glib repo  ","permalink":"https://brianpfeil.com/post/glib/","postedOnDate":" November 11, 2019","tags":["graphics","cpp"],"title":"GLib"},{"categories":["HCL","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/terraform-playground  learn and experiment with Terraform\nfollowed Packer GETTING STARTED docs\n  Execution Plans - describing what it will do and asks for your approval before making any infrastructure changes. This allows you to review changes before Terraform creates, updates, or destroys infrastructure. Resource Graph - Terraform builds a resource graph and creates or modifies non-dependent resources in parallel.  Resources  represent infrastructure objects each resource type is implemented by a provider, which is a plugin for Terraform that offers a collection of resource types Meta-Arguments  depends_on count - creates that many instances of the resource or module for_each - value is a map or a set of strings, Terraform will create one instance for each member of that map or set provider - use to override tf default provider. e.g. you want to change the region for a given resource lifecycle provisioner and connection    Syntax resource TYPE NAME { BODY }  Data Sources  Terraform Language  use hcl or json to declare Blocks - containers for other content and usually represent the configuration of some kind of object Arguments - assign a value to a name Expressions - represent a value, either literally or by referencing and combining other values   State  by default state is stored locally in *.tfstate file (the default backend) when multiple people or clients are collaborating on infra via tf, state can be stored in a remote backend  e.g. state for aws can be stored in S3 and a dynamodb table is used for locking when the state is shared amongst many people and/or systems  terraform { backend \u0026#34;s3\u0026#34; {# Replace this with your bucket name!  bucket = \u0026#34;terraform-up-and-running-state\u0026#34; key = \u0026#34;global/s3/terraform.tfstate\u0026#34; region = \u0026#34;us-east-2\u0026#34;# Replace this with your DynamoDB table name!  dynamodb_table = \u0026#34;terraform-up-and-running-locks\u0026#34; encrypt = true } }  Workspaces - allow you to store your Terraform state in multiple, separate, named workspaces  CLI # plan terraform plan # apply terraform apply -auto-approve # validate terraform validate # show outputs terraform output Resources  Terraform Language Documentation Terraform | AWS Provider Docs Terraform Registry  ","permalink":"https://brianpfeil.com/post/terraform/","postedOnDate":" November 5, 2019","tags":["infrastructure-as-code","aws"],"title":"Terraform"},{"categories":["Java","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/serverless-lambda-java-playground  serverless framework + lambda java\nBuild and Deploy cd ~/projects/serverless-lambda-java-playground serverless create --template aws-java-maven mvn clean install sls deploy --verbose sls invoke --function hello --data \u0026#39;{\u0026#34;msg\u0026#34;: \u0026#34;hello\u0026#34;}\u0026#39; --log { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;message\\\u0026#34;:\\\u0026#34;Go Serverless v1.x! Your function executed successfully!\\\u0026#34;,\\\u0026#34;input\\\u0026#34;:{}}\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;X-Powered-By\u0026#34;: \u0026#34;AWS Lambda \u0026amp; serverless\u0026#34; }, \u0026#34;isBase64Encoded\u0026#34;: false } Resources  How to create a REST API in Java using DynamoDB and Serverless  ","permalink":"https://brianpfeil.com/post/serverless-lambda-java/","postedOnDate":" October 27, 2019","tags":["serverless","lambda","java"],"title":"Serverless Lambda Java"},{"categories":["PHP","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/wordpress-playground  learn and experiment with all things WordPress and WordPress VIP (aka Enterprise WordPress)\nRunning using Docker Compose # ensure docker is up and running # start docker-compose up -d # admin ui (login: admin/password01) open http://localhost:8000/wp-admin # site open http://localhost:8000 # root rest api routes curl http://localhost:8000/index.php?rest_route=/ | jq \u0026#39;.\u0026#39; # rest api routes curl http://localhost:8000/\\?rest_route\\=/wp/v2 | jq \u0026#39;.\u0026#39; # rest api posts example curl http://localhost:8000/?rest_route=/wp/v2/posts | jq \u0026#39;.\u0026#39; # stop docker-compose down  Extending WP REST API | Adding Custom Endpoints | Custom Plugin Example based on Adding Custom Endpoints\n  create wp-root/wp-content/plugins/myplugin.php\n if needed, copy to \u0026ldquo;live\u0026rdquo; plugins directory\n cp wp-root/wp-content/plugins/myplugin.php html/wp-content/plugins/myplugin.php   activate via Admin | Plugins   access custom endpoint http://localhost:8000/index.php?rest_route=/myplugin/v1/author/1    Running using VVV (Varying Vagrant Vagrants) Setup  install System Requirements execute Installation steps  Running root directory path ~/vagrant-local\n  vagrant up\n  add VirtualBox port mappings 0.0.0.0:80 -\u0026gt; 80   update /etc/hosts to point to 127.0.0.1\nsudo sed -i.bu 's/192.168.50.4/127.0.0.1/g' /etc/hosts   visit http://vvv.test\n   Shouldn\u0026rsquo;t need to do the /etc/hosts and VirtualBox port mapping steps. This is a workaround to deal with an iss where macOS ignores the entries added by the vagrant-hostsupdater plugin in /etc/hosts file.\n stopping  vagrant halt  this removes /etc/hosts entries\n    Changes Allow logging in to a WP VIP site (e.g. http://WP-VIP-SITE/wp-admin) with admin / password. changed wpcom_vip_is_restricted_username @ WP-VIP-SITE/public_html/wp-content/mu-plugins/security.php to\nfunction wpcom_vip_is_restricted_username( $username ) { // return \u0026#39;admin\u0026#39; === $username \t// || WPCOM_VIP_MACHINE_USER_LOGIN === $username \t// || WPCOM_VIP_MACHINE_USER_EMAIL === $username; \treturn false; } Remove VIP_MAINTENANCE_MODE not defined error message showing in wp-admin and site UIs added the following to WP-VIP-SITE/public_html/wp-content/client-mu-plugins/plugin-loader.php to get rid of VIP_MAINTENANCE_MODE not defined error message showing in wp-admin and site UIs.\ndefine( \u0026#39;VIP_MAINTENANCE_MODE\u0026#39;, false );  Resources  Quickstart: Compose and WordPress WordPress VIP Documentation WordPress | REST API Handbook Block Editor Handbook WordPress/gutenberg  packages/block-library - Block library for the WordPress editor.   WordPress Storybook site developer.wordpress.org codex.wordpress.org Adding Custom Endpoints WPGraphQL - graphql API for WP Automattic/vip-go-mu-plugins - The development repo for mu-plugins used on the VIP Go platform. Automattic/vip-go-mu-plugins-built - The generated repo for mu-plugins used on the VIP Go platform Theme Handbook / Advanced Theme Topics / Child Themes  ","permalink":"https://brianpfeil.com/post/wordpress/","postedOnDate":" October 22, 2019","tags":["wordpress"],"title":"Wordpress"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-control-tower-playground  learn AWS Control Tower\n AWS Control Tower provides the easiest way to set up and govern a secure, compliant, multi-account AWS environment based on best practices established by working with thousands of enterprises. With AWS Control Tower, end users on your distributed teams can provision new AWS accounts quickly. Meanwhile your central cloud administrators will know that all accounts are aligned with centrally established, company-wide compliance policies.\n  Notes Control Tower is the composition of many AWS services\n AWS SSO - integrated with Microsoft AD on-prem and cloud/azure Organizations  Service Control Policies - central control over the maximum available permissions for all accounts in your organization, allowing you to ensure your accounts stay within your organization’s access control guidelines   Guardrails - two kinds of guardrails exist: preventive (block) and detective (after the fact notification of non-compliance)  implemented as AWS Config - monitor for compliance   Service Catalog - self-service provisioning of cloud products AWS landing zone is a solution that helps customers more quickly set up a secure, multi-account AWS environment based on AWS best practices.  Resources  AWS Control Tower Documentation AWS re:Inforce 2019: Using AWS Control Tower to Govern Multi-Account AWS Environments (GRC313-R) (video) Using AWS Control Tower to govern multi-account AWS environments at scale - GRC313-R - AWS re:Inforce 2019(slides) AWS Control Tower is now generally available  ","permalink":"https://brianpfeil.com/post/aws-control-tower/","postedOnDate":" October 17, 2019","tags":["aws"],"title":"AWS Control Tower"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-serverless-application-repository-playground  learn AWS Serverless Application Repository\nExample using SAM CLI # define deployment bucket BUCKET=\u0026#34;sam-deploy-bucket-01\u0026#34; # init sam app sam init --runtime nodejs cd sam-app # \u0026#34; create a Lambda deployment package\u0026#34;. # add Metadata section to `template.yml`. see https://docs.aws.amazon.com/en_pv/serverlessrepo/latest/devguide/serverlessrepo-quick-start.html#serverlessrepo-quick-start-hello-world-package-app # package sam package \\  --template-file template.yaml \\  --output-template-file packaged.yaml \\  --s3-bucket $BUCKET # publish to SAR. will be private by default sam publish \\  --template packaged.yaml \\  --region us-east-1 # create SAM app to consume SAR (embedded SAR) # embed SAR (`Type: AWS::Serverless::Application`) in template. see https://docs.aws.amazon.com/en_pv/serverless-application-model/latest/developerguide/serverless-sam-template.html#serverless-sam-template-application touch embed-serverless-application.yaml # package embedded app sam package \\  --template-file embed-serverless-application.yaml \\  --output-template-file embed-serverless-application-packaged.yaml \\  --s3-bucket $BUCKET # define name for stack STACK_NAME=\u0026#34;embed-serverless-application\u0026#34; # deploy embedded app. note usage of `CAPABILITY_AUTO_EXPAND` param sam deploy --template-file ./embed-serverless-application-packaged.yaml --stack-name \u0026#34;$STACK_NAME\u0026#34; --capabilities CAPABILITY_IAM CAPABILITY_AUTO_EXPAND # two stacks are created. the parent (sam-app/embed-serverless-application-packaged.yaml) and the emb embedded SAR (packaged.yaml) # cleanup / remove stack(s) aws cloudformation delete-stack --stack-name \u0026#34;$STACK_NAME\u0026#34; SAR App in Console\nNested CFN Stacks\n Example using aws serverlessrepo CLI  can also be done (and is preferred) via sam cli. see above.\n mkdir sar-cli-example cd sar-cli-example APP_NAME=myapp01 aws serverlessrepo list-applications # create appliction aws serverlessrepo create-application \\ --author \u0026#39;Brian Pfeil\u0026#39; \\ --description $APP_NAME \\ --name $APP_NAME \\ --semantic-version 0.0.1 \\ --template-body file://./s3-bucket-template.yaml # fetch ApplicationId APP_ID=$(aws serverlessrepo list-applications | jq --raw-output \u0026#34;.Applications[] | select(.Name == \\\u0026#34;$APP_NAME\\\u0026#34;).ApplicationId\u0026#34;) # create request to create cfn template (async operation) TEMPLATE_ID=$(aws serverlessrepo create-cloud-formation-template --application-id \u0026#34;$APP_ID\u0026#34; | jq --raw-output \u0026#34;.TemplateId\u0026#34;) # fetch the cfn template TEMPLATE_URL=$(aws serverlessrepo get-cloud-formation-template --application-id \u0026#34;$APP_ID\u0026#34; --template-id \u0026#34;$TEMPLATE_ID\u0026#34; | jq --raw-output \u0026#34;.TemplateUrl\u0026#34;) # view cfn template curl \u0026#34;$TEMPLATE_URL\u0026#34; # delete app aws serverlessrepo delete-application --application-id \u0026#34;$APP_ID\u0026#34; ","permalink":"https://brianpfeil.com/post/aws-serverless-application-repository/","postedOnDate":" October 14, 2019","tags":["aws","serverless"],"title":"AWS Serverless Application Repository"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/stackery-playground  learn stackery. Project based on Stackery Quickstart NodeJS.\nComments (as of 2019-10-09)  competes with serverless dashboard. many of the same features. secrets service, environment management, team/collaboration support says it supports serverless framework (serverless.yml), but SAM seems to be the first class citizen. SAM since its based on CF, lags behind in feature support over serverless. Serverless fills the gaps with custom plugins. installs a stack (roles, buckets, CodeBuild project, lambdas, SNS topics, etc.) into your account to link your aws account to the stackery SaaS service. the stackery cli feels heavy due to the number of flags and arguments you need to supply. e.g. always specifying env and aws profile. documentation feels a bit all over the place. this may be because the tool doesn\u0026rsquo;t have strong opinions and is favoring flexibility.  Prerequisites  docker  Session # ensure docker is running # install brew tap stackery/tap brew install stackery-cli stackery login # init stackery init -n stackery-quickstart # visual editor stackery edit # deploy stackery deploy --interactive-setup # cd to function directory cd src/get # invoke stackery local invoke -e pfeilbr-development --aws-profile admin Stackery editor that generates cloudformation (template.yml) or serverless framework (serverless.yml).\nThere is a \u0026ldquo;link your AWS account with Stackery\u0026rdquo; one time setup.\nCreates CF Stack for initial setup. Includes Roles, Bucket, CodeBuild, Lambdas, SNS. Roles created during one time setup Resources  Stackery Quickstart NodeJS Stackery Documentation  ","permalink":"https://brianpfeil.com/post/stackery/","postedOnDate":" October 9, 2019","tags":["infrastructure-as-code","aws"],"title":"Stackery"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-cognito-developer-authenticated-identities-playground  learn Developer Authenticated Identities (Identity Pools)\n With developer authenticated identities, you can register and authenticate users via your own existing authentication process, while still using Amazon Cognito to synchronize user data and access AWS resources.\n Example using AWS CLI   Add custom authentication provider (DEVELOPER_PROVIDER_NAME) to your identity pool via \u0026ldquo;Edit identity pool\u0026rdquo; UI\n  setup shell variables\nIDENTITY_POOL_ID=\u0026#34;us-east-1:335c1f44-87c9-4bbd-a314-93b47d91fadd\u0026#34; DEVELOPER_PROVIDER_NAME=com.brianpfeil.app01 # this is YOUR applications userid DEVELOPER_PROVIDER_USERID=003   create identity\naws cognito-identity get-open-id-token-for-developer-identity --identity-pool-id $IDENTITY_POOL_ID --logins \u0026#34;$DEVELOPER_PROVIDER_NAME=$DEVELOPER_PROVIDER_USERID\u0026#34; example output\n{ \u0026#34;Token\u0026#34;: \u0026#34;eyJraWQiOiJ1cy1lYXN0LTExIiwidHlwIjoiSldTIiwiYWxnIjoiUlM1MTIifQ.eyJzdWIiOiJ1cy1lYXN0LTE6YWVjYjU4YTgtMjc3Ni00NDMxLTk3OGMtZDYzOTVlMWI1Mzc5IiwiYXVkIjoidXMtZWFzdC0xOjMzNWMxZjQ0LTg3YzktNGJiZC1hMzE0LTkzYjQ3ZDkxZmFkZCIsImFtciI6WyJhdXRoZW50aWNhdGVkIiwiY29tLmJyaWFucGZlaWwuYXBwMDEiLCJjb20uYnJpYW5wZmVpbC5hcHAwMTp1cy1lYXN0LTE6MzM1YzFmNDQtODdjOS00YmJkLWEzMTQtOTNiNDdkOTFmYWRkOjAwMyJdLCJpc3MiOiJodHRwczovL2NvZ25pdG8taWRlbnRpdHkuYW1hem9uYXdzLmNvbSIsImV4cCI6MTU2OTUyMzg3NSwiaWF0IjoxNTY5NTIyOTc1fQ.F6ST-AQWETHUAAR7JM-IU1ZIFLDEVL9ZBNM49WDOL_RXLLCYEY2KYUICHSGYLERD4WWLHWEJG-AOHFMMS0DUXT-UANA3BENUFFZWWSBAYVD0N2BHCLHZG7PURTRKRDN2XRFGDGQQ2PIMURMWAIPSB0ZCM-EXMSV-QAGOGKE5C2QR0P91BICL_LB1OQRTF9VXANPEMFFSAMZED776WHKR8ZMP7NTXZBMRE453QFW7VGVNKV3KJDTAKSRVZJS6YVW7BXY74_OQUJCFF9KWXJSMTEBNOIMHEFI3LJ25HSDDJ4LMLBGODD_ET4PPSUORIVLGW4UQ-7PJYHCAYTBDV0MXAQ\u0026#34;, \u0026#34;IdentityId\u0026#34;: \u0026#34;us-east-1:aecb58a8-2776-4431-978c-d6395e1b5379\u0026#34; }   get token\naws cognito-identity get-open-id-token-for-developer-identity --identity-pool-id $IDENTITY_POOL_ID --identity-id $IDENTITY_ID --logins \u0026#34;$DEVELOPER_PROVIDER_NAME=$DEVELOPER_PROVIDER_USERID\u0026#34; example output\n{ \u0026#34;Token\u0026#34;: \u0026#34;eyJraWQiOiJ1cy1lYXN0LTExIiwidHlwIjoiSldTIiwiYWxnIjoiUlM1MTIifQ.eyJzdWIiOiJ1cy1lYXN0LTE6YWVjYjU4YTgtMjc3Ni00NDMxLTk3OGMtZDYzOTVlMWI1Mzc5IiwiYXVkIjoidXMtZWFzdC0xOjMzNWMxZjQ0LTg3YzktNGJiZC1hMzE0LTkzYjQ3ZDkxZmFkZCIsImFtciI6WyJhdXRoZW50aWNhdGVkIiwiY29tLmJyaWFucGZlaWwuYXBwMDEiLCJjb20uYnJpYW5wZmVpbC5hcHAwMTp1cy1lYXN0LTE6MzM1YzFmNDQtODdjOS00YmJkLWEzMTQtOTNiNDdkOTFmYWRkOjAwMyJdLCJpc3MiOiJodHRwczovL2NvZ25pdG8taWRlbnRpdHkuYW1hem9uYXdzLmNvbSIsImV4cCI6MTU2OTUyNDg5OCwiaWF0IjoxNTY5NTIzOTk4fQ.S8JRKAALQZV0FT0GX6WDBE2EZUH2UPHIJLQ1AX9_PQBXLDM4V7UFFVUDXMHGHMZ2T4VMC6R2ILUJATYO05EIKB4HKWPEHSJWHAT8ZUQ9MRVEZ4KJFAY-7ER4LCGKN8MW-ZTZWQRPXUAYGP3RHQFYDV7FGJCJ3GE-MTTCBGXRAY_0H8NNOQE2F1WRO0KPE-Q-8GXF2P89WGFM9FAHZYOBV0FCZYOH8LCAZ7CKQJQ6FO8NYIAQDXDWFJM5-SLMPRYJLBIW88PBLO00ASOP5OGTHFD61JJCUUXFDRB6UTUGM-RUNILJRCTZB5_AB0FXS2YWAG2YZ3_JOFPWDLL-FNQ2UA\u0026#34;, \u0026#34;IdentityId\u0026#34;: \u0026#34;us-east-1:aecb58a8-2776-4431-978c-d6395e1b5379\u0026#34; }   get credentials\naws cognito-identity get-credentials-for-identity --identity-id $IDENTITY_ID --logins \u0026#34;cognito-identity.amazonaws.com=$TOKEN\u0026#34; example output\n{ \u0026#34;Credentials\u0026#34;: { \u0026#34;SecretKey\u0026#34;: \u0026#34;U6hHM5cdTBjcXG3hxb6VcIwkijvskj72M+81CHBi\u0026#34;, \u0026#34;SessionToken\u0026#34;: \u0026#34;AgoJb3JpZ2luX2VjEIv//////////wEaCXVzLWVhc3QtMSJHMEUCIBbT6h4a8ZGV4lCrmmTIulJJkG9PnVCx4Cy2ddoU06ROAiEAzFVPpVhXwV3HAqhif23WOyn7j6I3sH4oCJjV6xZdK/gq3wQIZBAAGgw1MjkyNzYyMTQyMzAiDL0IwoimnbzRFyLAAiq8BIZJyKSEKLiEYpr45CDmkze7rxFb15buX2/L/9RGiAEThi0SmPF4eq+92c3UAsV7gkqajqdYHTEkksErAHrEAyyxLg62X6csqcAUo2rxdjvcG020qAbIEQ4d9m7ZfdZtsb9ByedAHCeJBNpDuIxio7EZfnfB/CUzElgLhWBIsWp+/3xCLoT4D2ElkfmjFEQ2Or6Hy/vcSc+ypaHIaaDN7bRrUDfZDFGkJaypqg7TKfCz8W1NV8UGjkc03x3EtxEawHb9om8Nb6KjZOjRoZf9HL9U4BGaHGmkx2Jlp2VB5k2zZks5+u2udZYDyYCrKOT+9Af+4KAyMtfooBfmvkY+n1hoS/7bgW1NgOGTPOfO7oTbuBBwCdtdN5EdJGkWmQDF0//y/m37kv6aPGefyc8XPz2gK1insPp67J/S1mGpMkSgLMijw60JkY2JZLc1shZg8hNZjxCnLd+ADMwxj27/jro/vypng8bq/9zQHCQT0NrH3PUrvyYdDjXo/58DLYLb8hoQmHx0gMBACdmcL9f3v0mNdi0rPKFuOtxOw9Z136cotgZeeRiQvJeRATQ2c8rUNWM2O4duc9+0CxguDZlvLpo+p3XsOPD8Ti5BS89R2lIU0p8iiNhCdHbp41ISxEzYNG4kFjw6uLnHM7Icni98K+QRTNQTISPNZTLALCFRNGEHFTJ3T7SMY0MPLV1EF7MODNOWMTO9SFJP0ITA5RQ6VXWLN6PU8II2OGXUSTWU9VGWG+AYUOKS5AKOQ5JVMIWTTOWFORQBWWGQ8G2OBX9WQLE7KCJHV7PEEQX2Z7/IY9SHDLV1MNP7SQBPJKS+MPGCK+DLCL8ZBMJLZCEL4H7VMIV+9TMCPK9J3LADATRGXCFYXEMMXLXG0YIK8GBTLU8QRJFYKWEDMZHARZ8MGRIOT7I9RSI6DAIBKWRNSKJ/EWTI4AJNQJLIDUAMOPBUDIUSJQHA5/WQMHQHORMYEKTXZBC2+8VAGR+WGL2F48IDWFFGWI1FS7UK7OFR\u0026#34;, \u0026#34;Expiration\u0026#34;: 1569527701.0, \u0026#34;AccessKeyId\u0026#34;: \u0026#34;ASIAXWO2SDPLARQRZ55K\u0026#34; }, \u0026#34;IdentityId\u0026#34;: \u0026#34;us-east-1:aecb58a8-2776-4431-978c-d6395e1b5379\u0026#34; }  NOTE: --logins cognito-identity.amazonaws.com=. See https://aws.amazon.com/blogs/mobile/understanding-amazon-cognito-authentication-part-4-enhanced-flow/\n  When using an Amazon Cognito token with GetCredentialsForIdentity, you use the key cognito-identity.amazonaws.com in the logins parameter.\n   You can now use AccessKeyId, SecretKey, and SessionToken to access AWS resources.\n  Resources  Developer Authenticated Identities (Identity Pools) Understanding Amazon Cognito Authentication Part 2: Developer Authenticated Identities  ","permalink":"https://brianpfeil.com/post/aws-cognito-developer-authenticated-identities/","postedOnDate":" September 26, 2019","tags":["aws","cognito"],"title":"AWS Cognito Developer Authenticated Identities"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/gitlab-playground  learn gitlab. Uses GitLab CE Docker image to run locally\nBased on steps in docs @ GitLab Docker images\nmkdir ~/dev/gitlab # not ssh exposed on 2022 to not conflict with mac | System Prefs | Sharing | Remote Login sudo docker run --detach \\  --hostname gitlab.example.com \\  --publish 443:443 --publish 80:80 --publish 2022:22 \\  --name gitlab \\  --restart always \\  --volume ~/dev/gitlab/config:/etc/gitlab \\  --volume ~/dev/gitlab/logs:/var/log/gitlab \\  --volume ~/dev/gitlab/data:/var/opt/gitlab \\  gitlab/gitlab-ce:latest # ***NOTE*** can take up to 10 min to load # check logs via `sudo docker logs -f gitlab` or Kitematic UI | Container Logs open http://localhost # will need to set root password # login with username: root, password: YOUR_PASSWORD # add ssh key via User Settings | SSH Keys cat ~/.ssh/id_rsa.pub | pbcopy # create project in UI (`project01`) # note port 2022 git clone ssh://git@localhost:2022/root/project01.git # stopping sudo docker stop gitlab  Container Logs via Kitematic UI Project view ","permalink":"https://brianpfeil.com/post/gitlab/","postedOnDate":" September 18, 2019","tags":["gitlab"],"title":"Gitlab"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/serverless-lambda-layers-playground  learn lambda layers with serverless framework\nRunning see serverless.yml and index.js\n layers are applied in order, meaning last layer in array is applied last and will overwrite any common files in other layers.\n # install deps npm i # run via local packages sls npm run sls -- deploy # invoke and view logs npm run sls -- invoke --function hello --log Resources  serverless docs | AWS - Layers Part 2 — Create Lambda Layers with Serverless Framework and Offline support  ","permalink":"https://brianpfeil.com/post/serverless-lambda-layers/","postedOnDate":" September 18, 2019","tags":["serverless","lambda"],"title":"Serverless Lambda Layers"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-service-catalog-playground  learn aws service catalog\n  aws-service-catalog-playground  Concepts Service Catalog Pipeline CloudFormation Support  Provision a Service Catalog Product Instance using CloudFormation Composing Solutions with AWS Service Catalog Provisioned Products   Example Use Case | Static Website Resources     Concepts  products are cloudformation templates portfolio is collection of products  access to portfolios is via IAM users, groups, roles   IT administrator creates products and portfolios and grants access End user accesses products and deploys them example use cases: approved self-service products from Solution Factory  e.g. static web site. S3 + CloudFormation + WAF + ACM (certificate) + Route 53 (hosted zone, domain) e.g. Oracle RDS DB with all security, tags, etc. in place   Service Actions - enable end users to perform operational tasks, troubleshoot issues, run approved commands, or request permissions in AWS Service Catalog via SSM docs. can include/reference existing product(s) in your product cloudformation template. This enables modular composition and nesting.   Service Catalog Pipeline Service catalog can be used to deliver products to all spoke accounts in an org.\nCentral hub account that provisions AWS Service Catalog Products into spoke accounts on your behalf\n CloudFormation Support Service Catalog resources can be created using CloudFormation. See AWS Service Catalog resource type reference.\nProvision a Service Catalog Product Instance using CloudFormation You can provision a Service Catalog Product using the AWS::ServiceCatalog::CloudFormationProvisionedProduct resource type.\nFor example, if you have a service catalog product named MyProduct you can provision an instance of it using the following cfn.\nAWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Description:My Service Catalog Provisioned ProductResources:MyProvisionedProduct:Type:AWS::ServiceCatalog::CloudFormationProvisionedProductProperties:ProductName:MyProductProvisioningArtifactName:\u0026#39;1.0\u0026#39;ProvisioningParameters:-Key:param1Value:\u0026#34;param1value\u0026#34;-Key:param2Value:\u0026#34;param2Value\u0026#34;Composing Solutions with AWS Service Catalog Provisioned Products  AWS Service Catalog now supports obtaining outputs from a Service Catalog provisioned product in an AWS CloudFormation template. Product outputs provide the interface from one product to another. With this new feature, administrators and developers can easily refer to those outputs in order to combine the products needed for their applications, which saves time building applications that use more than one product, such as a three-tier web application.\n  Provisioned product outputs are now available in AWS Service Catalog. Enabled via AWS::ServiceCatalog transform  Example cfn from docs\n// Example 1AWSTemplateFormatVersion:2010-09-09Transform:\u0026#39;AWS::ServiceCatalog\u0026#39;Resources:ExampleParameter:Type:\u0026#39;AWS::SSM::Parameter\u0026#39;Properties:Type:StringValue:\u0026#39;[[servicecatalog:provisionedproduct:SampleProvisionedProduct:SampleOutputKey]]\u0026#39;// Example 2AWSTemplateFormatVersion:2010-09-09Transform:\u0026#39;AWS::ServiceCatalog\u0026#39;Resources:ExampleParameter:Type:\u0026#39;AWS::SSM::Parameter\u0026#39;Properties:Type:StringValue:\u0026#39;[[servicecatalog:provisionedproduct:SampleProvisionedProduct:SampleOutputKey]]\u0026#39;// Example 3AWSTemplateFormatVersion:2010-09-09Transform:AWS::ServiceCatalogResources:ExampleParameter:Type:\u0026#39;AWS::SSM::Parameter\u0026#39;Properties:Type:StringValue:\u0026#34;[[servicecatalog:provisionedproduct:SampleProvisionedProduct:SampleOutputKey]]\u0026#34;// Example 4AWSTemplateFormatVersion:2010-09-09Transform:AWS::ServiceCatalogResources:ExampleParameter:Type:\u0026#39;AWS::SSM::Parameter\u0026#39;Properties:Type:StringValue:\u0026gt;-[[servicecatalog:provisionedproduct:SampleProvisionedProduct:SampleOutputKey]]// Example 5AWSTemplateFormatVersion:2010-09-09Transform:AWS::ServiceCatalogResources:ExampleParameter2:Type:\u0026#39;AWS::SSM::Parameter\u0026#39;Properties:Type:StringValue:[[servicecatalog:provisionedproduct:SSMProductProvisionedProduct:SampleOutputKey]] Example Use Case | Static Website The following is a simple example of a \u0026ldquo;Static Website\u0026rdquo; product for the service catalog. It\u0026rsquo;s an S3 bucket with website enabled for it. This product is purposely kept simple to keep the focus on Service Catalog, but a product can be make up of anything that can be expressed via a CloudFormation template.\n Define Launch Constraint\nthe IAM role the cloudformation stack provisioning runs under\n Allows you to assign an IAM role that is used to provision the resources at launch, so you can restrict user permissions without impacting users' ability to provision products from the catalog.\n Launch constraint for a product must be added at Portfolio level\nsee AWS Service Catalog Launch Constraints\nAssign Users, Groups, Roles for Portfolio\nEnd User Provisioning\nConstraint Types\nTemplate constraints allow you to limit/constrain CloudFormation template parameters. see AWS Service Catalog Template Constraints\nCloudFormation Outputs\nEnd User Provisioned Products List\nAdmin add new product version\nEnd user Update Provisioned Product\nEnd user view Resource changes\nEnd user provisioning update\nS3 static website hosting routing rules added (the update)\n\u0026ldquo;Backing\u0026rdquo; CloudFormation Stack Details\n Resources  AWS Service Catalog | AWS Management \u0026amp; Governance Blog - all aws blogs posts tagged with \u0026ldquo;AWS Service Catalog\u0026rdquo; AWS Service Catalog Documentation service-catalog-tools-workshop.com/ aws-samples/aws-service-catalog-reference-architectures AWS Service Catalog - Getting Started Simplify sharing your AWS Service Catalog portfolios in an AWS Organizations setup | Amazon Web Services AWS re:Invent 2018: Streamlining Application Development with AWS Service Catalog (DEV328) AWS CloudFormation support for AWS Service Catalog products GitHub - AlexRex/cdk-service-catalog: Showcase how to do a service catalog using CDK Standardize compliance in AWS using DevOps and a Cloud Center of Excellence (CCOE) approach | Amazon Web Services - example pipeline to delivery service catalog portfolio across all accounts in org. local evernote search tag:service-catalog  ","permalink":"https://brianpfeil.com/post/aws-service-catalog/","postedOnDate":" September 10, 2019","tags":["aws"],"title":"AWS Service Catalog"},{"categories":["CSS","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/serverless-plugin-cloudfront-lambda-edge-playground  learn silvermine/serverless-plugin-cloudfront-lambda-edge\nvisit https://d3cztrjc4xcpde.cloudfront.net and login with user01/password01\nBasic Auth Challenge\nusername: user01 password: password01 users are stored in aws secrets manager and sourced from users.json\nUsage # deploy all (provision infra, build static site, copy to s3, invalidate cache). npm run deploy # separate component deploys npm run deploy-infrastructure npm run build-static-site # gatsby npm run publish-static-assets-to-bucket npm run cloudfront:invalidate # bucket # not accessible because of Origin Access Identity applied # e.g. http://s3-cf-private-static-site-01-dev.s3-website-us-east-1.amazonaws.com open \u0026#34;http://$(node scripts/get-stack-property.js WebsiteBucketName).s3-website-us-east-1.amazonaws.com/index.html\u0026#34; # cloudfront url. e.g. https://d3cztrjc4xcpde.cloudfront.net open \u0026#34;https://$(node scripts/get-stack-property.js CloudFrontDistributionDomainName)\u0026#34; Removing Auth Update CloudFront Behavior to remove \u0026ldquo;Viewer Request\u0026rdquo; \u0026ldquo;Lambda Function Association\u0026rdquo;, then invalidate cache on all \u0026ldquo;*\u0026rdquo;.\nViewing CloudWatch Logs for Lambda@Edge Functions logging takes place in the region of the edge (PoP) location. This will vary based on the client location.\nVisit CloudFront | Monitoring | Lambda@Edge Functions | YOUR FUNCTION, then click [View Function Metrics] button\nsee Determining the Lambda@Edge Region for more details\nLambda@Edge Request { \u0026#34;event\u0026#34;: { \u0026#34;Records\u0026#34;: [ { \u0026#34;cf\u0026#34;: { \u0026#34;config\u0026#34;: { \u0026#34;distributionDomainName\u0026#34;: \u0026#34;d13ydba49ilc9v.cloudfront.net\u0026#34;, \u0026#34;distributionId\u0026#34;: \u0026#34;E20V9SS2N0VT6P\u0026#34;, \u0026#34;eventType\u0026#34;: \u0026#34;viewer-request\u0026#34;, \u0026#34;requestId\u0026#34;: \u0026#34;NcxNfOh2NaptKOLBlSimVF7AAlRp10OM-F1-CMZsJOGSMEkHUVd25A==\u0026#34; }, \u0026#34;request\u0026#34;: { \u0026#34;clientIp\u0026#34;: \u0026#34;100.11.96.70\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;host\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;Host\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;d13ydba49ilc9v.cloudfront.net\u0026#34; } ], \u0026#34;user-agent\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;User-Agent\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36\u0026#34; } ], \u0026#34;authorization\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;authorization\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;Basic dXNlcjpwYXNz\u0026#34; } ], \u0026#34;upgrade-insecure-requests\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;upgrade-insecure-requests\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;1\u0026#34; } ], \u0026#34;sec-fetch-mode\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;sec-fetch-mode\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;navigate\u0026#34; } ], \u0026#34;sec-fetch-user\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;sec-fetch-user\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;?1\u0026#34; } ], \u0026#34;accept\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;accept\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\u0026#34; } ], \u0026#34;sec-fetch-site\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;sec-fetch-site\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;none\u0026#34; } ], \u0026#34;accept-encoding\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;accept-encoding\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;gzip, deflate, br\u0026#34; } ], \u0026#34;accept-language\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;accept-language\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;en-US,en;q=0.9,nb;q=0.8,fr;q=0.7\u0026#34; } ], \u0026#34;if-none-match\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;if-none-match\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\\\u0026#34;2cad58ac06c32be3c6384050881bc507\\\u0026#34;\u0026#34; } ], \u0026#34;if-modified-since\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;if-modified-since\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;Tue, 10 Sep 2019 21:32:57 GMT\u0026#34; } ] }, \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;querystring\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;uri\u0026#34;: \u0026#34;/\u0026#34; } } } ] } } Resources  add origin access identity  see the following for cfn markup https://github.com/lroguet/amzn-cloudformation/blob/master/storage-content-delivery/static-website-with-cloudfront.yml Restricting Access to Amazon S3 Content by Using an Origin Access Identity   S3 Bucket | Granting Permission to an Amazon CloudFront Origin Identity  TODO  DNS (route 53)  Routing Traffic to an Amazon CloudFront Web Distribution by Using Your Domain Name. Covers [root|sub]domainsG see https://www.brautaset.org/articles/2017/route-53-cloudformation.html. Contains ApexRecordSet (example.com) and WwwRecordSet (www.example.com) Alias Resource Record Set for a CloudFront Distribution   update serverless.yml:iamRoleStatements with dynamic region, account id, and secretsmanager name  via serverless-pseudo-parameters plugin    Scratch $(node ./scripts/get-stack-property.js ) ","permalink":"https://brianpfeil.com/post/serverless-plugin-cloudfront-lambda-edge/","postedOnDate":" September 10, 2019","tags":["serverless","cloudfront","lambda"],"title":"Serverless Plugin CloudFront Lambda Edge"},{"categories":["CSS","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-amplify-console-playground  learn AWS Amplify Console\n AWS Amplify Console is a continuous delivery and hosting service for modern web applications. The AWS Amplify Console simplifies the deployment of your application front end and backend. Connect to your code repository and your front end and backend are deployed in a single workflow, on every code commit.\n Flow\n You specify a source (github, bitbucket, gitlab, S3, zip file upload). On code change (commit), it checks out the code to a CodeBuild project. Runs your build, test, [backend] deploy, etc. Deploys static web assets (.html, .js, .css, images) to S3 to be served with CloudFront Verifies deployment by visiting root site URL with various deveice form factors (iPhone, iPad, desktop) and taking screenshots.  Build settings are defined in amplify.yml. See Configuring Build Settings for YML Specification Syntax.\n set amplify service role. codebuild env will assume this role and commands will execute in this context. showing assumed role in codebuild env Update SAM deploy bucket policy to allow amplify service (amplify.amazonaws.com) to read/write to bucket. Custom Domain configuration\nApp running on custom domain https://amplify-master.minote.net/ Resources  Amplify Console | Getting Started aws-amplify/amplify-console  ","permalink":"https://brianpfeil.com/post/aws-amplify-console/","postedOnDate":" September 9, 2019","tags":["aws","amplify"],"title":"AWS Amplify Console"},{"categories":["HTML","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-polly-playground  learn aws polly text-to-speech (TTS)\nRunning based on https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/getting-started-browser.html#getting-started-browser-scenario\nupdate js code in polly.html with the following\nAWS.config.region = \u0026#39;\u0026lt;YOUR_REGION\u0026gt;\u0026#39;; AWS.config.credentials = new AWS.CognitoIdentityCredentials({ IdentityPoolId: \u0026#39;\u0026lt;YOUR_IDENTITY_POOL_ID\u0026gt;\u0026#39; }); open polly.html ","permalink":"https://brianpfeil.com/post/aws-polly/","postedOnDate":" September 6, 2019","tags":["aws","polly"],"title":"AWS Polly"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-delivlib-playground  learn aws-delivlib, which is a library that leverages AWS Cloud Development Kit (CDK) for defining continuous pipelines for building, testing and publishing code libraries through AWS CodeBuild and AWS CodePipeline.\nPrerequisites  pipeline source github repo must exist. (e.g. pfeilbr/aws-delivlib-playground) github personal access token must be stored in SSM Parameter named /com/brianpfeil/aws-delivlib-playground/github-personal-access-token   Running src/pipeline-hello-world is an example code pipeline where the source is this github repo (pfeilbr/aws-delivlib-playground). The source nodejs app is src/hello-world with jest tests.\nCode Pipeline\nsource -\u0026gt; build -\u0026gt; test (linux) -\u0026gt; test (windows)  If any of the tests (*.sh) in src/pipeline-hello-world/tests/ change, be sure to do a npm run build \u0026amp;\u0026amp; npm run cdk deploy. Internally uses assets.ZipDirectoryAsset from \u0026quot;@aws-cdk/assets\u0026quot; package.\n mkdir -p src/pipeline-hello-world cd src/pipeline-hello-world cdk init --language typescript # at this time, `aws-delivlib` is not using the most recent version of CDK # need to do the following # see https://github.com/aws/aws-cdk/issues/1733 npm remove aws-cdk @aws-cdk/core aws-delivlib npm i aws-cdk@0.24.1 -D npm i @aws-cdk/cdk@0.24.1 npm i aws-delivlib # for dev npm run watch # build npm run build # generate cfn to stdout npm run cdk synth # deploy stack npm run cdk deploy # make changes # build npm run build # diff npm run cdk diff # delete stack npm run cdk destroy  AWS Console | CodePipeline\nAWS Console | CloudFormation Stack ","permalink":"https://brianpfeil.com/post/aws-delivlib/","postedOnDate":" September 3, 2019","tags":["aws","continuous-delivery"],"title":"AWS Delivlib"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/drawio-playground  learn and store draw.io templates\nsee diagrams @ AWS Architecture Center for examples\n Scratchpad The scratchpad is a temporary working space for keeping commonly used shapes for easy access. See How to use the Scratchpad?\nexported aws-scratchpad @ aws-scratchpad-panel-export.xml.\n Note that the scratchpad is stored in the local storage of the browser, which means it\u0026rsquo;s contents are deleted if cookies are cleared. The scratchpad is automatically saved between each change.\n  You can export the scratchpad as a draw.io library from that dialog, if you want to store it more permanently or share it with others.\n ","permalink":"https://brianpfeil.com/post/drawio/","postedOnDate":" August 26, 2019","tags":["drawio"],"title":"Drawio"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/zipkin-playground  learn zipkin the distributed tracing system\nPrerequisites  docker  Running running zipkin server and viewing web ui\n# run zipkin server (NOTE: this is non-blocking and will return) docker run -d -p 9411:9411 openzipkin/zipkin # open zipkin web ui open http://localhost:9411/zipkin/ running a web app with frontend and backend the sends traces to zipkin server. see frontend.js for how code is instrumented to send traces to zipkin server.\n# download zipkin javascript example curl -LO https://github.com/openzipkin/zipkin-js-example/archive/master.zip unzip master.zip cd zipkin-js-example-master/web # install dependencies npm install # had to run the following also. this make be fixed npm install node-fetch # in `frontend.js` change `const {wrapAxios} = require(\u0026#34;zipkin-instrumentation-axiosjs\u0026#34;);` # to `const wrapAxios = require(\u0026#34;zipkin-instrumentation-axiosjs\u0026#34;);` # create bundle npm run browserify # run frontend and backend DEBUG=true npm start # open app. displays datetime and sends traces to zipkin sever. open http://localhost:8081 # now open zipkin web ui to view traces open http://localhost:9411/zipkin/ # click the [Find Traces] button view JSON trace data by clickint the [JSON] button [ { \u0026#34;traceId\u0026#34;: \u0026#34;9ee01dfbbba1a5f2\u0026#34;, \u0026#34;parentId\u0026#34;: \u0026#34;f107fa7e6a7f29db\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;15f42a92f26d5a19\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;SERVER\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;get /api\u0026#34;, \u0026#34;timestamp\u0026#34;: 1566397279334946, \u0026#34;duration\u0026#34;: 1509626, \u0026#34;localEndpoint\u0026#34;: { \u0026#34;serviceName\u0026#34;: \u0026#34;backend\u0026#34;, \u0026#34;ipv4\u0026#34;: \u0026#34;192.168.1.14\u0026#34; }, \u0026#34;tags\u0026#34;: { \u0026#34;http.path\u0026#34;: \u0026#34;/api\u0026#34;, \u0026#34;http.status_code\u0026#34;: \u0026#34;200\u0026#34; }, \u0026#34;shared\u0026#34;: true }, { \u0026#34;traceId\u0026#34;: \u0026#34;9ee01dfbbba1a5f2\u0026#34;, \u0026#34;parentId\u0026#34;: \u0026#34;f107fa7e6a7f29db\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;15f42a92f26d5a19\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;CLIENT\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;get\u0026#34;, \u0026#34;timestamp\u0026#34;: 1566397279301452, \u0026#34;duration\u0026#34;: 1542392, \u0026#34;localEndpoint\u0026#34;: { \u0026#34;serviceName\u0026#34;: \u0026#34;frontend\u0026#34; }, \u0026#34;tags\u0026#34;: { \u0026#34;http.path\u0026#34;: \u0026#34;/api\u0026#34;, \u0026#34;http.status_code\u0026#34;: \u0026#34;200\u0026#34; } }, { \u0026#34;traceId\u0026#34;: \u0026#34;9ee01dfbbba1a5f2\u0026#34;, \u0026#34;parentId\u0026#34;: \u0026#34;9ee01dfbbba1a5f2\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;f107fa7e6a7f29db\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;pay-me\u0026#34;, \u0026#34;timestamp\u0026#34;: 1566397279295227, \u0026#34;duration\u0026#34;: 1552644, \u0026#34;localEndpoint\u0026#34;: { \u0026#34;serviceName\u0026#34;: \u0026#34;frontend\u0026#34; } }, { \u0026#34;traceId\u0026#34;: \u0026#34;9ee01dfbbba1a5f2\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;9ee01dfbbba1a5f2\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;SERVER\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;get /\u0026#34;, \u0026#34;timestamp\u0026#34;: 1566397279276961, \u0026#34;duration\u0026#34;: 1572319, \u0026#34;localEndpoint\u0026#34;: { \u0026#34;serviceName\u0026#34;: \u0026#34;frontend\u0026#34;, \u0026#34;ipv4\u0026#34;: \u0026#34;192.168.1.14\u0026#34; }, \u0026#34;tags\u0026#34;: { \u0026#34;http.path\u0026#34;: \u0026#34;/\u0026#34;, \u0026#34;http.status_code\u0026#34;: \u0026#34;200\u0026#34; } } ] ","permalink":"https://brianpfeil.com/post/zipkin/","postedOnDate":" August 21, 2019","tags":["distributed-tracing","observability"],"title":"Zipkin"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/serverless-framework-full-lifecycle-with-dashboard-playground  serverless-framework-full-lifecycle-with-dashboard-playground learn and understand how Serverless Framework – Now, Full Lifecycle works. This allows serverless to instrument code, send cloudwatch logs to the serverless SaaS. This allows serverless to provide the Serverless Dashboard features\n Running serverless from cli to create project\nThe service, app, and org top-level properties added to serverless.yml enable serverless full lifecycle / dashboard\nservice:serverless-with-dashboard-playground-01app:serverless-with-dashboard-playground-01org:pfeilbrTo disable, add the following to serverless.yml\ncustom:enterprise:collectLambdaLogs:falseServerless framework creates a role during the deploy. This allows for the cloudwatch log group logs to be sent to serverless SaaS app. e.g. arn:aws:iam::529276214230:role/serverless-with-dashboard-EnterpriseLogAccessIamRo-19SDI69RM1KJ4\ninline policy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;logs:FilterLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:logs:us-east-1:529276214230:log-group:/aws/lambda/serverless-with-dashboard-playground-01-dev-hello:*\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] } trust relationship\n trust serverless aws account 802587217904\n { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::802587217904:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;sts:ExternalId\u0026#34;: \u0026#34;ServerlessEnterprise-LGGXBmZw2Z47MmWq6b\u0026#34; } } } ] } Instrumented/wrapped Code Example\nOn deploy, serverless instruments/wraps your code/handlers. You don\u0026rsquo;t see this locally in your codebase. You only see on the deployment side in AWS.\nembedded/bundled serverless SDK SERVERLESS_ENTERPRISE wrapped log example\nserverless hooks logging to stdout and stderr via serverlessSDK. This allows it to log structured JSON logs to cloudwatch logs with the prefix SERVERLESS_ENTERPRISE. This logging is additional, the console.logs are logged independently.\nTo see the log group subscription details\naws logs describe-subscription-filters --log-group-name '/aws/lambda/serverless-with-dashboard-playground-01-dev-hello'\n{ \u0026#34;subscriptionFilters\u0026#34;: [ { \u0026#34;filterPattern\u0026#34;: \u0026#34;?\\\u0026#34;REPORT RequestId: \\\u0026#34; ?\\\u0026#34;SERVERLESS_ENTERPRISE\\\u0026#34;\u0026#34;, \u0026#34;filterName\u0026#34;: \u0026#34;serverless-with-dashboard-playground-01-dev-CloudWatchLogsSubscriptionFilterHelloLogGroup-1SAKWRFMW5JHE\u0026#34;, \u0026#34;creationTime\u0026#34;: 1566318781436, \u0026#34;logGroupName\u0026#34;: \u0026#34;/aws/lambda/serverless-with-dashboard-playground-01-dev-hello\u0026#34;, \u0026#34;destinationArn\u0026#34;: \u0026#34;arn:aws:logs:us-east-1:802587217904:destination:LGGXBmZw2Z47MmWq6b#VlGYyRJNfvVVgHf8y1#serverless-with-dashboard-playground-01#dev\u0026#34;, \u0026#34;distribution\u0026#34;: \u0026#34;ByLogStream\u0026#34; } ] } It sends logs to the serverless AWS account (802587217904). The destinationArn: arn:aws:logs:us-east-1:802587217904:destination:LGGXBmZw2Z47MmWq6b#VlGYyRJNfvVVgHf8y1#serverless-with-dashboard-playground-01#dev is a kinesis stream within the serverless AWS account.\nThis is done via Cross-Account Log Data Sharing with Subscriptions\n Serverless Dashboard | Views\n\u0026ldquo;safeguard policies\u0026rdquo; are evaluated on serverless deploy Send notifications (e.g. email)\n Resources  reddit | Serverless Framework now supports full lifecycle on AWS  ","permalink":"https://brianpfeil.com/post/serverless-framework-full-lifecycle-with-dashboard/","postedOnDate":" August 20, 2019","tags":["serverless"],"title":"Serverless Framework Full Lifecycle with Dashboard"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-sam-local-playground  learn aws-sam-local\nsession cd examples/hello-world sam local invoke \u0026#34;HelloWorld\u0026#34; -e event.json echo \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;Brian\u0026#34; }\u0026#39; | sam local invoke \u0026#34;HelloWorld\u0026#34; # debugging # ensure launch.json localRoot is set to directory where index.js or code exists # e.g. \u0026#34;localRoot\u0026#34;: \u0026#34;${workspaceRoot}/examples/hello-world\u0026#34; sam local invoke -e event.json -d 5858 HelloWorld # set breakpoints in code (vscode) # then run debug in vscode # package # NOTE: bucket must exist (`aws s3 mb s3://sam-deploy-bucket-01`) sam package --template-file template.yaml --s3-bucket sam-deploy-bucket-01 --output-template-file packaged.yaml # deploy sam deploy --template-file packaged.yaml --stack-name sam-hello-world-v0 --capabilities CAPABILITY_IAM # invoke # NOTE: you\u0026#39;ll need to lookup the \u0026#34;full\u0026#34; function name aws lambda invoke --function-name \u0026#34;sam-hello-world-v1-HelloWorld-L8DLT50DZNIJ\u0026#34; --payload \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;brian\u0026#34;}\u0026#39; output.log; cat output.log # view logs sam logs -n HelloWorld --stack-name sam-hello-world-v1 # --- # invoke lambda via api gateway example cd examples/api-event-source # local development sam local start-api curl http://127.0.0.1:3000/ # package # NOTE: bucket must exist (`aws s3 mb s3://sam-deploy-bucket-01`) sam package --template-file template.yaml --s3-bucket sam-deploy-bucket-01 --output-template-file packaged.yaml # deploy sam deploy --template-file packaged.yaml --stack-name api-event-source-v1 --capabilities CAPABILITY_IAM Resources  AWS Serverless Application Model (AWS SAM) Documentation  ","permalink":"https://brianpfeil.com/post/aws-sam-local/","postedOnDate":" August 16, 2019","tags":["aws","sam"],"title":"AWS SAM Local"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-cloudformation-playground  learn aws cloudformation\n Concepts Stacks  Drift detection  Resources that support import and drift detection operations - AWS CloudFormation    Nested Stacks Stack Sets  enabling you to create, update, or delete stacks across multiple accounts and Regions with a single operation\n   You can create a stack set with either self-managed or service-managed permissions\n self-managed - first create the necessary IAM roles to establish a trusted relationship between the account you\u0026rsquo;re administering the stack set from and the account you\u0026rsquo;re deploying stack instances to service-managed (use with Orgs) - deploy stack instances to accounts managed by AWS Organizations in specific Regions. With this model, you don\u0026rsquo;t need to create the necessary IAM roles; StackSets creates the IAM roles on your behalf.    automatic deployment enabled, StackSets automatically deploys to accounts that are added to the target organization or organizational units (OUs) in the future\n  account gate is an optional feature that lets you specify an AWS Lambda function to verify that a target account meets certain requirements before AWS CloudFormation StackSets begins stack operations in that account\n  stackset stacks should be account and region agnostic. same template will be used for all deployments. use SSM parameter store parameters in the target account + region for specific configurations.\n   Running Examples examples in templates/ directory\n# validate template aws cloudformation validate-template --template-body file://templates/s3-bucket.yaml # deploy aws cloudformation deploy --template-file templates/s3-bucket.yaml --stack-name s3-bucket-stack # list stack output values aws cloudformation describe-stacks --stack-name s3-bucket-stack --query \u0026#34;Stacks[0].Outputs[].OutputValue\u0026#34; Dynamic References Example see templates/dynamic-references-ssm-secrets.yaml and Using Dynamic References to Specify Template Values \n# validate aws cloudformation validate-template --template-body file://templates/dynamic-references-ssm-secrets.yaml # create stack aws cloudformation deploy --template-file templates/dynamic-references-ssm-secrets.yaml --stack-name dynamic-references-ssm-secrets-stack # uncomment `Outputs` in templates/dynamic-references-ssm-secrets.yaml # update stack aws cloudformation deploy --template-file templates/dynamic-references-ssm-secrets.yaml --stack-name dynamic-references-ssm-secrets-stack # view stack outputs # NOTE: `MySecret01Value` output does not get resolved due to security aws cloudformation describe-stacks --stack-name dynamic-references-ssm-secrets-stack --query \u0026#34;Stacks[0].Outputs[].OutputValue\u0026#34; # clean up aws cloudformation delete-stack --stack-name dynamic-references-ssm-secrets-stack Resources  CloudFormation Custom Resources CloudFormation Macros   Scratch aws cloudformation deploy --template-file templates/playground.yaml --stack-name playground-stack --capabilities \u0026#34;CAPABILITY_IAM\u0026#34; \u0026#34;CAPABILITY_NAMED_IAM\u0026#34; \u0026#34;CAPABILITY_AUTO_EXPAND\u0026#34; aws cloudformation describe-stacks \\  --stack-name \u0026#34;playground-stack\u0026#34; \\  --query \u0026#34;Stacks[0].Outputs[?OutputKey==\u0026#39;LambdaName\u0026#39;].OutputValue\u0026#34; --output text playground-stack-MyLambdaFunction-iMVMRs2CA3fm aws lambda invoke \\  --cli-binary-format \u0026#34;raw-in-base64-out\u0026#34; \\  --function-name \u0026#34;playground-stack-MyLambdaFunction-iMVMRs2CA3fm\u0026#34; \\  --payload \u0026#39;{\u0026#34;msg\u0026#34;: \u0026#34;hello\u0026#34;}\u0026#39; \\  output.log; cat output.log; rm output.log ","permalink":"https://brianpfeil.com/post/aws-cloudformation/","postedOnDate":" August 14, 2019","tags":["aws","cloudformation"],"title":"AWS CloudFormation"},{"categories":["Java","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/intellij-maven-app-playground  example of IntelliJ Maven App\nResources  Apache Maven Assembly Plugin / Usage   # clean mvn clean # package with all dependencies and make .jar executable # see `pom.xml` for details mvn package # run jar java -jar ./target/app01-1.0-SNAPSHOT-jar-with-dependencies.jar ","permalink":"https://brianpfeil.com/post/intellij-maven-app/","postedOnDate":" August 14, 2019","tags":["java","maven","build-tools"],"title":"Intellij Maven App"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-xray-playground  learn AWS X-Ray\nsee index.js\nDevelopment # run x-ray daemon locally (nodejs code sends trace data to it and it forwards it to aws x-ray service) # see https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html  cd ~/bin/aws-xray-daemon-macos-3.x ./xray_mac -o -n us-east-1 # run code that generates trace/segment data npm run dev  Screenshots Resources  aws/aws-xray-sdk-node aws/aws-xray-sdk-node/blob/master/packages/core/README.md  ","permalink":"https://brianpfeil.com/post/aws-xray/","postedOnDate":" August 13, 2019","tags":["aws","xray"],"title":"AWS XRay"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/pipenv-playground  learn pipenv\n Pipenv is a tool that aims to bring the best of all packaging worlds (bundler, composer, npm, cargo, yarn, etc.) to the Python world. Windows is a first-class citizen, in our world.\n  It automatically creates and manages a virtualenv for your projects, as well as adds/removes packages from your Pipfile as you install/uninstall packages. It also generates the ever-important Pipfile.lock, which is used to produce deterministic builds.\n  based on https://docs.python-guide.org/dev/virtualenvs/  Usage # install pip3 install pipenv # create directory cd ~/tmp mkdir pipenv-playground cd pipenv-playground # install dependency pipenv install requests # write some code that uses the dependency touch main.py # run it using the created virtualenv pipenv run python main.py # can also specify `python3` explicitly pipenv run python3 main.py # try with jupyter notebook cd .. mkdir jupyter-notebook-playground cd jupyter-notebook-playground pipenv install jupyter pipenv run jupyter notebook # try with jupyterlab pipenv install jupyterlab pipenv run jupyter lab ","permalink":"https://brianpfeil.com/post/pipenv/","postedOnDate":" August 7, 2019","tags":["python","packaging"],"title":"Pipenv"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/python-packaging-playground  learn python packaging via Packaging Python Projects\nview example package at https://test.pypi.org/project/example-pkg-pfeilbr/\npython3 -m venv .venv source .venv/bin/activate mkdir example-pkg-pfeilbr touch example-pkg-pfeilbr/__init__.py python3 -m pip install --user --upgrade setuptools wheel python3 setup.py sdist bdist_wheel pip install --upgrade pip pip install wheel pip install twine python3 -m twine upload --repository-url https://test.pypi.org/legacy/ dist/* # testing mkdir tmp cd tmp python3 -m venv .venv source .venv/bin/activate pip list python3 -m pip install --index-url https://test.pypi.org/simple/ --no-deps example-pkg-pfeilbr # to install specific version. did this because it was using 0.0.1 from a cache python3 -m pip install --index-url https://test.pypi.org/simple/ --no-deps \u0026#39;example-pkg-pfeilbr==0.0.2\u0026#39; pip list # test using package echo -e \u0026#34;import example_pkg_pfeilbr\\nprint(example_pkg_pfeilbr.name)\u0026#34; | python  Example Package This is a simple example package. You can use Github-flavored Markdown to write your content.\n","permalink":"https://brianpfeil.com/post/python-packaging/","postedOnDate":" August 7, 2019","tags":["python"],"title":"Python Packaging"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/neo4j-playground  learn neo4j graph database\nExample Session # update brew update # install brew install neo4j # add neo4j binaries to path export PATH=\u0026#34;$PATH:/usr/local/Cellar/neo4j/3.5.8/bin\u0026#34; # start server neo4j start # open web ui open http://localhost:7474/ # it\u0026#39;ll prompt for password on first time # user and password is neo4j # you then need to change the password # open neo4j shell (Cypher Shell) cypher-shell -u neo4j -p PASSWORD # create nodes in shell CREATE (p:Person {name:\u0026#39;brian\u0026#39;}); CREATE (p:Person {name:\u0026#39;tricia\u0026#39;}); # create relationship MATCH (brian:Person {name:\u0026#39;brian\u0026#39;}) MATCH (tricia:Person {name:\u0026#39;tricia\u0026#39;}) CREATE (brian)-[:IS_MARRIED_TO]-\u0026gt;(tricia) CREATE (tricia)-[:IS_MARRIED_TO]-\u0026gt;(brian); # query `IS_MARRIED_TO` relationship MATCH (p1:Person)-[rel:IS_MARRIED_TO]-\u0026gt;(p2:Person) RETURN p1 AS spouse1, p2 AS spouse2; # clean up: delete all nodes and relationships MATCH (n) DETACH DELETE n; # exit shell :exit # stop server neo4j stop  Web UI\n Resources  neo4j documentation  ","permalink":"https://brianpfeil.com/post/neo4j/","postedOnDate":" August 5, 2019","tags":["neo4j"],"title":"Neo4j"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-transcribe-playground  learn aws transcribe speech to text service\nsee src/index.js and example output in data/\nRunning # install deps npm install # run npm start ","permalink":"https://brianpfeil.com/post/aws-transcribe/","postedOnDate":" July 30, 2019","tags":["aws"],"title":"AWS Transcribe"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/chrome-aws-lambda-playground  learn the chrome-aws-lambda package for use with aws lambda via serverless framework\nScreenshot Web Page return screenshot of page from provided url\nexample with https://twitter.com\nhttps://SERVICE_ENDPOINT/dev/webpagescreenshot?url=https://twitter.com\n","permalink":"https://brianpfeil.com/post/chrome-aws-lambda/","postedOnDate":" July 24, 2019","tags":["chrome","aws","lambda"],"title":"Chrome AWS Lambda"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/youtube-api-playground  learn youtube api using node.js\nsee src/index.js\nRunning # install deps npm install # setup your .env with your youtube api key cp .env.sample .env # run npm start ","permalink":"https://brianpfeil.com/post/youtube-api/","postedOnDate":" July 22, 2019","tags":["youtube","nodejs"],"title":"YouTube API"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-cdk-playground  learn AWS Cloud Development Kit (CDK)\nsee kitchen-sink/README.md\nDescription  express resources using general purpose programming languages (ts/js/python/java/C#) constructs - construct levels 1, 2, 3. cfn (L1), CDK (L2), pattern/solution (L3) synth to cfn cloud assemblies - cfn + source code, docker images, assets (s3) aspects - ability to visit each node/resource in stack and apply changes Application -\u0026gt; Stacks -\u0026gt; Constructs Parameters - cfn parameters. can pass in via cdk synth. Runtime context - key-value pairs that can be associated with a stack or construct. Can only be string values (kind of like parameters) [tf|k8s] CDKs jsii - core/foundational tech for multi-language/polyglot support. bind any language to underlying typescript implementation. CDK pipelines for CI/CD Custom Logical Names - shows how to hook into an provide own resource names. Can be used for IAM policies based on resource name prefixes Usage with Permissions Boundaries - class PermissionsBoundary · AWS CDK. e.g. PermissionsBoundary.of(this).apply(permissionsBoundariesPolicy);  Key Files and Directories  bin - entry point to CDK app. imports 1 or more stacks from lib folder lib/*-stack.* - define stacks here which contain constructs cdk.json - cdk configuration test - unit/integration/e2e tests cdk.out - CDK assembly / synth output (cfn, assets, etc.)  Common Areas  @aws-cdk/core - App, Stack, Stack.account, Stack.region, Stack.tags, Stack.terminationProtection, Construct, Duration, CfnOutput lambda.Function, lambda.Code.fromAsset, lambda.Code.fromInline @aws-cdk/aws-iam - Role, User, Group, PolicyStatement   Common Steps # init cdk app cdk init app --language javascript cdk init app --language typescript # list stacks in the app cdk list # [optional] build for ts -\u0026gt; js. not required for js npm run build # synthesize to cfn (`cdk.out`) cdk synth # run tests npm test # compare the specified stack with the deployed stack cdk diff # deploy cdk deploy # force deploy, no prompt cdk deploy --force --require-approval never # delete cdk destroy [STACKS..]  CDK Internals Details on the inner workings of CDK.\nCDK Tree Core of CDK is based on tree structure similar to the DOM.\n  node: ConstructNode - accessed via this.node - root of the tree.\n  node.children\n  node.findChild(id: string) - search for child in tree with id. new s3.Bucket(this, \u0026quot;Assets\u0026quot;). \u0026quot;Assets\u0026quot; is the id.\n  node.tryFindChild(id: string) - same as findChild but won\u0026rsquo;t throw if id doesn\u0026rsquo;t exist. Will return undefined.\n  node.defaultChild - reference to primary level 1 construct (Cfn*)\n  common L1 construct methods\n overrideLogicalId addOverride(propertyPath, value) - e.g. cfnBucket.addOverride(\u0026quot;Properties.BucketName\u0026quot;, \u0026quot;my-bucket-name-01\u0026quot;)  need to use for cfn attributes that are outside of the Properties. e.g. DeletionPolicy add bucket name to Metadata - cfnBucket.addOverride(\u0026quot;Metadata.BucketName\u0026quot;, cfnBucket.ref)   addDeletionOverride(propertyPath) - remove a property. e.g. cfnBucket.addDeletionOverride(\u0026quot;Properties.BucketName\u0026quot;) addPropertyOverride(propertyPath) - cfnBucket.addPropertyOverride(\u0026quot;Properties.BucketName\u0026quot;, \u0026quot;my-bucket-name-01\u0026quot;)    all Fn::GetAtt return values can be accessed via a property named Att${Return Value Name}. e.g. cfnBucket.AttArn, cfnBucket.AttDomainName\n  CDK Path  every resource defined in CDK tree has a path this.node.path - concatenation of path traversal to the node in the CDK tree. (e.g. MyStack/Assets) this path is added to the Metadata property for each resource in cfn.  CDK Identifiers  Logical ID - used in cfn template. scoped within stack. calculated using CDK path (sanitized id (no stack id) + hash) Unique ID - uniquely identify resource within CDK application. scoped within CDK application, which may be composed of multiple stacks. sanitized id (including stack) + hash   Common CDK Snippets  @aws-cdk/core module @aws-cdk/aws-iam module - key module  // durations Duration.seconds(300) // 5 minutes Duration.minutes(5) // 5 minutes Duration.hours(1) // 1 hour Duration.days(7) // 7 days Duration.parse(\u0026#39;PT5M\u0026#39;) // 5 minutes  // sizes Size.kibibytes(200) // 200 KiB Size.mebibytes(5) // 5 MiB Size.gibibytes(40) // 40 GiB Size.tebibytes(200) // 200 TiB Size.pebibytes(3) // 3 PiB  // create secret const secret = SecretValue.secretsManager(\u0026#39;secretId\u0026#39;, { jsonField: \u0026#39;password\u0026#39;, // optional: key of a JSON field to retrieve (defaults to all content),  versionId: \u0026#39;id\u0026#39;, // optional: id of the version (default AWSCURRENT)  versionStage: \u0026#39;stage\u0026#39;, // optional: version stage name (default AWSCURRENT) }); // get default VPC const vpc = ec2.Vpc.fromLookup(stack, \u0026#39;VPC\u0026#39;, { // This imports the default VPC but you can also  // specify a \u0026#39;vpcName\u0026#39; or \u0026#39;tags\u0026#39;.  isDefault: true, }); // custom resource const fn = new lambda.Function(this, \u0026#39;MyProvider\u0026#39;, functionProps); new CustomResource(this, \u0026#39;MyResource\u0026#39;, { serviceToken: fn.functionArn, }); // OR  const serviceToken = CustomResourceProvider.getOrCreate(this, \u0026#39;Custom::MyCustomResourceType\u0026#39;, { codeDirectory: `${__dirname}/my-handler`, runtime: CustomResourceProviderRuntime.NODEJS_12_X, description: \u0026#34;Lambda function created by the custom resource provider\u0026#34;, }); new CustomResource(this, \u0026#39;MyResource\u0026#39;, { resourceType: \u0026#39;Custom::MyCustomResourceType\u0026#39;, serviceToken: serviceToken }); // bastion host const host = new ec2.BastionHostLinux(this, \u0026#39;BastionHost\u0026#39;, { vpc });  Resources  AWS CDK · AWS CDK Reference Documentation Infrastructure-as-Code | Constructs | AWS Solutions awslabs/aws-solutions-constructs aws-samples/aws-cdk-examples aws/constructs - Constructs Programming Model panacloud-modern-global-apps/full-stack-serverless-cdk github | search | \u0026ldquo;filename:cdk.json\u0026rdquo; Exploring CDK Internals Working with the AWS CDK Explorer - AWS Toolkit for VS Code  ","permalink":"https://brianpfeil.com/post/aws-cdk/","postedOnDate":" July 11, 2019","tags":["aws","cdk"],"title":"AWS CDK"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-fargate-playground  learn AWS Fargate\n# register task definition aws ecs register-task-definition --cli-input-json file://./task-definitions/hello-world.json # run task aws ecs run-task --task-definition \u0026#34;fargate-001\u0026#34; --launch-type \u0026#34;FARGATE\u0026#34; --network-configuration \u0026#39;{\u0026#34;awsvpcConfiguration\u0026#34;: {\u0026#34;subnets\u0026#34;: [\u0026#34;subnet-154b7928\u0026#34;, \u0026#34;subnet-4700526d\u0026#34;, \u0026#34;subnet-6cf9a534\u0026#34;, \u0026#34;subnet-af5052d9\u0026#34;],\u0026#34;securityGroups\u0026#34;: [\u0026#34;sg-047fbd9524f6e2b5e\u0026#34;],\u0026#34;assignPublicIp\u0026#34;: \u0026#34;ENABLED\u0026#34;}}\u0026#39; # *** NOTE *** # * \u0026#34;assignPublicIp\u0026#34;: \u0026#34;ENABLED\u0026#34; is needed for ecs/fargate to pull image from docker hub # * \u0026#34;securityGroups\u0026#34;: must allow outbund traffic # * make sure log group is already created ","permalink":"https://brianpfeil.com/post/aws-fargate/","postedOnDate":" July 10, 2019","tags":["aws","fargate"],"title":"AWS Fargate"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-glue-playground  learn and experiment with aws glue\nRunning \u0026ldquo;Python Shell\u0026rdquo; Job Local Running/Testing of Script python3 -m venv venv source venv/bin/activate pip install -r requirements.txt python scripts/python3-shell-job-example.py Running/Submitting Python Shell Job cp .env.sample .env # modify .env for your environment # following submits the job (scripts/python3-shell-job-example.py) node src/job-runner.js run-python-shell-script scripts/python3-shell-job-example.py Steps to Run scripts/example-notebook-script-01.py in SageMaker notebook see scripts/example-notebook-script-01.py\n upload data.csv to S3 create glue crawler for data.csv which results in a table in glue database being created  you can verify by previewing the data in athena\n  create aws glue Dev Endpoint  no need to specify ssh key\n  create SageMaker notebook  SageMaker notebook works just like Zepplin notebook, but less setup steps.\n  open SageMaker notebook and past in code from scripts/example-notebook-script-01.py  ","permalink":"https://brianpfeil.com/post/aws-glue/","postedOnDate":" July 9, 2019","tags":["aws","glue"],"title":"AWS Glue"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-rekognition-playground  learn AWS Rekognition\nsee src/examples.js\nPrerequisites   AWS default credentials available to call Rekognition API\n  install imagemagick, graphicsmagick, and ghostscript (for fonts) for labelling image\nbrew install imagemagick brew install graphicsmagick brew install ghostscript   Example Labelled Image Using detectLabels API Source Labelled Example Labelled Image Using detectText API Source Labelled Running npm install npm start  Video Label Detection Example via CLI # start (it\u0026#39;s async) aws rekognition start-label-detection --video \u0026#34;S3Object={Bucket=rekognition-playground,Name=SampleVideo_1280x720_1mb.mp4}\u0026#34; # output { \u0026#34;JobId\u0026#34;: \u0026#34;2c9b387607977af21c0839f177bf7034ce1bcd5139810b533dea3deb6361f348\u0026#34; } # in progress aws rekognition get-label-detection --job-id \u0026#34;2c9b387607977af21c0839f177bf7034ce1bcd5139810b533dea3deb6361f348\u0026#34; # output { \u0026#34;Labels\u0026#34;: [], \u0026#34;LabelModelVersion\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;JobStatus\u0026#34;: \u0026#34;IN_PROGRESS\u0026#34; } # completed aws rekognition get-label-detection --job-id \u0026#34;2c9b387607977af21c0839f177bf7034ce1bcd5139810b533dea3deb6361f348\u0026#34; # output { \u0026#34;Labels\u0026#34;: [ { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 89.929931640625, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 69.0970458984375, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bunny\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 51.81949234008789, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Deer\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 83.59092712402344, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 50.83674621582031, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Green\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 83.93998718261719, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.92662048339844, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Moss\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 63.28266906738281, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.88518524169922, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Pet\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 90.28629302978516, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 69.0970458984375, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rabbit\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 69.0970458984375, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 71.99913787841797, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Tree\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 82.74295806884766, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 58.27427291870117, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 0, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 67.73959350585938, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 91.4648666381836, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.55938720703125, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bunny\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 53.18073654174805, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Deer\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 81.07315826416016, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 82.8969955444336, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.91206359863281, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Moss\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.965728759765625, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Nature\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.73519897460938, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.99771499633789, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Pet\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 89.0054931640625, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.55938720703125, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rabbit\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 61.68227767944336, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 74.91455078125, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Tree\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 82.96375274658203, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.77254104614258, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 74.65026092529297, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.01680755615234, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 59.57973098754883, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Deer\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 78.3232650756836, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 83.4029541015625, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.54331588745117, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Moss\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.17965316772461, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Nature\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 69.8688735961914, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 87.0956802368164, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.15915298461914, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 74.54655456542969, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Tree\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 80.760009765625, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 65.61725616455078, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 80.25843048095703, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.0205078125, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.57878875732422, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Deer\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 74.01980590820312, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 82.74808502197266, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 51.89423751831055, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Moss\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.12575149536133, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Nature\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 66.46729278564453, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 83.74144744873047, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.528724670410156, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 69.28874206542969, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Tree\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 74.46104431152344, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 61.98466873168945, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 85.43339538574219, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.25353240966797, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.10648727416992, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Deer\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 75.25298309326172, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.252071380615234, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Nature\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Land\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 83.48870086669922, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.91990280151367, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Nature\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 63.378013610839844, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 82.87625885009766, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.5538330078125, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 65.29582977294922, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Tree\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 70.30518341064453, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.97867965698242, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 90.27912139892578, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.98469543457031, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 76.76435089111328, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 84.5231704711914, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 62.500648498535156, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 83.34005737304688, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.20842361450195, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.69285583496094, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Tree\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 71.41803741455078, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.289005279541016, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Wildlife\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 90.80029296875, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.2735366821289, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.429866790771484, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bunny\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 79.42290496826172, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 84.56671905517578, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.960243225097656, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 83.51371002197266, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.429866790771484, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rabbit\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.429866790771484, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.99834060668945, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Tree\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.27635192871094, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 89.07957458496094, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 91.85724639892578, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.245033264160156, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.461219787597656, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bunny\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 80.37769317626953, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 51.644439697265625, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Green\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 81.59090423583984, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 50.62571716308594, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 51.50884246826172, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Pet\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 83.59095764160156, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.461219787597656, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rabbit\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.461219787597656, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Rodent\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.90790939331055, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Tree\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 69.43914031982422, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 85.9814453125, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 92.43132019042969, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.58529663085938, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 77.15897369384766, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 72.95342254638672, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.87014389038086, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Outdoors\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 50.35053634643555, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Pet\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 78.85031127929688, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.71328353881836, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Tree\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 67.42894744873047, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 86.85175323486328, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.09008026123047, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.34907206892967224, \u0026#34;Top\u0026#34;: 0.08466745913028717, \u0026#34;Left\u0026#34;: 0.18098066747188568, \u0026#34;Height\u0026#34;: 0.7858670353889465 }, \u0026#34;Confidence\u0026#34;: 87.56869506835938 } ], \u0026#34;Confidence\u0026#34;: 76.05467224121094, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 70.30843353271484, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 62.480037689208984, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 72.11174774169922, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 57.063655853271484, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Vegetation\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 1800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 89.28423309326172, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.03936004638672, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.733070373535156, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.358623743057251, \u0026#34;Top\u0026#34;: 0.051293861120939255, \u0026#34;Left\u0026#34;: 0.1617140769958496, \u0026#34;Height\u0026#34;: 0.8379018306732178 }, \u0026#34;Confidence\u0026#34;: 92.25386810302734 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.7171964049339294, \u0026#34;Top\u0026#34;: 0.07636002451181412, \u0026#34;Left\u0026#34;: 0.18950828909873962, \u0026#34;Height\u0026#34;: 0.8369417190551758 }, \u0026#34;Confidence\u0026#34;: 79.23548889160156 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.27733245491981506, \u0026#34;Top\u0026#34;: 0.002237256383523345, \u0026#34;Left\u0026#34;: 0.0026457428466528654, \u0026#34;Height\u0026#34;: 0.359114408493042 }, \u0026#34;Confidence\u0026#34;: 69.28044128417969 } ], \u0026#34;Confidence\u0026#34;: 87.71780395507812, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.62752914428711, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.03357696533203, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 62.13314437866211, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 59.2055778503418, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 82.38220977783203, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.34841918945312, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.2954216003418, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.35335078835487366, \u0026#34;Top\u0026#34;: 0.05790714547038078, \u0026#34;Left\u0026#34;: 0.15636315941810608, \u0026#34;Height\u0026#34;: 0.8401352167129517 }, \u0026#34;Confidence\u0026#34;: 93.80805206298828 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.7027698755264282, \u0026#34;Top\u0026#34;: 0.06268657743930817, \u0026#34;Left\u0026#34;: 0.22604236006736755, \u0026#34;Height\u0026#34;: 0.8820430040359497 }, \u0026#34;Confidence\u0026#34;: 79.38104248046875 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.12301671504974365, \u0026#34;Top\u0026#34;: 0.08307760953903198, \u0026#34;Left\u0026#34;: 0.0, \u0026#34;Height\u0026#34;: 0.2910917401313782 }, \u0026#34;Confidence\u0026#34;: 67.13511657714844 } ], \u0026#34;Confidence\u0026#34;: 92.72528076171875, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 71.46737670898438, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 51.77077865600586, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 82.10325622558594, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 94.62578582763672, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.21943664550781, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.35887837409973145, \u0026#34;Top\u0026#34;: 0.06843113154172897, \u0026#34;Left\u0026#34;: 0.14393199980258942, \u0026#34;Height\u0026#34;: 0.8300164341926575 }, \u0026#34;Confidence\u0026#34;: 95.54167938232422 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.6892942190170288, \u0026#34;Top\u0026#34;: 0.08313678950071335, \u0026#34;Left\u0026#34;: 0.2348754107952118, \u0026#34;Height\u0026#34;: 0.8645190596580505 }, \u0026#34;Confidence\u0026#34;: 73.23546600341797 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.2922210097312927, \u0026#34;Top\u0026#34;: 0.006060568615794182, \u0026#34;Left\u0026#34;: 0.0026990175247192383, \u0026#34;Height\u0026#34;: 0.3458782136440277 }, \u0026#34;Confidence\u0026#34;: 70.34931945800781 } ], \u0026#34;Confidence\u0026#34;: 93.9428482055664, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 73.18048858642578, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 50.8458366394043, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 84.690673828125, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 94.66659545898438, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.99951934814453, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.3687349259853363, \u0026#34;Top\u0026#34;: 0.07353333383798599, \u0026#34;Left\u0026#34;: 0.1337471306324005, \u0026#34;Height\u0026#34;: 0.8266903162002563 }, \u0026#34;Confidence\u0026#34;: 94.13199615478516 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.6544439196586609, \u0026#34;Top\u0026#34;: 0.11645308881998062, \u0026#34;Left\u0026#34;: 0.2392454445362091, \u0026#34;Height\u0026#34;: 0.8009392619132996 }, \u0026#34;Confidence\u0026#34;: 66.88501739501953 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.27630096673965454, \u0026#34;Top\u0026#34;: 0.0037734773941338062, \u0026#34;Left\u0026#34;: 0.0016699910629540682, \u0026#34;Height\u0026#34;: 0.3773573935031891 }, \u0026#34;Confidence\u0026#34;: 59.929168701171875 } ], \u0026#34;Confidence\u0026#34;: 93.93486785888672, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 71.29080200195312, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.107154846191406, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 84.884765625, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 94.47773742675781, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.99027252197266, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.38219374418258667, \u0026#34;Top\u0026#34;: 0.0916653499007225, \u0026#34;Left\u0026#34;: 0.12020987272262573, \u0026#34;Height\u0026#34;: 0.7875498533248901 }, \u0026#34;Confidence\u0026#34;: 93.746337890625 } ], \u0026#34;Confidence\u0026#34;: 93.69722747802734, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 50.03854751586914, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 70.23558044433594, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.43981170654297, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 2800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 79.4557876586914, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.83204650878906, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.40727233886719, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.3897032141685486, \u0026#34;Top\u0026#34;: 0.08954781293869019, \u0026#34;Left\u0026#34;: 0.11494585126638412, \u0026#34;Height\u0026#34;: 0.7958506941795349 }, \u0026#34;Confidence\u0026#34;: 92.31681823730469 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.6983879804611206, \u0026#34;Top\u0026#34;: 0.09777429699897766, \u0026#34;Left\u0026#34;: 0.21733859181404114, \u0026#34;Height\u0026#34;: 0.8366428017616272 }, \u0026#34;Confidence\u0026#34;: 70.86040496826172 } ], \u0026#34;Confidence\u0026#34;: 93.1003189086914, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.9047966003418, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.41144561767578, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 62.5224609375, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 50.769561767578125, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Waterfowl\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 77.5377426147461, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.4638900756836, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.41419991850852966, \u0026#34;Top\u0026#34;: 0.0762210413813591, \u0026#34;Left\u0026#34;: 0.10949432849884033, \u0026#34;Height\u0026#34;: 0.8263728022575378 }, \u0026#34;Confidence\u0026#34;: 92.80986785888672 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.716448187828064, \u0026#34;Top\u0026#34;: 0.07755652815103531, \u0026#34;Left\u0026#34;: 0.20436832308769226, \u0026#34;Height\u0026#34;: 0.8662547469139099 }, \u0026#34;Confidence\u0026#34;: 65.755615234375 } ], \u0026#34;Confidence\u0026#34;: 92.78094482421875, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 62.132137298583984, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 57.85761642456055, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 67.59366607666016, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 53.58717727661133, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Waterfowl\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 71.5042495727539, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 92.79534912109375, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.4154813885688782, \u0026#34;Top\u0026#34;: 0.07800661772489548, \u0026#34;Left\u0026#34;: 0.11423929035663605, \u0026#34;Height\u0026#34;: 0.822206437587738 }, \u0026#34;Confidence\u0026#34;: 92.5831298828125 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.7635012865066528, \u0026#34;Top\u0026#34;: 0.10048328340053558, \u0026#34;Left\u0026#34;: 0.1485721319913864, \u0026#34;Height\u0026#34;: 0.832586407661438 }, \u0026#34;Confidence\u0026#34;: 64.7535171508789 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.3332541882991791, \u0026#34;Top\u0026#34;: 0.0031649908050894737, \u0026#34;Left\u0026#34;: 0.0, \u0026#34;Height\u0026#34;: 0.39897918701171875 }, \u0026#34;Confidence\u0026#34;: 63.40528869628906 } ], \u0026#34;Confidence\u0026#34;: 92.79534912109375, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 61.568965911865234, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.528438568115234, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.99581146240234, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 51.52910614013672, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.16550827026367, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Waterfowl\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 63.12147903442383, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.00226593017578, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 57.59740447998047, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Aquatic\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.39586177468299866, \u0026#34;Top\u0026#34;: 0.09188465774059296, \u0026#34;Left\u0026#34;: 0.11620678752660751, \u0026#34;Height\u0026#34;: 0.8037567138671875 }, \u0026#34;Confidence\u0026#34;: 92.49174499511719 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.7152539491653442, \u0026#34;Top\u0026#34;: 0.08323486894369125, \u0026#34;Left\u0026#34;: 0.2065276801586151, \u0026#34;Height\u0026#34;: 0.8613862991333008 }, \u0026#34;Confidence\u0026#34;: 63.56003189086914 } ], \u0026#34;Confidence\u0026#34;: 93.00226593017578, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 66.82272338867188, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.20016860961914, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Legend of Zelda\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 51.27878952026367, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.2894058227539, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 51.18978500366211, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Sea Life\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 59.10639572143555, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.734310150146484, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Waterfowl\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 58.78702926635742, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 94.29412078857422, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 61.6994514465332, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Aquatic\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.3951866924762726, \u0026#34;Top\u0026#34;: 0.11749797314405441, \u0026#34;Left\u0026#34;: 0.11840298026800156, \u0026#34;Height\u0026#34;: 0.7652148604393005 }, \u0026#34;Confidence\u0026#34;: 93.82617950439453 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.7300499081611633, \u0026#34;Top\u0026#34;: 0.08484145253896713, \u0026#34;Left\u0026#34;: 0.19536180794239044, \u0026#34;Height\u0026#34;: 0.8607867956161499 }, \u0026#34;Confidence\u0026#34;: 70.83800506591797 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.33079493045806885, \u0026#34;Top\u0026#34;: 0.004325739573687315, \u0026#34;Left\u0026#34;: 0.0, \u0026#34;Height\u0026#34;: 0.3973473012447357 }, \u0026#34;Confidence\u0026#34;: 60.03199005126953 } ], \u0026#34;Confidence\u0026#34;: 89.16603088378906, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.32997131347656, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.55190658569336, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.33173370361328, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.37184524536133, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Sea Life\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 63.10999298095703, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.42851257324219, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Waterfowl\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 3800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 66.54654693603516, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.92424011230469, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.050777435302734, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Aquatic\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.38773655891418457, \u0026#34;Top\u0026#34;: 0.12097299098968506, \u0026#34;Left\u0026#34;: 0.12352852523326874, \u0026#34;Height\u0026#34;: 0.7628968954086304 }, \u0026#34;Confidence\u0026#34;: 93.34445190429688 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.7438606023788452, \u0026#34;Top\u0026#34;: 0.11014620214700699, \u0026#34;Left\u0026#34;: 0.15275272727012634, \u0026#34;Height\u0026#34;: 0.8042365312576294 }, \u0026#34;Confidence\u0026#34;: 66.38320922851562 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.33265557885169983, \u0026#34;Top\u0026#34;: 0.0027915106620639563, \u0026#34;Left\u0026#34;: 0.0, \u0026#34;Height\u0026#34;: 0.3603067696094513 }, \u0026#34;Confidence\u0026#34;: 66.176025390625 } ], \u0026#34;Confidence\u0026#34;: 87.69349670410156, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 65.20291900634766, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.93068313598633, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.37018585205078, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.07685089111328, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Sea Life\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.50196838378906, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 74.234130859375, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 94.10073852539062, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 63.6142463684082, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Aquatic\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.3899807929992676, \u0026#34;Top\u0026#34;: 0.11104846745729446, \u0026#34;Left\u0026#34;: 0.13585709035396576, \u0026#34;Height\u0026#34;: 0.7780617475509644 }, \u0026#34;Confidence\u0026#34;: 69.82188415527344 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.7412311434745789, \u0026#34;Top\u0026#34;: 0.07028910517692566, \u0026#34;Left\u0026#34;: 0.1845070868730545, \u0026#34;Height\u0026#34;: 0.8762639164924622 }, \u0026#34;Confidence\u0026#34;: 61.936519622802734 } ], \u0026#34;Confidence\u0026#34;: 86.78479766845703, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 61.21832275390625, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 63.98245620727539, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 50.86898422241211, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 65.02304077148438, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.770111083984375, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Sea Life\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 63.6142463684082, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 81.00969696044922, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.77033233642578, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.46247863769531, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Aquatic\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 57.74924087524414, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.30696171522140503, \u0026#34;Top\u0026#34;: 0.144287109375, \u0026#34;Left\u0026#34;: 0.22396674752235413, \u0026#34;Height\u0026#34;: 0.7462866306304932 }, \u0026#34;Confidence\u0026#34;: 86.27051544189453 } ], \u0026#34;Confidence\u0026#34;: 86.7204818725586, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.02400207519531, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 62.43345260620117, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.2487907409668, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 66.2137680053711, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 58.16676712036133, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Sea Life\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.46247863769531, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4400, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 85.66663360595703, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.82898712158203, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 67.83256530761719, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Aquatic\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 59.0078239440918, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.3058396279811859, \u0026#34;Top\u0026#34;: 0.13702332973480225, \u0026#34;Left\u0026#34;: 0.2092207968235016, \u0026#34;Height\u0026#34;: 0.7735120058059692 }, \u0026#34;Confidence\u0026#34;: 89.72554016113281 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.17597775161266327, \u0026#34;Top\u0026#34;: 0.003950765356421471, \u0026#34;Left\u0026#34;: 0.15447595715522766, \u0026#34;Height\u0026#34;: 0.19859127700328827 }, \u0026#34;Confidence\u0026#34;: 72.09510040283203 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.31234344840049744, \u0026#34;Top\u0026#34;: 0.007410896942019463, \u0026#34;Left\u0026#34;: 0.002845072653144598, \u0026#34;Height\u0026#34;: 0.3882608711719513 }, \u0026#34;Confidence\u0026#34;: 70.87576293945312 } ], \u0026#34;Confidence\u0026#34;: 87.15044403076172, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 53.97991943359375, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Grass\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 61.05377197265625, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 57.4560661315918, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.12495803833008, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 60.812286376953125, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Sea Life\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 67.83256530761719, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4600, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 87.4284439086914, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.2036361694336, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.24736785888672, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Aquatic\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 61.71356964111328, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.30193066596984863, \u0026#34;Top\u0026#34;: 0.14368638396263123, \u0026#34;Left\u0026#34;: 0.20988507568836212, \u0026#34;Height\u0026#34;: 0.7614515423774719 }, \u0026#34;Confidence\u0026#34;: 92.7527847290039 }, { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.31587615609169006, \u0026#34;Top\u0026#34;: 0.007122527342289686, \u0026#34;Left\u0026#34;: 0.002042448613792658, \u0026#34;Height\u0026#34;: 0.38757696747779846 }, \u0026#34;Confidence\u0026#34;: 62.651546478271484 } ], \u0026#34;Confidence\u0026#34;: 90.06462860107422, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.28676986694336, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 62.933197021484375, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 56.79875564575195, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 55.53575897216797, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Sea Life\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.24736785888672, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 4800, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 86.41097259521484, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 93.97762298583984, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.58273315429688, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Aquatic\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.67484283447266, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.3098117709159851, \u0026#34;Top\u0026#34;: 0.17863719165325165, \u0026#34;Left\u0026#34;: 0.21030397713184357, \u0026#34;Height\u0026#34;: 0.7127665281295776 }, \u0026#34;Confidence\u0026#34;: 93.915283203125 } ], \u0026#34;Confidence\u0026#34;: 90.92428588867188, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.265533447265625, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Mammal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.71392822265625, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 54.23300552368164, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 59.28446578979492, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Sea Life\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 68.58273315429688, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5000, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 85.9736099243164, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 94.2772216796875, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.10331726074219, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Aquatic\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 67.0080337524414, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Beak\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [ { \u0026#34;BoundingBox\u0026#34;: { \u0026#34;Width\u0026#34;: 0.38834601640701294, \u0026#34;Top\u0026#34;: 0.17760764062404633, \u0026#34;Left\u0026#34;: 0.22096411883831024, \u0026#34;Height\u0026#34;: 0.7267040610313416 }, \u0026#34;Confidence\u0026#34;: 83.2437973022461 } ], \u0026#34;Confidence\u0026#34;: 91.10344696044922, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 66.91466522216797, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;Bird\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Penguin\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 52.75025939941406, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Plant\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 57.49009323120117, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Sea Life\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 64.10331726074219, \u0026#34;Parents\u0026#34;: [], \u0026#34;Name\u0026#34;: \u0026#34;Water\u0026#34; } }, { \u0026#34;Timestamp\u0026#34;: 5200, \u0026#34;Label\u0026#34;: { \u0026#34;Instances\u0026#34;: [], \u0026#34;Confidence\u0026#34;: 84.29118347167969, \u0026#34;Parents\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Animal\u0026#34; } ], \u0026#34;Name\u0026#34;: \u0026#34;Zoo\u0026#34; } } ], \u0026#34;LabelModelVersion\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;JobStatus\u0026#34;: \u0026#34;SUCCEEDED\u0026#34;, \u0026#34;VideoMetadata\u0026#34;: { \u0026#34;Format\u0026#34;: \u0026#34;QuickTime / MOV\u0026#34;, \u0026#34;FrameRate\u0026#34;: 25.0, \u0026#34;Codec\u0026#34;: \u0026#34;h264\u0026#34;, \u0026#34;DurationMillis\u0026#34;: 5280, \u0026#34;FrameHeight\u0026#34;: 720, \u0026#34;FrameWidth\u0026#34;: 1280 } } ","permalink":"https://brianpfeil.com/post/aws-rekognition/","postedOnDate":" July 8, 2019","tags":["aws"],"title":"AWS Rekognition"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-codebuild-local-playground  Resources  Announcing Local Build Support for AWS CodeBuild  Running # build CodeBuild image locally  git clone https://github.com/aws/aws-codebuild-docker-images.git cd aws-codebuild-docker-images/ubuntu/standard/2.0 docker build -t aws/codebuild/standard:2.0 . # pull CodeBuild local agent docker pull amazon/aws-codebuild-local:latest --disable-content-trust=false # cd to directory containing `buildspec.yml` # NOTE: script was previously downloaded to `~/bin/codebuild_build.sh` cd basic-01 codebuild_build.sh -i \u0026#39;aws/codebuild/standard:2.0\u0026#39; -a \u0026#39;artifact-output\u0026#39; -c ","permalink":"https://brianpfeil.com/post/aws-codebuild-local/","postedOnDate":" July 3, 2019","tags":["aws","codebuild"],"title":"AWS Codebuild Local"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/golang-debug-in-docker-with-delve-playground  based on Debugging Go using Delve, Docker and VS Code post\nmake run # or make build first # set breakpoint in vscode on line 18, then Debug | Start Debugging Resources  dlv debug cli docs  ","permalink":"https://brianpfeil.com/post/golang-debug-in-docker-with-delve/","postedOnDate":" June 24, 2019","tags":["golang","docker"],"title":"Golang Debug In Docker with Delve"},{"categories":["HTML","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/cognito-federated-to-salesforce-and-s3-presigned-url-playground  Login with Cognito Federated to Salesforce Example  see index.html see ~/Dropbox/notes/static-s3-cognito-authentication.md on local machine also for greater detail on setup  # local dev # start server. serves static files from current directory \u0026#39;.\u0026#39;. listens on ssl 443 sudo node server.js open https://localhost # on s3 open https://pfeil-static-site-01.s3.amazonaws.com/index.html # on cloudfront open https://d3tz189emgpc7c.cloudfront.net/index.html # copy updated file to s3 aws s3 cp index.html s3://pfeil-static-site-01/index.html # invalidate cloudfront dist after copy # if any login issues # clear site data for https://pfeil-dev-ed.my.salesforce.com in chrome dev tools Pre-signed URL Example  see index.js node index.js outputs pre-signed url. (uses ~/.aws/credentials and pre-signed URL generated under that users context/permission) PUT / upload file to S3 via curl -X PUT -T hello.txt -L '\u0026lt;pre-signed url\u0026gt;'  ","permalink":"https://brianpfeil.com/post/cognito-federated-to-salesforce-and-s3-presigned-url/","postedOnDate":" June 13, 2019","tags":["cognito","salesforce","s3"],"title":"Cognito Federated to Salesforce and S3 Presigned URL"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-kubernetes-service-aks-playground  learn azure kubernetes service\nRunning # create resource group az group create --name \u0026#34;pfeilbr-aks-01\u0026#34; --location eastus # create cluster az aks create \\  --resource-group \u0026#34;pfeilbr-aks-01\u0026#34; \\  --name \u0026#34;pfeilbr-aks-01\u0026#34; \\  --node-count 1 \\  --location eastus \\  --enable-addons monitoring \\  --generate-ssh-keys # set connectivity to cluster for kubectl az aks get-credentials --resource-group \u0026#34;pfeilbr-aks-01\u0026#34; --name \u0026#34;pfeilbr-aks-01\u0026#34; # list cluster nodes kubectl get nodes # deploy kubectl apply -f azure-vote.yaml # monitor deployment progress kubectl get service azure-vote-front --watch # open \u0026#34;EXTERNAL-IP\u0026#34; in browser to view webapp # delete cluster az group delete --name \u0026#34;pfeilbr-aks-01\u0026#34; --yes --no-wait ","permalink":"https://brianpfeil.com/post/azure-kubernetes-service-aks/","postedOnDate":" May 18, 2019","tags":["azure","kubernetes"],"title":"Azure Kubernetes Service AKS"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-nodejs-arm-resources-playground  manipulate azure resources (deployments, etc.) programmatically via nodejs\n","permalink":"https://brianpfeil.com/post/azure-nodejs-arm-resources/","postedOnDate":" May 15, 2019","tags":["azure","nodejs"],"title":"Azure Nodejs ARM Resources"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-cli-playground  azure cli usage examples\n# version info az -v # help az -h # find examples az find \u0026#34;az functionapp list\u0026#34; # interactive login az login # log in with a service principal using client secret. az login --service-principal -u http://azure-cli-2019-05-09-16-09-40 -p \u0026#39;[CLIENT_SECRET_HERE]\u0026#39; --tenant brianpfeilgmail.onmicrosoft.com az logout az account show az account show | jq \u0026#39;.tenantId\u0026#39; TENANT_ID=$(az account show --query tenantId --output tsv) az account list az account get-access-token az account list-locations # list account fields in table format az account list --output table --query \u0026#39;[].{Name:name, SubscriptionId:id, TenantId:tenantId}\u0026#39; # details of signed in user az ad signed-in-user show # ad az ad -h # ad service principals az ad sp -h # create a service principal and configure its access to Azure az ad sp create-for-rbac # list service principals az ad sp list # list service principals with subset of properties az ad sp list --query \u0026#34;[].{id:appId, tenant:appOwnerTenantId, name:displayName}\u0026#34; # list role assignments for service principal az role assignment list --assignee \u0026#39;http://azure-cli-2019-05-09-16-09-40\u0026#39; # list role assignments for user (user sign-in name) az role assignment list --assignee \u0026#39;dev01@brianpfeilgmail.onmicrosoft.com\u0026#39; # list role assignments for user (object id) az role assignment list --assignee \u0026#39;38d35c72-5a26-464c-bbb3-c4487a1d4779\u0026#39; # list role assignments for service principal az role assignment list --assignee \u0026#34;http://service-principal-01\u0026#34; # reset service principal password. if you forgot or lost it, this is the only way to get it. az ad sp credential reset --name \u0026#34;http://service-principal-01\u0026#34; # output # { # \u0026#34;appId\u0026#34;: \u0026#34;00133c8e-a08e-490e-ae7c-872ea2debf1e\u0026#34;, # \u0026#34;name\u0026#34;: \u0026#34;http://service-principal-01\u0026#34;, # \u0026#34;password\u0026#34;: \u0026#34;09tGSBcRsl_Gml7DI7VkRniFu_r_xxxxxx\u0026#34;, # \u0026#34;tenant\u0026#34;: \u0026#34;b0579be4-503f-48ca-9bd2-ca22100857dd\u0026#34; # } # login with service principal az login --service-principal --username \u0026#34;http://service-principal-01\u0026#34; --password \u0026#34;09tGSBcRsl_Gml7DI7VkRniFu_r_xxxxxx\u0026#34; --tenant \u0026#34;b0579be4-503f-48ca-9bd2-ca22100857dd\u0026#34; # get access token (bearer) # NOTE: must be logged in with `service-principal-01` above for this example # or may need to add client id to authorize application. see following screenshot # \u0026lt;https://www.evernote.com/l/AAFJLMG88QhDgqehvtS8P-qkVuCcmFFUhCMB/image.png\u0026gt; ACCESS_TOKEN=$(az account get-access-token --resource \u0026#39;https://brianpfeilmyfn01.azurewebsites.net\u0026#39;) # call endpoint protected by azure ad. e.g. functions function endpoint curl --header \u0026#34;Authorization: Bearer ${ACCESS_TOKEN}\u0026#34; https://brianpfeilmyfn01.azurewebsites.net/api/HttpExample # show service principal details az ad sp show --id \u0026#34;http://service-principal-01\u0026#34; # get access token (Bearer) that can be used as `Authorization` header # current user az account get-access-token # for specific resource az account get-access-token --resource \u0026#39;https://vault.azure.net\u0026#39; # list app registrations az ad app list --query \u0026#39;[].{displayName: displayName}\u0026#39; --output table # create resource group az group create --name \u0026#34;group01\u0026#34; --location eastus # list resource group names az group list | jq \u0026#39;.[].name\u0026#39; # delete resource group az group delete --name \u0026#34;group01\u0026#34; # deploy arm template examples az group deployment create --name \u0026#34;my-deployment-01\u0026#34; --resource-group \u0026#34;my-resource-group-01\u0026#34; --template-file template.json --parameters @parameters.json az group deployment create --name cosmosdbaccountdeployment01 --resource-group group01 --template-file azure-cosmos-db-account.json --parameters name=\u0026#34;account01\u0026#34; location=\u0026#34;eastus\u0026#34; locationName=\u0026#34;East US\u0026#34; defaultExperience=\u0026#34;DocumentDB\u0026#34; # interactive/repl mode. immediately exits / doesn\u0026#39;t work as of 2019-05-14 az interactive # list all resources az resource list az role assignment list az role definition list az role definition list --custom-role-only true --output json | jq \u0026#39;.[] | {\u0026#34;roleName\u0026#34;:.roleName, \u0026#34;roleType\u0026#34;:.roleType}\u0026#39; az role definition list | jq \u0026#39;.[].description\u0026#39; # list storage account az storage account list | jq \u0026#39;.[].name\u0026#39; ","permalink":"https://brianpfeil.com/post/azure-cli/","postedOnDate":" May 14, 2019","tags":["azure","cli"],"title":"Azure CLI"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-js-cognitive-services-playground  learn azure cognitive services\nExamples\nrunHandwrittenOCRForURL() - uses computer vision batchReadFile API to perform handwritten OCR on a image of a form (image sourced from public URL).\nResources  cognitive-services/computer-vision docs  Running  Create new cognitive services computer vision resource\nrun az login, then npm run provision\nOR via portal  Copy .env.sample to .env and populate with values via the following steps. CLIENT_ID, DOMAIN  SUBSCRIPTION_ID  COGNITIVE_SERVICES_ENDPOINT  COGNITIVE_SERVICES_KEY  run npm start  ","permalink":"https://brianpfeil.com/post/azure-js-cognitive-services/","postedOnDate":" May 13, 2019","tags":["azure","javascript"],"title":"Azure JS Cognitive Services"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-nodejs-arm-storage-playground  manipulate azure storage accounts programmatically via nodejs\nResources  Azure Storage modules for Node.js  ","permalink":"https://brianpfeil.com/post/azure-nodejs-arm-storage/","postedOnDate":" May 10, 2019","tags":["azure","nodejs"],"title":"Azure Nodejs ARM Storage"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-sdk-for-node-authentication-playground  learn authentication methods for azure sdk for nodejs\nService Principal Authentication  Based on azure-sdk-for-node/Documentation/Authentication.md\n   clientId, secret, and domain are defined in .env. Copy .env.sample to .env and populate with values via the following steps.\n  getting clientId and domain\nrun az ad sp list\n  getting / creating secret\nnavigate to Portal | Azure Active Directory | App registrations create new client secret if needed OR use existing   ","permalink":"https://brianpfeil.com/post/azure-sdk-for-node-authentication/","postedOnDate":" May 10, 2019","tags":["azure","sdk"],"title":"Azure SDK for Node Authentication"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-serverless-framework-playground   learn serverless framework for azure source @ src/services/hello-world see Azure - Credentials for getting setup  ","permalink":"https://brianpfeil.com/post/azure-serverless-framework/","postedOnDate":" May 10, 2019","tags":["azure","serverless"],"title":"Azure Serverless Framework"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/python-2.x-websocket-client-playground  learn python websocket-client module\nprerequisites  python 2.x node.js: for local websocket server. code is from https://glitch.com/~socketio-basic. uses ws: a Node.js WebSocket library virtualenv: pip install virtualenv or sudo pip install virtualenv  running # server (node.js) - run in own terminal (blocking) cd src/server npm i npm start # client - run in separate terminal cd src/client virtualenv venv source venv/bin/activate pip install -r requirements.txt python client.py example run\n","permalink":"https://brianpfeil.com/post/python-2.x-websocket-client/","postedOnDate":" May 10, 2019","tags":["python"],"title":"Python 2.X WebSocket Client"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/azure-cosmos-js-sdk-playground  learn azure cosmos db javascript sdk.\nRunning  provision resources # create group az group create --name group01 --location \u0026#34;East US\u0026#34; # create cosmos db account az group deployment create \\ --name cosmosdbaccountdeployment01 \\ --resource-group group01 \\ --template-file arm-templates/azure-cosmos-db-account.json \\ --parameters name=\u0026#34;account01\u0026#34; location=\u0026#34;eastus\u0026#34; locationName=\u0026#34;East US\u0026#34; defaultExperience=\u0026#34;DocumentDB\u0026#34;  copy .env.sample to .env and populate with your information from Keys  run npm start  ","permalink":"https://brianpfeil.com/post/azure-cosmos-js-sdk/","postedOnDate":" May 8, 2019","tags":["azure","javascript","sdk"],"title":"Azure Cosmos JS SDK"},{"categories":["CSS","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/gatsbyjs-playground  learn Gatsby\nPlugin custom plugin at plugins/gatsby-source-random\noriginal README.md from starter below\n  Gatsby's default starter  Kick off your project with this default boilerplate. This starter ships with the main Gatsby configuration files you might need to get up and running blazing fast with the blazing fast app generator for React.\nHave another more specific idea? You may want to check out our vibrant collection of official and community-created starters.\n🚀 Quick start   Create a Gatsby site.\nUse the Gatsby CLI to create a new site, specifying the default starter.\n# create a new Gatsby site using the default starter gatsby new my-default-starter https://github.com/gatsbyjs/gatsby-starter-default   Start developing.\nNavigate into your new site’s directory and start it up.\ncd my-default-starter/ gatsby develop   Open the source code and start editing!\nYour site is now running at http://localhost:8000!\nNote: You\u0026rsquo;ll also see a second link: http://localhost:8000/___graphql. This is a tool you can use to experiment with querying your data. Learn more about using this tool in the Gatsby tutorial.\nOpen the my-default-starter directory in your code editor of choice and edit src/pages/index.js. Save your changes and the browser will update in real time!\n  🧐 What\u0026rsquo;s inside? A quick look at the top-level files and directories you\u0026rsquo;ll see in a Gatsby project.\n. ├── node_modules ├── src ├── .gitignore ├── .prettierrc ├── gatsby-browser.js ├── gatsby-config.js ├── gatsby-node.js ├── gatsby-ssr.js ├── LICENSE ├── package-lock.json ├── package.json └── README.md    /node_modules: This directory contains all of the modules of code that your project depends on (npm packages) are automatically installed.\n  /src: This directory will contain all of the code related to what you will see on the front-end of your site (what you see in the browser) such as your site header or a page template. src is a convention for “source code”.\n  .gitignore: This file tells git which files it should not track / not maintain a version history for.\n  .prettierrc: This is a configuration file for Prettier. Prettier is a tool to help keep the formatting of your code consistent.\n  gatsby-browser.js: This file is where Gatsby expects to find any usage of the Gatsby browser APIs (if any). These allow customization/extension of default Gatsby settings affecting the browser.\n  gatsby-config.js: This is the main configuration file for a Gatsby site. This is where you can specify information about your site (metadata) like the site title and description, which Gatsby plugins you’d like to include, etc. (Check out the config docs for more detail).\n  gatsby-node.js: This file is where Gatsby expects to find any usage of the Gatsby Node APIs (if any). These allow customization/extension of default Gatsby settings affecting pieces of the site build process.\n  gatsby-ssr.js: This file is where Gatsby expects to find any usage of the Gatsby server-side rendering APIs (if any). These allow customization of default Gatsby settings affecting server-side rendering.\n  LICENSE: Gatsby is licensed under the MIT license.\n  package-lock.json (See package.json below, first). This is an automatically generated file based on the exact versions of your npm dependencies that were installed for your project. (You won’t change this file directly).\n  package.json: A manifest file for Node.js projects, which includes things like metadata (the project’s name, author, etc). This manifest is how npm knows which packages to install for your project.\n  README.md: A text file containing useful reference information about your project.\n  🎓 Learning Gatsby Looking for more guidance? Full documentation for Gatsby lives on the website. Here are some places to start:\n  For most developers, we recommend starting with our in-depth tutorial for creating a site with Gatsby. It starts with zero assumptions about your level of ability and walks through every step of the process.\n  To dive straight into code samples, head to our documentation. In particular, check out the Guides, API Reference, and Advanced Tutorials sections in the sidebar.\n  💫 Deploy \n","permalink":"https://brianpfeil.com/post/gatsbyjs/","postedOnDate":" March 9, 2019","tags":["gatsbyjs"],"title":"GatsbyJS"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/apollo-client-local-state-playground   Apollo client Local state management see src/App.js  ","permalink":"https://brianpfeil.com/post/apollo-client-local-state/","postedOnDate":" February 27, 2019","tags":["apollo"],"title":"Apollo Client Local State"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/jest-testing-framework-playground  ","permalink":"https://brianpfeil.com/post/jest-testing-framework/","postedOnDate":" February 23, 2019","tags":["jest"],"title":"Jest Testing Framework"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/glitch-local-development-playground  =================\nClick Show in the header to see your app live. Updates to your code will instantly deploy and update live.\nGlitch is the friendly community where you\u0026rsquo;ll build the app of your dreams. Glitch lets you instantly create, remix, edit, and host an app, bot or site, and you can invite collaborators or helpers to simultaneously edit code with you.\nFind out more about Glitch.\nYour Project On the front-end,\n edit public/client.js, public/style.css and views/index.html drag in assets, like images or music, to add them to your project  On the back-end,\n your app starts at server.js add frameworks and packages in package.json safely store app secrets in .env (nobody can see this but you and people you invite)  Made by Glitch \\ ゜o゜)ノ\n","permalink":"https://brianpfeil.com/post/glitch-local-development/","postedOnDate":" February 20, 2019","tags":["glitch"],"title":"Glitch Local Development"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/react-hooks-playground  learn React Hooks introduced in React 16.8\nsee src/App.tsx\n","permalink":"https://brianpfeil.com/post/react-hooks/","postedOnDate":" February 11, 2019","tags":["react"],"title":"React Hooks"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/pivotal-cloud-foundry-playground  learn Pivotal Cloud Foundry\nResources  PCF on your Local Workstation with PCF Dev tutorial Cloud Foundry Documentation Why Yes, Cloud Foundry IS Like Your Own Heroku!   Example Apps see README.md in subdirectories of apps/\n Notes  stacks is a prebuilt root file system (rootfs) that supports a specific operating system (https://docs.cloudfoundry.org/devguide/deploy-apps/stacks.html)  e.g. cflinuxfs3: The Linux cflinuxfs3 stack is derived from Ubuntu Bionic 18.04.\n  uses buildpacks to support different languages/run-times (based on heroku buildpack scheme). buildpacks are layered on top of stacks supports Deploy an App with Docker Restaging your app stops your app and restages it, by compiling a new droplet and starting it. Task: A task is an app or script whose code is included as part of a deployed app, but runs independently in its own container.   cf cli session cf help # install PCF Dev \u0026lt;https://pivotal.io/pcf-dev\u0026gt; ./pcfdev-v0.30.0+PCF1.11.0-osx # start environment (VM, etc). takes ~5 mins. cf dev start # To begin using PCF Dev, please run: # cf login -a https://api.local.pcfdev.io --skip-ssl-validation # Apps Manager URL: https://apps.local.pcfdev.io # Admin user =\u0026gt; Email: admin / Password: admin # Regular user =\u0026gt; Email: user / Password: pass cf login -a https://api.local.pcfdev.io --skip-ssl-validation # web UI open https://apps.local.pcfdev.io # login: admin/admin cd ~/dev # fetch sample git clone https://github.com/cloudfoundry-samples/spring-music cd spring-music # build ./gradlew assemble # deploy app cf push --hostname spring-music # show logs cf logs spring-music --recent # stream logs cf logs spring-music # view app resources cf app spring-music # show app ENV cf env spring-music # run a task (simple `ls`) cf run-task spring-music \u0026#34;ls\u0026#34; --name my-task # view task output cf logs spring-music --recent # list tasks for an app (running, failed, succeeded) cf tasks spring-music # cancel a task cf terminate-task spring-music TASK-ID # stop app cf stop spring-music # show routes cf routes # stop environment (VMs, etc.) cf dev stop  Screenshots login\n","permalink":"https://brianpfeil.com/post/pivotal-cloud-foundry/","postedOnDate":" January 31, 2019","tags":["paas"],"title":"Pivotal Cloud Foundry"},{"categories":["Shell","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/fswatch-playground   learn fswatch file change monitor github @ emcrisostomo/fswatch  Example Script see watch.sh\nExample Usage # get file path information for changed files fswatch -0 . # print file path information for each changed file on separate line fswatch -0 . | xargs -0 -n 1 -I {} echo {} ","permalink":"https://brianpfeil.com/post/fswatch/","postedOnDate":" January 29, 2019","tags":["tools"],"title":"fswatch"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/storybook-ui-development-environment-playground  learn Storybook UI Development Environment\nRunning  add stories to src/components/*.stories.js run storybook via npm run storybook  ","permalink":"https://brianpfeil.com/post/storybook-ui-development-environment/","postedOnDate":" January 25, 2019","tags":["react","ui","ui-components",""],"title":"Storybook UI Development Environment"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/jupyter-kernel-gateway-playground  learn Jupyter Kernel Gateway\nDevelopment # build image docker build -t pfeilbr/jupyter-kernel-gateway . # run docker run -it --rm -p 8888:8888 pfeilbr/jupyter-kernel-gateway # view swagger json open http://0.0.0.0:8888/api/swagger.json # expose to public internet ngrok http 8888 # view in swagger ui open https://petstore.swagger.io # enter https://NGROK_HOST/api/swagger.json in explore # e.g. # https://0278ef82.ngrok.io/api/swagger.json # needed to add CORS params in `docker-stacks-image/Dockerfile` `CMD` statement # running `browser-client-example.js` in chrome DevTools open http://0.0.0.0:8888/api/swagger.json # open DevTools and run code in Sources | Snippets # push docker image docker push pfeilbr/jupyter-kernel-gateway Screenshots ","permalink":"https://brianpfeil.com/post/jupyter-kernel-gateway/","postedOnDate":" January 19, 2019","tags":["jupyter"],"title":"Jupyter Kernel Gateway"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-api-gateway-websockets-serverless-playground  update 2019-10-03: websocket events are now \u0026ldquo;natively supported in serverless framework\u0026rdquo; no longer need to use serverless-websockets-plugin. see https://serverless.com/framework/docs/providers/aws/events/websocket/\nbelow uses serverless-websockets-plugin\n learn AWS API Gateway Websockets with serverless framework\n Using API Gateway WebSockets with the Serverless Framework serverless-websockets-plugin/example Control Access to a WebSocket API in API Gateway API Gateway Limits for Configuring and Running a WebSocket API  ","permalink":"https://brianpfeil.com/post/aws-api-gateway-websockets-serverless/","postedOnDate":" January 8, 2019","tags":["aws","serverless"],"title":"AWS API Gateway WebSockets Serverless"},{"categories":["Rust","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/rust-playground  learn Rust programming language\nPrerequisites  nodemon - enables compile and run on file change  Development # run on file(s) change (ensure `nodemon` is installed) # turn off dead_code warning nodemon --exec \u0026#34;RUSTFLAGS=\\\u0026#34;$RUSTFLAGS-A dead_code\\\u0026#34; cargo run\u0026#34; src/main.rs Resources  The Rust Programming Language book Rust by Example  ","permalink":"https://brianpfeil.com/post/rust/","postedOnDate":" December 21, 2018","tags":["rust"],"title":"Rust"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-codepipeline-playground  learn AWS CodePipeline\nUsing CodeBuild for a \u0026ldquo;custom\u0026rdquo; CodePipeline deploy phase CodeBuild gives you a amz linux server and you can run whatever you want. This is an example using it for the \u0026ldquo;deployment\u0026rdquo; phase.\n During the \u0026ldquo;build\u0026rdquo; phase in buildspec.yml, the post_build command runs mv deploy-buildspec.yml buildspec.yml. The newly renamed buildspec.yml is what gets used in the \u0026ldquo;deploy\u0026rdquo; phase.\n Exporting Pipeline Definition/Metadata  via CodePipeline.getPipeline method\n node scripts/get-pipeline.js \u0026gt; /pipeline-definition-export.json ","permalink":"https://brianpfeil.com/post/aws-codepipeline/","postedOnDate":" December 20, 2018","tags":["aws","codepipeline"],"title":"AWS CodePipeline"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/twit-twitter-api-client-playground  learn twit, the Twitter API Client for node. Supports both the REST and Streaming API.\nsee index.js for examples\nRunning cp .env.sample .env # update .env with your twitter developer consumer and access values (e.g. app defined @ https://developer.twitter.com) # Uncomment examples in `index.js` to run # dev / live reload npm run dev Resources  https://github.com/ttezel/twit https://developer.twitter.com/en/docs  ","permalink":"https://brianpfeil.com/post/twit-twitter-api-client/","postedOnDate":" November 19, 2018","tags":["twitter","api","nodejs"],"title":"Twit Twitter API Client"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-amplify-js-app-playground   learn AWS Amplify Framework getting started walkthrough @ https://aws-amplify.github.io/docs/js/start?ref=amplify-js-btn\u0026amp;platform=purejs  Session\nmkdir aws-amplify-js-app-playground cd aws-amplify-js-app-playground/\\\\n mkdir src touch package.json index.html webpack.config.js src/app.js touch README.md npm i npm start npm install --save aws-amplify amplify init amplify status amplify add analytics amplify push amplify add hosting amplify publish amplify status ","permalink":"https://brianpfeil.com/post/aws-amplify-js-app/","postedOnDate":" November 13, 2018","tags":["aws","amplify","javascript"],"title":"AWS Amplify JS App"},{"categories":["Dockerfile","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-ecr-playground   learn Amazon Elastic Container Registry Docker Basics for Amazon ECR tutorial  Session cd ~/projects mkdir aws-ecr-playground code aws-ecr-playground touch Dockerfile touch README.md docker build -t hello-world . touch .gitignore docker build -t hello-world . docker-machine ip docker run -p 80:80 hello-world docker-machine ip aws ecr create-repository --repository-name hello-world docker tag hello-world 529276214230.dkr.ecr.us-east-1.amazonaws.com/hello-world $(aws ecr get-login --no-include-email) docker push 529276214230.dkr.ecr.us-east-1.amazonaws.com/hello-world ","permalink":"https://brianpfeil.com/post/aws-ecr/","postedOnDate":" November 13, 2018","tags":["aws","ecr"],"title":"AWS ECR"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/dynogels-playground  learn dynogels - DynamoDB data mapper for node.js\n this code uses dynogels-promisified to leverage async/await. Promisifies by appending Async to each method name.\n ","permalink":"https://brianpfeil.com/post/dynogels/","postedOnDate":" October 22, 2018","tags":["aws","javascript","dynamodb"],"title":"Dynogels"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/node-jenkins-api-playground  project to learn node-jenkins\nInstall  npm install jenkins copy .env.sample to .env and update with \u0026ldquo;your\u0026rdquo; values  Run Examples node index.js\n shows getting details of job and building a job\n ","permalink":"https://brianpfeil.com/post/node-jenkins-api/","postedOnDate":" October 18, 2018","tags":["jenkins"],"title":"Node Jenkins API"},{"categories":["M4","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/autotools-playground  learn Autotools\n Autotools is composed of several tools: aclocal, autoconf, automake and others, belonging to two packages: Automake and Autoconf\n Prerequisites brew install automake\nBuild and Run brew install automake mkdir hello_world cd hello_world touch main.c touch configure.ac touch Makefile.am aclocal autoconf automake --add-missing ./configure make ./helloworld # make distrubution .tar.gz make dist # test that the distribution tarball make distcheck # Use Makefile to install the program make install Resources\n The magic behind configure, make, make install Using Autotools  ","permalink":"https://brianpfeil.com/post/autotools/","postedOnDate":" October 10, 2018","tags":["autotools"],"title":"Autotools"},{"categories":["CMake","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/vcpkg-playground  learn vcpkg C++ package manager\nsee README.md file(s) in sub diredctories\nResources\n https://github.com/Microsoft/vcpkg https://docs.microsoft.com/en-us/cpp/vcpkg  ","permalink":"https://brianpfeil.com/post/vcpkg/","postedOnDate":" September 27, 2018","tags":["cpp","package-manager"],"title":"Vcpkg"},{"categories":["C++","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-sdk-cpp-playground  learn aws-sdk-app C++ SDK\nsee README.md file(s) in subdirectories of src\ninstall aws-sdk-cpp cd ~/dev git clone https://github.com/aws/aws-sdk-cpp.git cd aws-sdk-cpp mkdir build cd build cmake .. make make install build and run example cd src/s3-example mkdir -p build \u0026amp;\u0026amp; cd build cmake .. \u0026amp;\u0026amp; make # run ./s3-example output\nKey Install File Locations\n /usr/local/lib/cmake/AWSSDK - cmake modules /usr/local/include - headers installed /usr/local/lib - libraries installed (e.g. libaws-cpp-sdk-core.dylib)  ","permalink":"https://brianpfeil.com/post/aws-sdk-cpp/","postedOnDate":" September 25, 2018","tags":["aws","sdk","cpp"],"title":"AWS SDK CPP"},{"categories":["C++","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/google-test-cpp-test-framework-playground  learn googletest / gtest C++ test framework\nsee README.md in each subdirectory under src\ngtest install # download source cd ~/dev curl -LO https://github.com/google/googletest/archive/release-1.8.1.zip unzip release-1.8.1.zip cd googletest-release-1.8.1 mkdir build cd build cmake .. make make install ","permalink":"https://brianpfeil.com/post/google-test-cpp-test-framework/","postedOnDate":" September 25, 2018","tags":["google","cpp"],"title":"Google Test CPP Test Framework"},{"categories":["C++","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/modern-cpp-playground  based on nesteruk/ModernCpp\n playground.cpp - main file scripts/ - build, run, etc. scripts   NOTE (to self): developed and ran on 2016 MacBook Pro. Depends on local file locations.\n development build and run on file contents change (live reload)\n# start watcher ./scripts/build-and-run-on-change playground.cpp # edit and save `playground.cpp` for live reload ","permalink":"https://brianpfeil.com/post/modern-cpp/","postedOnDate":" September 24, 2018","tags":["cpp"],"title":"Modern CPP"},{"categories":["Shell","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/v8-javascript-engine-playground  project to learn and develop with V8\n Root V8 source directory is @ ~/dev/v8 on local machine\n Build Source and Sample(s)  Follow steps at https://github.com/v8/v8/wiki/Building-from-Source up until, but not inlcuding tools/dev/v8gen.py ... generate \u0026ldquo;debug\u0026rdquo; build files tools/dev/v8gen.py x64.debug change contents of v8/out.gn/x64.debug/args.gn to is_debug = true target_cpu = \u0026#34;x64\u0026#34; v8_enable_backtrace = true v8_enable_slow_dchecks = true v8_optimized_debug = false v8_monolithic = true v8_use_external_startup_data = false is_component_build = false  needed to enable debugging\n  compile with ninja -C out.gn/x64.debug compile debug version of samples/hello-world.cc with g++ -g -I. -Iinclude samples/hello-world.cc -o out.gn/x64.debug/hello_world -lv8 -lv8_libbase -lv8_libplatform -licuuc -licui18n -Lout.gn/x64.debug/ -pthread -std=c++0x  -g enables debug version\n  move into output directory pushd out.gn/x64.debug set library path and run LD_LIBRARY_PATH=./ ./hello_world return to v8 root popd   Developing  configure: modify script/env for your setup build: ./scripts/build src/playground.cc run: ./scripts/run src/playground.cc build and run on change (dev): ./scripts/build-and-run-on-change src/playground.cc    vscode debugging launch.json configuration { \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;(lldb) Launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${workspaceFolder}/out.gn/x64.debug/hello_world\u0026#34;, \u0026#34;args\u0026#34;: [], \u0026#34;stopAtEntry\u0026#34;: false, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}/out.gn/x64.debug\u0026#34;, \u0026#34;environment\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;LD_LIBRARY_PATH\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;./\u0026#34;}], \u0026#34;externalConsole\u0026#34;: true, \u0026#34;MIMode\u0026#34;: \u0026#34;lldb\u0026#34; } ] }  ${workspaceFolder} is v8 root directory\n ","permalink":"https://brianpfeil.com/post/v8-javascript-engine/","postedOnDate":" September 21, 2018","tags":["v8"],"title":"V8 JavaScript Engine"},{"categories":["CMake","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/cmake-playground  project to learn CMake\nsee README.md file for each sub directory\n","permalink":"https://brianpfeil.com/post/cmake/","postedOnDate":" September 20, 2018","tags":["cmake"],"title":"CMake"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/lerna-playground  learn lerna A tool for managing JavaScript projects with multiple packages\nPrerequisites install lerna npm install --global lerna\nExample Workflow # init lerna repo mkdir lerna-playground cd lerna-playground git init lerna init # create mathlib cd packages mkdir mathlib cd mathlib npm init -f touch index.js # write mathlib code # create client that depends on mathlib cd .. mkdir client cd client npm init -f # add mathlib lerna add mathlib # create client code touch index.js # run client node index.js ","permalink":"https://brianpfeil.com/post/lerna/","postedOnDate":" September 2, 2018","tags":["nodejs","npm","tools"],"title":"Lerna"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/vuejs-webpack-playground   A Vue.js project\n Build Setup # install dependencies npm install # serve with hot reload at localhost:8080 npm run dev # build for production with minification npm run build # build for production and view the bundle analyzer report npm run build --report # run unit tests npm run unit # run e2e tests npm run e2e # run all tests npm test For a detailed explanation on how things work, check out the guide and docs for vue-loader.\n","permalink":"https://brianpfeil.com/post/vuejs-webpack/","postedOnDate":" September 1, 2018","tags":["vuejs"],"title":"VueJS webpack"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/webassembly-playground  ","permalink":"https://brianpfeil.com/post/webassembly/","postedOnDate":" August 22, 2018","tags":["webassembly"],"title":"WebAssembly"},{"categories":["C++","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/Lua-c-api-playground  learn and experiment with Lua C API\nsee Lua-c-api-playground/main.cpp\nXcode Project Config ","permalink":"https://brianpfeil.com/post/lua-c-api/","postedOnDate":" July 24, 2018","tags":["lua","c"],"title":"Lua C API"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-appsync-playground  learn and experiment with AWS AppSync, the managed GraphQL service.\nComponents  GraphQL Schema Resolvers  resolver request/response mapping templates   DataSources  DynamoDB, ElasticSearch, Lambda (as of 2018-06-09)    AppSync Resource Types  API  AWS::AppSync::GraphQLApi createGraphqlApi   Schema  AWS::AppSync::GraphQLSchema createType startSchemaCreation   DataSource  AWS::AppSync::DataSource createDataSource   Resolver  AWS::AppSync::Resolver createResolver   FunctionConfiguration  AWS::AppSync::FunctionConfiguration createFunction   ApiKey  AWS::AppSync::ApiKey createApiKey ApiCache  AWS::AppSync::ApiCache createApiCache      Resources  nabeelthedev/chat-app - example using CloudFormation for all AppSync and other resource provisioning. sbstjn/appsync-resolvers-example - Example project for AppSync, GraphQL, and AWS Lambda resolvers using Go. sbstjn/go-appsync-graphql-cloudformation - AWS AppSync GraphQL API Proxy with Lambda, CloudFormation, and SAM AWS JavaScript SDK | AWS.AppSync Build your own multi-user photo album app with React, GraphQL, and AWS Amplify gabehollombe-aws/react-graphql-amplify-blog-post serverless-appsync-plugin  example service urql - GraphQL client    ","permalink":"https://brianpfeil.com/post/aws-appsync/","postedOnDate":" June 9, 2018","tags":["aws"],"title":"AWS Appsync"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/json-schema-playground  project to learn JSON schema\n see main.spec.ts for examples run examples/tests npm run test or npm run test:watch uses Ajv schema validator  ","permalink":"https://brianpfeil.com/post/json-schema/","postedOnDate":" June 6, 2018","tags":["json"],"title":"JSON Schema"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/jenkins-pipeline-github-playground  learn and experiment with Jenkins automation server.\n# run docker run -p 8080:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home --privileged jenkins/jenkins:lts # open web ui open http://localhost:8080/job/projects/job/jenkins-pipeline-github-playground/configure github project example https://github.com/pfeilbr/jenkins-pipeline-github-playground\nscreenshots ","permalink":"https://brianpfeil.com/post/jenkins-pipeline-github/","postedOnDate":" May 30, 2018","tags":["jenkins"],"title":"Jenkins Pipeline GitHub"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/alexa-skills-playground  sage skill data driven skill. modify config.js then deploy\n NOTE: skills/sage/lambda/custom/config.js is generated. do not edit directly!\n # build cd skills/sage/lambda/custom npm install # deploy cd skills/sage npm run deploy  npm build generates models/en-US.json and lambda/custom/config.js scripts/run performs file generation   Development Workflow # configure ask cli ask init # create new skill ask new # clone an existing skill ask clone --skill-id amzn1.ask.skill.1aee9e3d-ec1c-4e07-8239-19fea42c3036 # deploy ask deploy  Payload Examples LaunchRequest Payload Example (simplified)\n{ \u0026#34;type\u0026#34;: \u0026#34;LaunchRequest\u0026#34;, \u0026#34;requestId\u0026#34;: \u0026#34;amzn1.echo-api.request.310bdf96-793a-4e14-b586-e8f680ffe52f\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2018-05-15T17:32:42Z\u0026#34;, \u0026#34;locale\u0026#34;: \u0026#34;en-US\u0026#34;, \u0026#34;shouldLinkResultBeReturned\u0026#34;: false } LaunchRequest Payload Example (full)\n{ \u0026#34;requestEnvelope\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;session\u0026#34;: { \u0026#34;new\u0026#34;: true, \u0026#34;sessionId\u0026#34;: \u0026#34;amzn1.echo-api.session.314b8ce7-06d6-4cd5-8822-7644d2f5a799\u0026#34;, \u0026#34;application\u0026#34;: { \u0026#34;applicationId\u0026#34;: \u0026#34;amzn1.ask.skill.1aee9e3d-ec1c-4e07-8239-19fea42c3036\u0026#34; }, \u0026#34;user\u0026#34;: { \u0026#34;userId\u0026#34;: \u0026#34;amzn1.ask.account.AFPKUMM66XYI7MZMSUYLSGUUJDILTGYDXEMEL2WFFLEIG2TIQIE3NSIDODHS7VW2UKCA4EYR2QQS6QDZA5FAKMIQI5ASRRAEEXMNFMF6KSYQYM6YSVZ4UGU52L3SMJ3T73LOQPSFYBTIUQRPBLOFFQPEGIW35AP2FMQP5IP55QR4M6LZ2RGEEHNORLF6GWJOD3VSZIQGNLIC4MI\u0026#34; } }, \u0026#34;context\u0026#34;: { \u0026#34;AudioPlayer\u0026#34;: { \u0026#34;playerActivity\u0026#34;: \u0026#34;IDLE\u0026#34; }, \u0026#34;Display\u0026#34;: { \u0026#34;token\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;System\u0026#34;: { \u0026#34;application\u0026#34;: { \u0026#34;applicationId\u0026#34;: \u0026#34;amzn1.ask.skill.1aee9e3d-ec1c-4e07-8239-19fea42c3036\u0026#34; }, \u0026#34;user\u0026#34;: { \u0026#34;userId\u0026#34;: \u0026#34;amzn1.ask.account.AFPKUMM66XYI7MZMSUYLSGUUJDILTGYDXEMEL2WFFLEIG2TIQIE3NSIDODHS7VW2UKCA4EYR2QQS6QDZA5FAKMIQI5ASRRAEEXMNFMF6KSYQYM6YSVZ4UGU52L3SMJ3T73LOQPSFYBTIUQRPBLOFFQPEGIW35AP2FMQP5IP55QR4M6LZ2RGEEHNORLF6GWJOD3VSZIQGNLIC4MI\u0026#34; }, \u0026#34;device\u0026#34;: { \u0026#34;deviceId\u0026#34;: \u0026#34;amzn1.ask.device.AEOU6OLEMMGRPZDLADWRH5FELI7QBDGR4XXXM2EGU53EJQWESEUGNQF7WZKY3SUJFR2SFLQ7DB2KUJ4QAXTYH2DJGWR3K36SPOIGNFVPTFHPHN34LBW234VMAU5IM5PJUFYCAI3QHPTUBAXZT6VIBPFBMXXX3BLQFNRO3IJ6WFVXBPDFAKRP6\u0026#34;, \u0026#34;supportedInterfaces\u0026#34;: { \u0026#34;AudioPlayer\u0026#34;: {}, \u0026#34;Display\u0026#34;: { \u0026#34;templateVersion\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;markupVersion\u0026#34;: \u0026#34;1.0\u0026#34; } } }, \u0026#34;apiEndpoint\u0026#34;: \u0026#34;https://api.amazonalexa.com\u0026#34;, \u0026#34;apiAccessToken\u0026#34;: \u0026#34;\u0026lt;REMOVED\u0026gt;\u0026#34; } }, \u0026#34;request\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;LaunchRequest\u0026#34;, \u0026#34;requestId\u0026#34;: \u0026#34;amzn1.echo-api.request.310bdf96-793a-4e14-b586-e8f680ffe52f\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2018-05-15T17:32:42Z\u0026#34;, \u0026#34;locale\u0026#34;: \u0026#34;en-US\u0026#34;, \u0026#34;shouldLinkResultBeReturned\u0026#34;: false } }, \u0026#34;context\u0026#34;: { \u0026#34;callbackWaitsForEmptyEventLoop\u0026#34;: true, \u0026#34;logGroupName\u0026#34;: \u0026#34;/aws/lambda/aws-serverless-repository-alexaskillskitnodejsfact-6CKGX2O4QCIR\u0026#34;, \u0026#34;logStreamName\u0026#34;: \u0026#34;2018/05/15/[$LATEST]239394be80f1496387bc6961cede7161\u0026#34;, \u0026#34;functionName\u0026#34;: \u0026#34;aws-serverless-repository-alexaskillskitnodejsfact-6CKGX2O4QCIR\u0026#34;, \u0026#34;memoryLimitInMB\u0026#34;: \u0026#34;128\u0026#34;, \u0026#34;functionVersion\u0026#34;: \u0026#34;$LATEST\u0026#34;, \u0026#34;invokeid\u0026#34;: \u0026#34;f8d0e1c0-5865-11e8-9638-0df1b13913aa\u0026#34;, \u0026#34;awsRequestId\u0026#34;: \u0026#34;f8d0e1c0-5865-11e8-9638-0df1b13913aa\u0026#34;, \u0026#34;invokedFunctionArn\u0026#34;: \u0026#34;arn:aws:lambda:us-east-1:529276214230:function:aws-serverless-repository-alexaskillskitnodejsfact-6CKGX2O4QCIR\u0026#34; }, \u0026#34;attributesManager\u0026#34;: {}, \u0026#34;responseBuilder\u0026#34;: {}, \u0026#34;serviceClientFactory\u0026#34;: { \u0026#34;apiConfiguration\u0026#34;: { \u0026#34;apiClient\u0026#34;: {}, \u0026#34;apiEndpoint\u0026#34;: \u0026#34;https://api.amazonalexa.com\u0026#34;, \u0026#34;authorizationValue\u0026#34;: \u0026#34;\u0026lt;REMOVED\u0026gt;\u0026#34; } } }  IntentRequest Payload Example (simplified)\n{ \u0026#34;type\u0026#34;: \u0026#34;IntentRequest\u0026#34;, \u0026#34;requestId\u0026#34;: \u0026#34;amzn1.echo-api.request.7bfbb240-78c3-4622-b255-53a8dcc34376\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2018-05-15T17:34:12Z\u0026#34;, \u0026#34;locale\u0026#34;: \u0026#34;en-US\u0026#34;, \u0026#34;intent\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;GetNewFactIntent\u0026#34;, \u0026#34;confirmationStatus\u0026#34;: \u0026#34;NONE\u0026#34; } } IntentRequest Payload Example (full)\n{ \u0026#34;requestEnvelope\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;session\u0026#34;: { \u0026#34;new\u0026#34;: true, \u0026#34;sessionId\u0026#34;: \u0026#34;amzn1.echo-api.session.204f5c22-869d-406e-bd59-9d866477cfcc\u0026#34;, \u0026#34;application\u0026#34;: { \u0026#34;applicationId\u0026#34;: \u0026#34;amzn1.ask.skill.1aee9e3d-ec1c-4e07-8239-19fea42c3036\u0026#34; }, \u0026#34;user\u0026#34;: { \u0026#34;userId\u0026#34;: \u0026#34;amzn1.ask.account.AFPKUMM66XYI7MZMSUYLSGUUJDILTGYDXEMEL2WFFLEIG2TIQIE3NSIDODHS7VW2UKCA4EYR2QQS6QDZA5FAKMIQI5ASRRAEEXMNFMF6KSYQYM6YSVZ4UGU52L3SMJ3T73LOQPSFYBTIUQRPBLOFFQPEGIW35AP2FMQP5IP55QR4M6LZ2RGEEHNORLF6GWJOD3VSZIQGNLIC4MI\u0026#34; } }, \u0026#34;context\u0026#34;: { \u0026#34;AudioPlayer\u0026#34;: { \u0026#34;playerActivity\u0026#34;: \u0026#34;IDLE\u0026#34; }, \u0026#34;Display\u0026#34;: { \u0026#34;token\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;System\u0026#34;: { \u0026#34;application\u0026#34;: { \u0026#34;applicationId\u0026#34;: \u0026#34;amzn1.ask.skill.1aee9e3d-ec1c-4e07-8239-19fea42c3036\u0026#34; }, \u0026#34;user\u0026#34;: { \u0026#34;userId\u0026#34;: \u0026#34;amzn1.ask.account.AFPKUMM66XYI7MZMSUYLSGUUJDILTGYDXEMEL2WFFLEIG2TIQIE3NSIDODHS7VW2UKCA4EYR2QQS6QDZA5FAKMIQI5ASRRAEEXMNFMF6KSYQYM6YSVZ4UGU52L3SMJ3T73LOQPSFYBTIUQRPBLOFFQPEGIW35AP2FMQP5IP55QR4M6LZ2RGEEHNORLF6GWJOD3VSZIQGNLIC4MI\u0026#34; }, \u0026#34;device\u0026#34;: { \u0026#34;deviceId\u0026#34;: \u0026#34;amzn1.ask.device.AEOU6OLEMMGRPZDLADWRH5FELI7QBDGR4XXXM2EGU53EJQWESEUGNQF7WZKY3SUJFR2SFLQ7DB2KUJ4QAXTYH2DJGWR3K36SPOIGNFVPTFHPHN34LBW234VMAU5IM5PJUFYCAI3QHPTUBAXZT6VIBPFBMXXX3BLQFNRO3IJ6WFVXBPDFAKRP6\u0026#34;, \u0026#34;supportedInterfaces\u0026#34;: { \u0026#34;AudioPlayer\u0026#34;: {}, \u0026#34;Display\u0026#34;: { \u0026#34;templateVersion\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;markupVersion\u0026#34;: \u0026#34;1.0\u0026#34; } } }, \u0026#34;apiEndpoint\u0026#34;: \u0026#34;https://api.amazonalexa.com\u0026#34;, \u0026#34;apiAccessToken\u0026#34;: \u0026#34;\u0026lt;REMOVED\u0026gt;\u0026#34; } }, \u0026#34;request\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;IntentRequest\u0026#34;, \u0026#34;requestId\u0026#34;: \u0026#34;amzn1.echo-api.request.7bfbb240-78c3-4622-b255-53a8dcc34376\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2018-05-15T17:34:12Z\u0026#34;, \u0026#34;locale\u0026#34;: \u0026#34;en-US\u0026#34;, \u0026#34;intent\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;GetNewFactIntent\u0026#34;, \u0026#34;confirmationStatus\u0026#34;: \u0026#34;NONE\u0026#34; } } }, \u0026#34;context\u0026#34;: { \u0026#34;callbackWaitsForEmptyEventLoop\u0026#34;: true, \u0026#34;logGroupName\u0026#34;: \u0026#34;/aws/lambda/aws-serverless-repository-alexaskillskitnodejsfact-6CKGX2O4QCIR\u0026#34;, \u0026#34;logStreamName\u0026#34;: \u0026#34;2018/05/15/[$LATEST]239394be80f1496387bc6961cede7161\u0026#34;, \u0026#34;functionName\u0026#34;: \u0026#34;aws-serverless-repository-alexaskillskitnodejsfact-6CKGX2O4QCIR\u0026#34;, \u0026#34;memoryLimitInMB\u0026#34;: \u0026#34;128\u0026#34;, \u0026#34;functionVersion\u0026#34;: \u0026#34;$LATEST\u0026#34;, \u0026#34;invokeid\u0026#34;: \u0026#34;2e99cd8c-5866-11e8-ac6c-091c252114f4\u0026#34;, \u0026#34;awsRequestId\u0026#34;: \u0026#34;2e99cd8c-5866-11e8-ac6c-091c252114f4\u0026#34;, \u0026#34;invokedFunctionArn\u0026#34;: \u0026#34;arn:aws:lambda:us-east-1:529276214230:function:aws-serverless-repository-alexaskillskitnodejsfact-6CKGX2O4QCIR\u0026#34; }, \u0026#34;attributesManager\u0026#34;: {}, \u0026#34;responseBuilder\u0026#34;: {}, \u0026#34;serviceClientFactory\u0026#34;: { \u0026#34;apiConfiguration\u0026#34;: { \u0026#34;apiClient\u0026#34;: {}, \u0026#34;apiEndpoint\u0026#34;: \u0026#34;https://api.amazonalexa.com\u0026#34;, \u0026#34;authorizationValue\u0026#34;: \u0026#34;\u0026lt;REMOVED\u0026gt;\u0026#34; } } } ","permalink":"https://brianpfeil.com/post/alexa-skills/","postedOnDate":" May 17, 2018","tags":["aws","alexa"],"title":"Alexa Skills"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/graphql-playground  project to learn and experiment with graphql using Apollo\nserver  location - `src/server' entrypoint - src/server/index.ts dev (reload on change) - npm run dev run - npm start  client  location - `src/client' entrypoint - src/client/App.tsx run - npm start   ensure server is running on port 3000\n Examples Run via GraphiQL @ http://localhost:3000/graphiql\nquery { books { id, title, author } } mutation { createBook(title: \u0026#34;How To\u0026#34;, author: \u0026#34;John Doe\u0026#34;) { id, title author } } subscription onBookAdded { bookAdded { id title author } } Screenshots subscriptiion push over websocket\nScratch ","permalink":"https://brianpfeil.com/post/graphql/","postedOnDate":" April 30, 2018","tags":["graphql"],"title":"GraphQL"},{"categories":["C++","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/sfml-macos-playground  learn SFML, the Simple and Fast Multimedia Library\n","permalink":"https://brianpfeil.com/post/sfml-macos/","postedOnDate":" February 27, 2018","tags":["macos","graphics","cpp"],"title":"SFML MacOS"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-iot-playground  learn and experiment with AWS IoT\nuses aws-iot-device-sdk-js for programmatic access. see index.js copy .env.template to .env and populate with your values\n Object Hierarchy\nthing -\u0026gt; certificate -\u0026gt; policy\n","permalink":"https://brianpfeil.com/post/aws-iot/","postedOnDate":" February 10, 2018","tags":["aws","iot"],"title":"AWS IoT"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-iam-playground  serverless-project-policy-templates/ - serverless project policy templates for the various roles (admin, support, lambda, apigateway). they aim to isolate permissions by matching resources against a project prefix\n","permalink":"https://brianpfeil.com/post/aws-iam/","postedOnDate":" February 8, 2018","tags":["aws","iam"],"title":"AWS IAM"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-emr-playground  examples of using aws-emr. hive, pig, spark, etc.\nDynamodb Export/Import to/from S3 Examples -- link hive table to dynamodb table CREATEEXTERNALTABLEhiveLogTable(idstring,datastring)STOREDBY\u0026#39;org.apache.hadoop.hive.dynamodb.DynamoDBStorageHandler\u0026#39;TBLPROPERTIES(\u0026#34;dynamodb.table.name\u0026#34;=\u0026#34;log\u0026#34;,\u0026#34;dynamodb.column.mapping\u0026#34;=\u0026#34;id:id,data:data\u0026#34;);-- query dynamodb table using hive SQL SELECT*FROMhiveLogTable;-- export dynamodb table to s3 INSERTOVERWRITEDIRECTORY\u0026#39;s3://com.brianpfeil.scratch/emr/dynamodb/export/table/log/\u0026#39;SELECT*FROMhiveLogTable;-- create export table that will be comma delimited CREATEEXTERNALTABLEs3_export(idstring,datastring)ROWFORMATDELIMITEDFIELDSTERMINATEDBY\u0026#39;,\u0026#39;LOCATION\u0026#39;s3://com.brianpfeil.scratch/emr/dynamodb/export/table/log/\u0026#39;;-- export dynamodb table to s3 as comman delimited file (csv) INSERTOVERWRITETABLEs3_exportSELECT*FROMhiveLogTable;-- link hive table to s3 path CREATEEXTERNALTABLEs3_import(idstring,datastring)ROWFORMATDELIMITEDFIELDSTERMINATEDBY\u0026#39;,\u0026#39;LOCATION\u0026#39;s3://com.brianpfeil.scratch/emr/dynamodb/export/table/log/\u0026#39;;-- import csv data from s3 into dynamodb table INSERTOVERWRITETABLEhiveLogTableSELECT*FROMs3_import;","permalink":"https://brianpfeil.com/post/aws-emr/","postedOnDate":" February 3, 2018","tags":["aws","emr"],"title":"AWS Emr"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/golang-dep-playground  project to learn to use dep the dependency management tool for go\n# create new project dep init # add new import(s) in source code # pull down imports into ./vendor/ dep ensure # can always run `dep ensure` to sync everything up ","permalink":"https://brianpfeil.com/post/golang-dep/","postedOnDate":" February 3, 2018","tags":["golang"],"title":"Golang Dep"},{"categories":["Jupyter Notebook","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/imagenet-playground  project to explore ImageNet image data for ML applications\nRunning run jupyter notebook via kjupyter command\nsee imagenet-classify.ipynb\n","permalink":"https://brianpfeil.com/post/imagenet/","postedOnDate":" January 31, 2018","tags":["machine-learning","python"],"title":"Imagenet"},{"categories":["Jupyter Notebook","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/opencv-python-playground  code is split between jupyter notebook(s) and python (.py) files\nto create virtualenv (only required for first time setup) python3 -m venv .env Running activate virtualenv\nsource .env/bin/activate display webcam video\npython opencv-webcam.py example run screenshot ","permalink":"https://brianpfeil.com/post/opencv-python/","postedOnDate":" January 31, 2018","tags":["opencv","python"],"title":"OpenCV Python"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-ecs-playground  learn AWS ECS\nSession Steps  following steps are based on http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_CLI_tutorial.html\n # configure ecs-cli ecs-cli configure profile --profile-name ecs-cluster-01 --access-key \u0026lt;YOUR KEY\u0026gt; --secret-key \u0026lt;YOUR SECRET\u0026gt; ecs-cli configure --cluster cluster01 --region us-east-1 --config-name cluster01 # create 1 node cluster ecs-cli up --keypair brianpfeil --capability-iam --size 1 --instance-type t2.micro # create node app cd simple-node docker build -t pfeilbr/simple-node . docker push pfeilbr/simple-node # NOTE: pfeilbr/simple-node docker image is referenced by docker-compose.yml ecs-cli compose up ecs-cli ps # shows ip and port. see https://www.evernote.com/l/AAET15kkH-dNhoxA67iDXzzSmR6DBjWtC00B/image.png open http://34.237.144.74 # see https://www.evernote.com/l/AAE7iN32poNDwJTGe6T8QYX875Rz4jbJwHYB/image.png ecs-cli compose down # make changes to server.js # rebuild image docker build -t pfeilbr/simple-node . # test locally docker run -p 49160:8080 -d pfeilbr/simple-node # open locally open http://localhost:49160 # push docker push pfeilbr/simple-node # make changes to docker-compose.yml if neccessary ecs-cli compose up # scale cluster to 2 nodes ecs-cli scale --capability-iam --size 2 # scale simple-node across 2 nodes ecs-cli compose scale 2 # create a service. defaults to 1 task. # if task dies, service will automatically restart it # e.g. try /kill path of web app, which calls process.exit(1).  # it will start a new container instance within a few seconds ecs-cli compose service up # be sure to run \u0026#34;ecs-cli compose down\u0026#34; first # delete service ecs-cli compose service down # delete cluster ecs-cli down --force Resources  Installing the Amazon ECS CLI Configuring the Amazon ECS CLI Amazon ECS CLI Tutorial Dockerizing a Node.js web app  ","permalink":"https://brianpfeil.com/post/aws-ecs/","postedOnDate":" November 11, 2017","tags":["aws","ecs"],"title":"AWS ECS"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/serverless-python-playground  experiment with the serverless framework using python\nbased on https://serverless.com/blog/serverless-python-packaging/\nsession\n# install `serverless framework` if not already installed npm install serverless -g # create serverless python project serverless create --template aws-python3 --name numpy-test --path numpy-test cd numpy-test # create isolated virtualenv virtualenv venv --python=python3 touch handler.py code . # add code for `handler.py` # activate virtualenv source venv/bin/activate # run to test python handler.py pip install numpy # save dependencies pip freeze \u0026gt; requirements.txt cat requirements.txt # install dependencies (don\u0026#39;t need to execute if starting from scratch) pip install -r requirements.txt python handler.py npm init --force # add serverless `serverless-python-requirements` plugin npm install --save serverless-python-requirements # deploy sls deploy # invoke lambda and output log sls invoke -f numpy --log # cleanup sls remove ","permalink":"https://brianpfeil.com/post/serverless-python/","postedOnDate":" November 10, 2017","tags":["serverless","python"],"title":"Serverless Python"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/boto-playground  learn and experiment with Boto 3 / AWS SDK for Python\nInitial setup\ngit clone \u0026lt;this repo\u0026gt; # ensure python 3.x python3 -m venv venv source venv/bin/activate # install dependencies pip install boto3 pip install -U python-dotenv # save dependencies pip freeze \u0026gt; requirements.txt Running\n# setup virtualenv source venv/bin/activate pip install -r requirements.txt # run script python s3-example.py # exit virtualenv / deactivate deactivate ","permalink":"https://brianpfeil.com/post/boto/","postedOnDate":" October 30, 2017","tags":["boto"],"title":"Boto"},{"categories":["Java","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/minecraft-spigot-plugin-playground  Learn plugin development for the spigot minecraft server.\nProject Setup and Configuration see Creating a blank Spigot plugin in IntelliJIDEA\nAdd spigot.jar Artifacts Remote Debug Configuration Developing (hot swap/live coding)  launch minecraft server in debug mode  cd ./minecraft-spigot-server ./start.command # java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 -jar spigot-1.12.2.jar Launch Debug confifguration in IntelliJ   Set breakpoints, etc. in code\n  Launch minecraft and play\n  Breakpoints will be hit.\nUse Evaluate Code Fragment to explore while debugger is paused   You can edit code, save, and build (cmd-F9). It\u0026rsquo;ll live apply/hot swap without stopping server.\n  Resources  https://www.spigotmc.org/wiki/intellij-debug-your-plugin/  ","permalink":"https://brianpfeil.com/post/minecraft-spigot-plugin/","postedOnDate":" October 29, 2017","tags":["minecraft"],"title":"Minecraft Spigot Plugin"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/pusher-playground  learn pusher\nRun Client https://jsbin.com/modutol/edit?html,js,output\nServer triggered event node index.js # this will cause alert with message in client web browser ","permalink":"https://brianpfeil.com/post/pusher/","postedOnDate":" October 21, 2017","tags":["javascript","real-time"],"title":"Pusher"},{"categories":["Jupyter Notebook","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/deep-and-machine-learning-playground  docker image + jupyter notebook UI for learning and experimenting with deep and machine learning.\ndocker image based on https://github.com/floydhub/dl-docker - All-in-one Docker image for Deep Learning\ndocker hub image @ https://hub.docker.com/r/pfeilbr/deep-and-machine-learning/\nRunning docker run -it -p 8888:8888 -p 6006:6006 -v /Users/brianpfeil/projects/deep-and-machine-learning-playground:/root/sharedfolder pfeilbr/deep-and-machine-learning:v2 bash # this lands you at a bash prompt in the container # start jupyter jupyter notebook # open browser to http://localhost:8888/ To save container changes for example to save software installs (e.g. apache mxnet was added to image)\n# list images to find commit id docker ps -a # commit changes # docker commit 5b4a6fb7117b pfeilbr/deep-and-machine-learning:TAG # e.g.  docker commit 5b4a6fb7117b pfeilbr/deep-and-machine-learning:v2 # push new image to docker hub # docker push pfeilbr/deep-and-machine-learning:TAG # e.g. docker push pfeilbr/deep-and-machine-learning:v2 ","permalink":"https://brianpfeil.com/post/deep-and-machine-learning/","postedOnDate":" September 24, 2017","tags":["machine-learning","python"],"title":"Deep and Machine Learning"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/jupyter-playground  learn and experiment with jupyter notebooks\njupyterlab (early preview as of this - 2017-09-09) # install conda install -c conda-forge jupyterlab # run jupyter lab # notebook server now running @ http://localhost:8888 screenshots\njupyter notebook (classic UI) # run jupyter notebook screenshots\njupyter qtconsole  The Qt console is a very lightweight application that largely feels like a terminal, but provides a number of enhancements only possible in a GUI, such as inline figures, proper multi-line editing with syntax highlighting, graphical calltips, and much more. The Qt console can use any Jupyter kernel.\n # install conda install qtconsole conda install pyqt # run jupyter qtconsole screenshots\nIJavascript Kernel IJavascript is a Javascript kernel (node.js) for the Jupyter notebook\n# install npm install -g ijavascript # registers the IJavascript kernel with Jupyter ijsinstall screenshots\n","permalink":"https://brianpfeil.com/post/jupyter/","postedOnDate":" September 9, 2017","tags":["jupyter"],"title":"Jupyter"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-kms-playground  learn how to use kms to encrypt and decrypt data\nsee index.js\n","permalink":"https://brianpfeil.com/post/aws-kms/","postedOnDate":" August 31, 2017","tags":["aws","kms"],"title":"AWS KMS"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/scribbletune-playground  learn Scribbletune. Generate musical patterns with JavaScript and export as MIDI files using Node.js\n install timidity command line midi player via brew install timidity timidity man docs  ","permalink":"https://brianpfeil.com/post/scribbletune/","postedOnDate":" August 26, 2017","tags":["nodejs","music"],"title":"Scribbletune"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/puppeteer-playground  learn puppeteer\n Puppeteer is a Node library which provides a high-level API to control headless Chrome over the DevTools Protocol. It can also be configured to use full (non-headless) Chrome.\n see examples\n","permalink":"https://brianpfeil.com/post/puppeteer/","postedOnDate":" August 22, 2017","tags":["testing","browser"],"title":"Puppeteer"},{"categories":["HTML","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/s3-website-playground  learn s3-website npm module\nusage session\n# install deps npm install # create static website ./node_modules/s3-website/s3-website.js create # deploy static website com.brianpfeil.s3-website-playground.site01 ./node_modules/s3-website/s3-website.js deploy # view  open http://com.brianpfeil.s3-website-playground.site01.s3-website-us-east-1.amazonaws.com # NOTE: using `./node_modules/s3-website/s3-website.js` to avoid global install and # doesn\u0026#39;t work with `npx` because of https://www.evernote.com/l/AAH8gou8OCZKF6rfnqA2Tom3BU7c0xuFTM0B/image.png ","permalink":"https://brianpfeil.com/post/s3-website/","postedOnDate":" August 17, 2017","tags":["s3","aws","static-site"],"title":"S3 Website"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/react-router-4-playground  project to learn and experiment with react-router 4\n built with create-react-app see src/index.js  install deps and run\n$ yarn $ yarn start upgrade all deps\n$ yarn upgrade react react-dom react-redux react-router react-router-dom react-router-redux redux react-scripts ","permalink":"https://brianpfeil.com/post/react-router-4/","postedOnDate":" July 29, 2017","tags":["react"],"title":"React Router 4"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/aws-kinesis-playground  learn aws kinesis\nexample session   create kinesis stream   create lambda (logs stream event)   kinesis stream triggers lambda   put a record to kinesis stream via cli   get shard iterator via cli   get records via cli\n)\n  view event in lambda cloudwatch logs   ","permalink":"https://brianpfeil.com/post/aws-kinesis/","postedOnDate":" July 18, 2017","tags":["aws","kinesis"],"title":"AWS Kinesis"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/serverless-typescript-webpack-playground  project to learn/explore serverless + typescript + webpack\nSession example testing and deployment session\n# cd to service dir cd src/services/logger # local test ../../../node_modules/.bin/sls webpack invoke -f scan --data \u0026#39;{\u0026#34;key1\u0026#34;:\u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;:\u0026#34;value2\u0026#34;}\u0026#39; # deploy ../../../node_modules/.bin/sls deploy # test logger endpoint - create log item curl -d \u0026#39;{\u0026#34;key1\u0026#34;:\u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;:\u0026#34;value2\u0026#34;}\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -X POST https://4qodphulj8.execute-api.us-east-1.amazonaws.com/dev/logger # lambda-limits service # invoke concurrent lambda executions test # ***warning** understand/check resource usage curl -X POST https://m1v5komsge.execute-api.us-east-1.amazonaws.com/dev/lambda-limits/concurrent # kinesis-playground # PUT record curl -d \u0026#39;{\u0026#34;key1\u0026#34;:\u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;:\u0026#34;value2\u0026#34;}\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -X POST https://ijkemqb2r8.execute-api.us-east-1.amazonaws.com/dev/stream/put # tail remote logs ../../../node_modules/.bin/sls logs -f hello -t Notes   updated tsconfig.json with \u0026quot;target\u0026quot;: \u0026quot;es2015\u0026quot;\n  needed to add the following for webpack + awesome-typescript-loader to run without errors\nyarn add @types/node --dev yarn add @types/async --dev   ","permalink":"https://brianpfeil.com/post/serverless-typescript-webpack/","postedOnDate":" July 11, 2017","tags":["serverless","typescript"],"title":"Serverless TypeScript webpack"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/ethereum-playground  learn and experiment with Ethereum decentralized blockchain based platform\nTODO  walk all the testnet transaction and get counts of the addresses to see which addresses produce the most transactions walk all testnet transactions and plot transaction count over time for the top X% of addresses that produce the most transactions  Files and Directories of Interest Production\n~/Library/Ethereum ~/Library/Ethereum/geth/chaindata TEST-NET\n~/Library/Ethereum/testnet ~/Library/Ethereum/testnet/geth/chaindata Ethereum Wallet Ethereum Wallet Screenshot\nGeth CLI command line interface for running a full ethereum node\n# attach to existing geth instance (e.g. Ethereum Wallet GUI app\u0026#39;s geth instance). opens up a javascript repl geth attach # js console geth console # open testnet console geth --testnet console Ethereum Block Explorer  production - https://etherscan.io/ testnet - https://testnet.etherscan.io/  Ethereum Javascript API  Web3 JavaScript Ðapp API web3.js npm module  ","permalink":"https://brianpfeil.com/post/ethereum/","postedOnDate":" January 17, 2017","tags":["blockchain","cryptocurrency"],"title":"Ethereum"},{"categories":["Lua","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/lua-playground  learn and experiment with the Lua programming language\nResources  Learn Lua in 15 Minutes Lua - Object Oriented - Tutorialspoint  ","permalink":"https://brianpfeil.com/post/lua/","postedOnDate":" January 10, 2017","tags":["lua"],"title":"Lua"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/node-google-cloud-playground   Speech API  ","permalink":"https://brianpfeil.com/post/node-google-cloud/","postedOnDate":" December 9, 2016","tags":["google"],"title":"Node Google Cloud"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/apex-lambda-playground  learn Apex serverless architecture\nExample Session\napex init apex deploy apex logs --follow apex invoke hello echo -n \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;brian\u0026#34;}\u0026#39; | apex invoke hello apex list echo -n \u0026#39;{\u0026#34;q\u0026#34;: \u0026#34;heroku\u0026#34;}\u0026#39; | apex invoke search # file upload example # see screenshot of how to access file contents from lambda @ # http://static-content-01.s3-website-us-east-1.amazonaws.com/2__apex_logs_-f__apex__1DF7126D.png curl -i -F name=test -F filedata=@README.md https://UPDATEME.execute-api.us-east-1.amazonaws.com/prod/playground_api-gateway ","permalink":"https://brianpfeil.com/post/apex-lambda/","postedOnDate":" December 6, 2016","tags":["apex","lambda"],"title":"Apex Lambda"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/heroku-container-playground  Learn heroku container support. Based on Heroku Container Registry and Runtime article\n# install container support heroku plugins:install heroku-container-registry # login to registry heroku container:login # build docker build -t my-nodejs-app . # run docker run -it --rm -p 8000:8000 --name my-running-app my-nodejs-app # visit http://localhost:8000 # create heroku app heroku create # push. NOTE: app name of \u0026#34;stormy-badlands-73151\u0026#34; will be different heroku container:push web --app stormy-badlands-73151 # check that it is up and running heroku ps --app stormy-badlands-73151 # visit in browser heroku open --app stormy-badlands-73151 # update flow # make change to `server.js` # build and push heroku container:push web --app stormy-badlands-73151 ","permalink":"https://brianpfeil.com/post/heroku-container/","postedOnDate":" November 4, 2016","tags":["heroku"],"title":"Heroku Container"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/nextjs-playground  Learn Next.js, a small framework for server-rendered universal JavaScript webapps, built on top of React, Webpack and Babel\nDeveloping $ npm run dev ","permalink":"https://brianpfeil.com/post/nextjs/","postedOnDate":" November 1, 2016","tags":["javascript","react"],"title":"NextJS"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/keystonejs-playground  Learn and experiment with KeystoneJS\nInstall and Run $ npm install # create dir for mongodb files $ mkdir -p data/db # start mongodb $ mongod --dbpath data/db \u0026amp; # start webapp $ node keystone.js # visit http://localhost:3000/ Admin Login\nEmail: brian.pfeil@gmail.com Password: admin  ","permalink":"https://brianpfeil.com/post/keystonejs/","postedOnDate":" October 20, 2016","tags":["javascript","ui","framework"],"title":"KeystoneJS"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/kubernetes-playground  learn kubernetes. based on tutorial at http://kubernetes.io/docs/tutorials/kubernetes-basics\nInstall and start minikube $ cd ~/tmp $ curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.11.0/minikube-darwin-amd64 \u0026amp;\u0026amp; chmod +x minikube \u0026amp;\u0026amp; sudo mv minikube /usr/local/bin/ # verify install $ minikube version # start $ minikube start  minikube VMs, etc. are stored in ~/.minikube\n $ tree ~/.minikube . ├── addons ├── apiserver.crt ├── apiserver.key ├── ca.crt ├── ca.key ├── ca.pem ├── cache │ ├── iso │ │ └── minikube-0.7.iso │ └── localkube ├── cert.pem ├── certs │ ├── ca-key.pem │ ├── ca.pem │ ├── cert.pem │ └── key.pem ├── config ├── key.pem └── machines ├── minikube │ ├── boot2docker.iso │ ├── config.json │ ├── disk.vmdk │ ├── id_rsa │ ├── id_rsa.pub │ └── minikube │ ├── Logs │ │ └── VBox.log │ ├── minikube.vbox │ └── minikube.vbox-prev ├── server-key.pem └── server.pem REST API start proxy to allow access\n$ kubectl proxy Access API\n$ curl http://127.0.0.1:8001/api { \u0026#34;kind\u0026#34;: \u0026#34;APIVersions\u0026#34;, \u0026#34;versions\u0026#34;: [ \u0026#34;v1\u0026#34; ], \u0026#34;serverAddressByClientCIDRs\u0026#34;: [ { \u0026#34;clientCIDR\u0026#34;: \u0026#34;0.0.0.0/0\u0026#34;, \u0026#34;serverAddress\u0026#34;: \u0026#34;10.0.2.15:8443\u0026#34; } ] }  visit API endpoint at http://127.0.0.1:8001/api visit kubernetes-dashboard at http://127.0.0.1:8001/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard/#/workload?namespace=default  Accessing Services The cluster ip address as exposed to host machine can be obtained via\n$ kubectl cluster-info ","permalink":"https://brianpfeil.com/post/kubernetes/","postedOnDate":" October 18, 2016","tags":["kubernetes"],"title":"Kubernetes"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/phaser-playground  project to learn the Phaser HTML5 game framework\nstackem game Simple drop and stack game\nPlay @ https://pfeilbr.github.io/phaser-playground/\nDeveloping # start live reload server live-server ","permalink":"https://brianpfeil.com/post/phaser/","postedOnDate":" August 2, 2016","tags":["javascript","game","framework"],"title":"Phaser"},{"categories":["C","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/emscripten-playground  learn and experiment with emscripten\nRunning  Follow the Download and install instructions Run the following  # base install location # ~/dev/emsdk_portable # source in environment to update PATH and make tools available # could add to .bash_profile to make available in all shells $ source ~/dev/emsdk_env.sh # needed to add python2 symlink (see https://github.com/kripken/emscripten/issues/3872) $ cd /usr/local/bin $ ln -s /usr/bin/python2.7 python2 # compile c file to javascript -\u0026gt; generates output/hello_world.js $ emcc hello_world.c -o output/hello_world.js $ node output/hello_world.js # compile c file and generate html to view it -\u0026gt; generates output/hello.html and output/hello.js # NOTE: overwrites $ emcc hello_world.c -o output/hello.html ","permalink":"https://brianpfeil.com/post/emscripten/","postedOnDate":" June 2, 2016","tags":["web-assembly","tools"],"title":"Emscripten"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/gitbook-playground  GitBook Toolchain Documentation\nSetup $ npm install gitbook-cli -g $ mkdir gitbook-playground $ cd gitbook-playground/ $ gitbook init # MAKE EDITS - see http://toolchain.gitbook.com/ # server via built-in webserver $ gitbook serve # generate pdf $ gitbook pdf ./ ./mybook.pdf Introduction Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nSection 1 Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nSubsection 1 Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nSection 2 Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nSubsection 1 Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n","permalink":"https://brianpfeil.com/post/gitbook/","postedOnDate":" May 20, 2016","tags":["react","documentation"],"title":"GitBook"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/typescript-node-playground  example app showing how to setup and develop a typescript based node app using the typings TypeScript Definition Manager\nInitial Setup $ npm init --force $ typings install --ambient node $ npm install request --save $ typings install --ambient request // tsc was complaining about `form-data` $ typings install --ambient form-data // for `Promise`, `Object.assign`, etc. $ typings install --ambient es6-shim // compile from .ts to .js $ tsc Developing // live re-compile and re-run on changes via nodemon $ npm run dev // NOTE: app will be ran 2xs on every change when editing in Atom since atom-typescript will re-compile also in addition to `tsc -w` in the `dev` npm script ","permalink":"https://brianpfeil.com/post/typescript-node/","postedOnDate":" May 18, 2016","tags":["typescript"],"title":"TypeScript Node"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/angular-cli-app-playground  learn and experiment with angular-cli\n","permalink":"https://brianpfeil.com/post/angular-cli-app/","postedOnDate":" May 9, 2016","tags":["angular","cli"],"title":"Angular CLI App"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/react-redux-playground  learn and experiment with\n react redux react-redux react-router-redux   Based on jackielii/simplest-redux-example\n Running  npm install npm start open http://localhost:8080/webpack-dev-server/ in the browser  Files  index.html - host page index.js - entry point main.css - styles webpack.config.js - webpack config  ","permalink":"https://brianpfeil.com/post/react-redux/","postedOnDate":" May 4, 2016","tags":["react"],"title":"React Redux"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/typings-playground  learn and experiment with TypeScript typings\n# install typescript $ npm install typescript --global # install typings $ npm install typings --global # install node typings $ typings install node --ambient --save # compile index.ts to index.js $ tsc # run $ node index.js see contents of tsconfig.json, which tells tsc how to compile\nResources  How to add type definitions to a TypeScript project typings DefinitelyTyped/DefinitelyTyped http://definitelytyped.org/  ","permalink":"https://brianpfeil.com/post/typings/","postedOnDate":" May 2, 2016","tags":["typescript"],"title":"Typings"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/nexe-playground  Learn and experiment with nexe\nnexe lets you create a single executable out of your node.js apps\nInstall $ npm install nexe -g Running There are two methods to run nexe, command line and by specifying the paramaters in package.json\nCommand line $ nexe -r 4.2.4 -i ./index.js -o ./main.nex  Downloads node source 4.2.4 for the platform it\u0026rsquo;s running on in ./tmp directory, compiles it, uses browserify on ./index.js then bundles it all an outputs ./main.nex\n package.json nexe property of package.json specifies all the parameters\n$ nexe # output is ./main.nex, which is specified in the nexe.output property ","permalink":"https://brianpfeil.com/post/nexe/","postedOnDate":" April 5, 2016","tags":["nodejs","distribution","packaging","tools"],"title":"Nexe"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/node-odata-playground  node-odata-playground This is an example of a custom OData 4.0 provider that can be consumed by salesforce Lightning Connect\nSetup $ npm install Running $ node custom-odata-provider-example.js # run ngrok to expose local server publicly $ ngrok 1337 OData Endpoints you can visit\n http://localhost:1337 http://localhost:1337/$metadata http://localhost:1337/$metadata#PIMSProduct http://localhost:1337/PIMSProduct?$count=false http://localhost:1337/todos?$count=false  Using brian.pfeil.1@gmail.com salesforce org.\nScreenshots\nQuery Example\nExternal Data Source\nExternal Object\nFilter Criteria / Where Clause\n","permalink":"https://brianpfeil.com/post/node-odata/","postedOnDate":" March 18, 2016","tags":["nodejs","odata"],"title":"Node OData"},{"categories":["TypeScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/angular2-playground  Project to learn and experiment with Angular2\nRunning $ npm install $ npm start make changes and page will live reload\n","permalink":"https://brianpfeil.com/post/angular2/","postedOnDate":" January 13, 2016","tags":["angular","framework"],"title":"Angular2"},{"categories":["golang","atom"],"contents":"I\u0026rsquo;ve recently switched to Atom from Sublime Text for web development. The transition was relatively painless since many of the keyboard shortcuts and capabilities are the same in. I really enjoy usig Atom and want to have that same experience with programming in Go. This documents my Go setup in Atom.\nInstall and Configuration Steps   Install go-plus\n  Set the go-plus GOPATH setting\n Ideally the Atom application process should have GOPATH in its ENV and you shouldn\u0026rsquo;t have to set this.\n   Install atom build\n  Set build Panel Visibility setting to Keep Visible\n  Add .atom-build.json to root of your project directory\n  { \u0026#34;cmd\u0026#34;: \u0026#34;$GOROOT/bin/go run {FILE_ACTIVE}\u0026#34;, \u0026#34;shell\u0026#34;: true, \u0026#34;env\u0026#34;: { \u0026#34;GOROOT\u0026#34;: \u0026#34;/usr/local/go\u0026#34;, \u0026#34;GOPATH\u0026#34;: \u0026#34;/Users/pfeilbr/go\u0026#34; } } Keyboard Shortcuts  cmd-alt-b - run current file cmd-alt-g - goto definition ctrl-space - code completion  ","permalink":"https://brianpfeil.com/post/atom-golang-support/","postedOnDate":" December 2, 2015","tags":["golang","atom"],"title":"Atom Golang Setup"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/beefy-playground  Learn and experiment with Beefy, which makes working with Browserify a little nicer.\n Running  Clone this repo Install deps  $ npm install Run with live reload and es6 support (babelify)  $ beefy index.js --live --open -- -t babelify ","permalink":"https://brianpfeil.com/post/beefy/","postedOnDate":" October 16, 2015","tags":["nodejs","tools"],"title":"Beefy"},{"categories":["HTML","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/flexbox-playground  Project to learn and experiment with the CSS3 Flexbox layout module.\nindex.html is the entry point\nResources  A Visual Guide to CSS3 Flexbox Properties A Complete Guide to Flexbox  ","permalink":"https://brianpfeil.com/post/flexbox/","postedOnDate":" October 15, 2015","tags":["css"],"title":"Flexbox"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/node-coveralls-playground  node-coveralls-playground To learn and experiment with coveralls test coverage service.\nSetup Steps   Install deps\n$ npm install mocha coveralls mocha-lcov-reporter --save-dev   Install istanbul\n$ npm install istanbul --save-dev -g   If running from command line, ensure .coveralls.yml is in current directory. It should contain a line with repo_token: REPO_TOKEN\n  Running To run on the tests in the test/ directory.\n$ istanbul cover ./node_modules/mocha/bin/_mocha --report lcovonly -- -R spec \u0026amp;\u0026amp; cat ./coverage/lcov.info | ./node_modules/coveralls/bin/coveralls.js \u0026amp;\u0026amp; rm -rf ./coverage  You can view the raw coverage output in the ./coverage directory.\n ","permalink":"https://brianpfeil.com/post/node-coveralls/","postedOnDate":" September 29, 2015","tags":["testing","nodejs"],"title":"Node Coveralls"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/heroku-deploy-playground  To learn and experiment with various heroku deployment options such as github and dropbox\n","permalink":"https://brianpfeil.com/post/heroku-deploy/","postedOnDate":" September 23, 2015","tags":["heroku"],"title":"Heroku Deploy"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/heroku-docker-playground   Heroku Docker Playground To learn heroku-docker to Build, run and deploy Heroku apps with Docker\nDeploy Note Renamed app to \u0026ldquo;heroku-docker-playground\u0026rdquo; via heroku web app. Need to push via the following.\nheroku docker:release \u0026ndash;app heroku-docker-playground\nResources  Build and Deploy with Docker  ","permalink":"https://brianpfeil.com/post/heroku-docker/","postedOnDate":" September 23, 2015","tags":["heroku","docker"],"title":"Heroku Docker"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/mocha-playground  Mocha Playground Area to learn and explore the Mocha JavaScript test framework\nInstall Mocha $ npm install -g mocha  Install THIS and dependencies Clone repo then\n$ npm install  Run Tests $ mocha  ","permalink":"https://brianpfeil.com/post/mocha/","postedOnDate":" September 22, 2015","tags":["mocha"],"title":"Mocha"},{"categories":["Swift","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/osx-audio-playground  Playground to learn the various audio frameworks and APIs\nServer server/\ncontains a node server (websocket) that the playground code interacts with\n","permalink":"https://brianpfeil.com/post/osx-audio/","postedOnDate":" September 15, 2015","tags":["osx"],"title":"OSX Audio"},{"categories":["Ruby","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/metaforce-playground  Playground to learn and experiment with the metaforce gem for interacting with the salesforce metadata api.\n","permalink":"https://brianpfeil.com/post/metaforce/","postedOnDate":" September 9, 2015","tags":["salesforce","ruby","gem"],"title":"Metaforce"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/docker-hub-automated-build-playground  see https://docs.docker.com/docker-hub/github/\nGithub Services\n","permalink":"https://brianpfeil.com/post/docker-hub-automated-build/","postedOnDate":" August 20, 2015","tags":["docker"],"title":"Docker Hub Automated Build"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/webdriverio-playground  Running Selenium Standalone Server (Preferred / lighter weight)  Start selenium Standalone server  # run the following in it\u0026#39;s own shell and leave running $ java -jar selenium-server/selenium-server-standalone-2.53.0.jar Run script  $ node index.js Running Selenium Hub and Node(s) Using Docker   start hub (clients connect to this)\n $ docker run -d -P --name selenium-hub -e GRID_TIMEOUT=10000 selenium/hub    start chrome node (hub delegates work to it)\n $ docker run -d --link selenium-hub:hub selenium/node-chrome    Get host and port for \u0026ldquo;selenium-hub\u0026rdquo; container and use them in your client.\nExample client config\nvar options = { host: \u0026#34;192.168.99.100\u0026#34;, port: 32768, desiredCapabilities: { browserName: \u0026#39;chrome\u0026#39; } }; see index.js\n","permalink":"https://brianpfeil.com/post/webdriverio/","postedOnDate":" August 20, 2015","tags":["nodejs","testing","automation","browser"],"title":"WebdriverIO"},{"categories":["Python","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/spark-playground  Project to learn and experiment with the Spark cluster computing system.\nSetup spark installed at ~/dev/spark-2.2.0-bin-hadoop2.7 and is part of PATH in .bash_profile\nexport SPARK_HOME=~/dev/spark-2.2.0-bin-hadoop2.7 export PATH=$SPARK_HOME/bin:$PATH  Running an example $ spark-submit dataframes-and-sql-examples.py  Docker $ docker run -i -t -P --name spark -v /Users/pfeilbr/Dropbox/mac01/Users/brianpfeil/projects/spark-playground:/src sequenceiq/spark:latest bash  Resources  Spark Documentation  ","permalink":"https://brianpfeil.com/post/spark/","postedOnDate":" June 5, 2015","tags":["spark"],"title":"Spark"},{"categories":["C++","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/v8-playground  Project to learn and experiment with the V8 javascript engine.\nBuilding V8 with Xcode  Install depot-tools. And add to PATH environment variable. Clone repo $ git clone https://chromium.googlesource.com/v8/v8.git Build $ cd v8 $ build/gyp_v8 -Dtarget_arch=x64  Background This project was created with a new Application | Command Line Tool with the language set to C++ in Xcode.\nThe static libraries from the v8 build were copied in The v8 include files were copied from v8/include to v8-includes\nResources  Google V8 Docs  ","permalink":"https://brianpfeil.com/post/v8/","postedOnDate":" May 19, 2015","tags":["v8"],"title":"V8"},{"categories":["HTML","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/html-video-embed-playground  Project to learn and experiment with various HTML video players\nUsage   Start a local webserver\n python -m SimpleHTTPServer 8000    Visit the .html files to view video embeds. e.g. http://localhost:8000/test-screencast-jwplayer.html\n  Resources  JW Player Video.js  ","permalink":"https://brianpfeil.com/post/html-video-embed/","postedOnDate":" May 12, 2015","tags":["html"],"title":"HTML Video Embed"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/webpack-playground  A project to learn and experiment with the webpack module bundler.\nDevelopment   Start local webpack server\n$ webpack-dev-server --progress --colors --debug  This serves all changes out of memory. Remember to run webpack by itself to persist changes\n   Open http://localhost:8080/webpack-dev-server/bundle\n  Make code changes. Changes will live reload.\n  Persist changes by running\n$ webpack   Directory and File Details public/ - client side files public/lib/index.js - webpacks entry point\n react-app.js - react application example\ndemonstrates the usage of\n jsx loader css loader es6 support   angular-app.js - angular application example\ndemonstrates the usage of\n ng-cache loader for views and partials   ","permalink":"https://brianpfeil.com/post/webpack/","postedOnDate":" April 3, 2015","tags":["javascript","bundler","packaging"],"title":"webpack"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/es6-playground  Area to learn and experiment with ECMAScript 6 using the Babel JavaScript compiler.\nRunning $ npm install  Edit app.js\n$ node index.js  ","permalink":"https://brianpfeil.com/post/es6/","postedOnDate":" March 30, 2015","tags":["javascript"],"title":"ES6"},{"categories":["javascript","ios","react","react native"],"contents":"React Native was released as open source yesterday. There\u0026rsquo;s been quite a bit of build up and excitement since the React.js Conf 2015 video. The video showed a real app being built with a web development style workflow (your favorite editor with livereload). I\u0026rsquo;ve built some apps using React.js and really appreciate the simplicity and development workflow. Having the same for native app development definitely is exciting. I\u0026rsquo;ve gottent to spend a few hours with it and it looks like it\u0026rsquo;s living up to the hype.\nI started in with the tutorial, which is a movies app backed by Rotten Tomatoes data. The main UI is a run of the mill List View with each cell containing a poster image, and the movie title and year.\nIt shows fetching data over the network, some of the concerns with rendering list views, and the react core concept of only re-rendering thing that\u0026rsquo;ve changes with ListView.DataSource.rowHasChanged.\nThey sprinkle in ES6 syntax within the examples, and some of it I had to look up. This is a good way to give people a gentle introduction to it. I can see how it might be a bit distracting if your trying to learn something new. Having to learn language level features on top of a new framework could be offputting for some.\nYep. It\u0026rsquo;s All in that single file. It does a good job with starting off with a single minimal view and layering on the different concepts to get you to some more than hello world, but not a real app. One of the things that stood out to me and made it much easier to follow is that all the code is in a single file. UI, style, logic, and data. This is huge from a learning and user uptake perspective. For larger apps, it will get cumbersome quickly and using separate .js files and require them in will make it managaeble.\nI\u0026rsquo;ve seen way too much time spent in other javascript frameworks first introducing the file and directory layout. There are as many different ways to lay things out as there are javascript frameworks these days. I agree it\u0026rsquo;s important for maintainability and collaboration, but when starting out, I feel it should be kept simple, and only restructure when needed. Choice is good, but I hope facebook explicitly documents their recommended layout and people just use it.\nNative Modules: Call for Community Contributions If react native doesn\u0026rsquo;t provide the UI component or capability you need, they allow extension via Native Modules. Bridging is never pretty as it always feels like you need to switch contexts and be aware this is a bridge component. They do their best to minimize this and in the spirit of react it\u0026rsquo;s lightweight and only requires the minimal amount of hooks to do it\u0026rsquo;s job.\nYou only need to implement the RCTBridgeModule protocol to expose native code.\nHere\u0026rsquo;s the example\n// CalendarManager.h #import \u0026#34;RCTBridgeModule.h\u0026#34; @interface CalendarManager : NSObject \u0026lt;RCTBridgeModule\u0026gt; @end // CalendarManager.m @implementation CalendarManager - (void)addEventWithName:(NSString *)name location:(NSString *)location { RCT_EXPORT(); RCTLogInfo(@\u0026#34;Pretending to create an event %@ at %@\u0026#34;, name, location); } @end var CalendarManager = require(\u0026#39;NativeModules\u0026#39;).CalendarManager; CalendarManager.addEventWithName(\u0026#39;Birthday Party\u0026#39;, \u0026#39;4 Privet Drive, Surrey\u0026#39;); As you can see, it\u0026rsquo;s minimally intrusive on both the objc and js sides.\nNative Modules is the community aspect of this effort and if done right will give it staying power. The productivity and developer workflow benefits of npm install awesomesauce is the one of the core underlying reasons for javascript/node popularity.\nA decision needs to be made on whether npm or a native packager like Cocoapods will be the vehicle for packaging and distributing native modules. To keep it x-platform and support android, npm would be the obvious choice. It\u0026rsquo;s important for the react native team to make a decision on this and define this from the start. People will fill the gaps that react native doesn\u0026rsquo;t include. The easier you make it for them to publish for community, the better off the ecosystem will be.\nFetch Networking and more specifically the ability to fetch HTTP resources is a core capability of a majority of applications today. While walking through the tutorial I saw the use of fetch, but had never seen it before. I thought it was something that facebook defined and injected that bridged into iOS\u0026rsquo;s networking. It does this, but in addition it\u0026rsquo;s based on the fetch networking API, which is going through the standard process. Hopefully a higher profile project like react native will give it some legs.\nOnward Native development on the native target platform will always be more popular. It doesn\u0026rsquo;t strive to or need to try to supplant native development. Capturing the web development community alone is a huge audience. More importantly, the react community is full of super star developers that will acively champion things they like. If it reached the success of a Xamarin and as large a community, it would be quite an achievement.\nIt\u0026rsquo;s early and if you don\u0026rsquo;t have a lot free time or care to be on the bleeding edge, I\u0026rsquo;d recommend waiting a bit before using it to develop a production app. As with anything new and in interest of the long-term goals, I\u0026rsquo;m sure there will be bugs to work through, breaking changes, API changes, additional development and debugging tooling, etc.\nEven if I don\u0026rsquo;t dive right in, at a minimum I\u0026rsquo;ll keep up with it\u0026rsquo;s progress via rss feeds and twitter. Kudos to the react native team for a great launch and wish them the best.\n","permalink":"https://brianpfeil.com/post/react-native-initial-thoughts/","postedOnDate":" March 27, 2015","tags":["javascript","ios","react","react native"],"title":"React Native - Initial Thoughts"},{"categories":["golang","concurrency"],"contents":"Go has been getting a lot of traction among the coding elite due to it\u0026rsquo;s simplicity, speed, and most touted, it\u0026rsquo;s ability to enable concurrent solutions.\nGo is a very small language. If you have experience with a few languages, you can learn in a few days and fit and keep it all in your head. With most other languages, I\u0026rsquo;m accustomed to looking up documentation or examples on stackoverflow while I code. With Go, I find I don\u0026rsquo;t do it as much.\nIt\u0026rsquo;s a language influenced by C and the rest of curly brace family of languages. It compiles down into standalone binaries with no dependencies. I can\u0026rsquo;t emphasize how great this is for building cross-platform tools. You write your code once, and can cross-compile to any of core three OSs (osx, linux, windows) from any one of them. No need to run a windows VM to build for windows.\nThe most visible feature and probably most discussed is it\u0026rsquo;s concurrency model. It provides the primitive channel construct, with along with the syntax makes tackling concurrency problems more intuitive than the typical thread construct provided by a majority of languages.\nIn order to get a thorough understanding of concurrency in go, I thought of a real world problem that lends itself to being solved via concurrency. The ATP podcast with Marco Arment was food for thought for an example real world. Downloading web content and indexing it in an efficient manner is a problem many web based services do. The process of indexing web content is computationally expensive, and only doing it when neccessary is desired. If the web content hasn\u0026rsquo;t changed, then we shouldn\u0026rsquo;t waste compute resources indexing the content. One way to detect this is by doing an MD5 hash of the web contents (HTML page) and only index it if it\u0026rsquo;s changed.\nThe first step is fetching the contents of the web resource via a URL. The built-in net/http package turns this into a one-liner\nresp, err := http.Get(url)  We can then get the body\nbody, err := ioutil.ReadAll(resp.Body)  and create an MD5 hash of it\nhash := md5.Sum(body)  Now onto the interesting part of parallelizing. We create a simple structure to hold the information needed to do the work. In this case it\u0026rsquo;s simply a URL\ntype URLJob struct { url string }  We also need to create a structure to hold the results\ntype URLResult struct { URL string Body string MD5 string }  With these in place we con now focus on the work with our worker function.\nfunc worker(id int, jobs \u0026lt;-chan URLJob, results chan\u0026lt;- URLResult) { for j := range jobs { fmt.Println(\u0026quot;worker\u0026quot;, id, \u0026quot;processing job\u0026quot;, j.url) results \u0026lt;- fetch(j.url) } }  Let\u0026rsquo;s focus on the arguments. jobs \u0026lt;-chan URLJob is an array of channels where you can send URLJob instances to it. results chan\u0026lt;- URLResult is an array of channels where we can send the results to.\nWe then invoke via a goroutine\ngo worker(w, jobs, results)  This is where the magic happens. go func creates a goroutine that is ran concurrently by the Go runtime.\nIn our example, waiting on the network to respond with the contents of the URL is the limiting factor. In this case, all these http GET requests will be fired off essentially at once, and as the responses return our results channel array will be updated. You could request 1000s of URLs at a time and assuming the response contents are not huge, this wouldn\u0026rsquo;t move the needle noticably on CPU and memory for a reasonably sized machine.\nParallelism is baked into all hardware these days and is the way the computing hardware industry holds true to Moores law. Modern languages like Go need to surface these advances, but without the usual cognitive load of using threads. The holy grail of writing your code as if everything is syncronous and having it parallelized automatically for you to make use of all the cores, etc. seems a ways off or most likely will never happen. In the meantime Go is making a good run at it and moving us forward in this space.\nExample code for the concurrent downloader example is on github at pfeilbr/concurrent-downloader.\n","permalink":"https://brianpfeil.com/post/concurrent-downloader-in-go/","postedOnDate":" March 26, 2015","tags":["golang","concurrency"],"title":"Concurrent Downloader in Go"},{"categories":["docker","elastic beanstalk","aws","elastic search"],"contents":" TL;DR code on github @ pfeilbr/Elastic-Beanstalk-Dockerrun.aws.json-Example\n This article will show you the steps to run elasticsearch on AWS Elastic Beanstalk. This example uses the elasticsearch docker image as an example. Once running you can visit http://\u0026lt;beanstalk domain\u0026gt;/?pretty an you will see the root elastic search JSON response.\nInitial Deployment   Modify Dockerrun.aws.json for your needs.\n Dockerrun.aws.json reference\n   Commit changes to repo\n$ git commit -a -m \u0026#34;changes\u0026#34; ``\n assumes Dockerrun.aws.json has already been added to repo. if not, git add .\n   Create eb app\n$ eb init # populate details ``\n NOTE: select Docker. Populate all details\n   Create environment for app\n$ eb create dev-env ``\n IMPORTANT Must immediately update the ec2 instance with tags so it doesn\u0026rsquo;t get terminated. Enable termination protection on the ec2 instance.\n   Deploying Updates   Modify Dockerrun.aws.json for your needs.\n  Commit changes\n$ git commit -a -m \u0026#34;my updates\u0026#34; ``\n  Deploy to eb\n$ eb deploy ``\n   NOTE: Takes between 3-5 min to deploy changes\n Notes Port mapping details specific to aws beanstalk\n","permalink":"https://brianpfeil.com/post/running-elasticsearch-on-elastic-beanstalk/","postedOnDate":" March 25, 2015","tags":["docker","elastic beanstalk","aws","elastic search"],"title":"Running Elasticsearch on AWS Elastic Beanstalk"},{"categories":["nodejs","docker","elastic beanstalk","aws"],"contents":"Example of developing and deploying a dockerized Node.js app to Elastic Beanstalk\n source on Github at pfeilbr/Elastic-Beanstalk-Docker-Node.js-Example\n Local Development Workflow   Edit code. e.g. index.js\n  Build image\n$ docker build --tag=\u0026#34;pfeilbr/eb-docker-node-example\u0026#34; . ``\n  Run\n$ docker run -p 80:80 -it -rm -name eb-docker-node-example pfeilbr/eb-docker-node-example ``\n  Get docker host ip (optional. only if using boot2docker)\n$ boot2docker ip ``\n  Open browser to http://\u0026lt;boot2docker ip\u0026gt;\n  Initial Deployment   Init git repo\n$ git init . ``\n  Add files to repo\n$ git add . ``\n  Commit changes\n$ git commit -m \u0026#34;init\u0026#34; ``\n  Create eb app\n$ eb init # populate details ``\n Populate all details\n   Create environment for app\n$ eb create dev-env ``\n IMPORTANT Must immediately update the ec2 instance with tags so it doesn\u0026rsquo;t get terminated. Enable termination protection on the ec2 instance.\n   Output\nDeploying Updates   Modify code and test via [Local Development Workflow]\n  Commit changes\n$ git commit -a -m \u0026#34;my updates\u0026#34; ``\n  Deploy to eb\n$ eb deploy ``\n   NOTE: Takes between 3-5 min to deploy changes\n Output\nEstablish Interactive Bash Shell in Running Docker Container   ssh into ec2 docker host server\n$ eb ssh ``\n  Get container name\n$ sudo docker ps # save off name of container ``\n  Connect/attach with an interactive bash session\n$ sudo docker exec -i -t \u0026lt;container name\u0026gt; bash ``\n  Example Session with Output\n","permalink":"https://brianpfeil.com/post/dockerized-nodejs-app-on-elastic-beanstalk-example/dockerized-nodejs-app-on-elastic-beanstalk-example/","postedOnDate":" March 25, 2015","tags":["nodejs","docker","elastic beanstalk","aws"],"title":"Dockerized Node.js App on Elastic Beanstalk Example"},{"categories":["javascript","nodejs","desktop","nw.js"],"contents":" Post is based on the pfeilbr/nwjs-playground project.\n NW.js Playground Project to learn and experiment with NW.js.\nNW.js enables the creation of cross platform desktop applications. Your UI is built with standard html, js, and css technologies. Access to the underlying desktop OS capabilites are provided by giving you access to node.js. You can use the Node.js core modules plus any of the 3rd party NPM modules;\nInstalling NW.js Download and unpack nwjs app for your platform from http://nwjs.io\n On OSX you\u0026rsquo;ll end up with /Applications/nwjs.app\n Developing Your App create index.html and package.json files\n see nw.js quick-start for details\n This app is a minimal example with an added app.js file for javascript. It\u0026rsquo;s sets the document.body to 'Hello There'.\nRunning Create alias in ~/.bash_profileto ease the use from terminal\n# alias to nw alias nw=\u0026#34;/Applications/nwjs.app/Contents/MacOS/nwjs\u0026#34; Run\n$ cd ~/projects/nwjs-playground $ nw . Packaging as app on OSX   Create .nw file\n$ cd ~/projects/nwjs-playground $ zip -r ../${PWD##*/}.nw * ``\n .nw file will be created along side the project directory\n   make copy of nwjs.app\n$ cp -r /Applications/nwjs.app /Applications/myapp.app ``\n  Copy .nw file into myapp.app bundle\n$ cp ../nwjs-playground.nw /Applications/myapp.app/Contents/Resources/app.nw ``\n  ","permalink":"https://brianpfeil.com/post/cross-platform-desktop-apps-with-nw-js/","postedOnDate":" February 15, 2015","tags":["javascript","nodejs","desktop","nw.js"],"title":"Cross-platform Desktop Apps with NW.js"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/karma-playground  Project to learn and experiment with the Karma javascript test runner. Karma runs your javascript tests in multiple browsers.\nQuickstart Tutorial   Change to project directory\n $ cd ~/projects/karma-playground    New NPM project\n $ npm init   accept all defaults\n   Install karma\n# Install Karma: $ npm install karma --save-dev # Install plugins that your project needs: $ npm install karma-jasmine karma-chrome-launcher --save-dev ``\n  Install global karma cli so we can type karma without the full path from anywhere.\n $ npm install -g karma-cli    Create sample test.\n Using Jasmine for our example.\n $ mkdir test $ touch test/sample1.js ``\n// test/sample1.js describe(\u0026#34;A suite\u0026#34;, function() { it(\u0026#34;contains spec with an expectation\u0026#34;, function() { expect(true).toBe(true); }); }); ``\n  Generate the karma configuration file\n $ karma init my.conf.js    Start karma\n # Start Karma using your configuration: $ karma start my.conf.js   You\u0026rsquo;ll see Chrome or the browsers you chose start\n   ","permalink":"https://brianpfeil.com/post/karma/","postedOnDate":" February 15, 2015","tags":["javascript","testing"],"title":"Karma"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/nwjs-playground  NW.js playground Project to learn and experiment with NW.js.\nNW.js enables the creation of cross platform desktop applications. Your UI is built with standard html, js, and css technologies. Access to the underlying desktop OS capabilites are provided by giving you access to node.js. You can use the Node.js core modules plus any of the 3rd party NPM modules;\nInstalling NW.js Download and unpack nwjs app for your platform from http://nwjs.io\n On OSX you\u0026rsquo;ll end up with /Applications/nwjs.app\n Developing Your App create index.html and package.json files\n see nw.js quick-start for details\n This app is a minimal example with an added app.js file for javascript. It\u0026rsquo;s sets the document.body to 'Hello There'.\nRunning Create alias in ~/.bash_profileto ease the use from terminal\n# alias to nw alias nw=\u0026#34;/Applications/nwjs.app/Contents/MacOS/nwjs\u0026#34; Run\ncd ~/projects/nwjs-playground nw . Packaging as app on OSX   Create .nw file\ncd ~/projects/nwjs-playground zip -r ../${PWD##*/}.nw * ``\n .nw file will be created along side the project directory\n   make copy of nwjs.app\ncp -r /Applications/nwjs.app /Applications/myapp.app ``\n  Copy .nw file into myapp.app bundle\ncp ../nwjs-playground.nw /Applications/myapp.app/Contents/Resources/app.nw ``\n  ","permalink":"https://brianpfeil.com/post/nwjs/","postedOnDate":" February 15, 2015","tags":["nodejs","cross-platform","framework"],"title":"NWjs"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/sauce-labs-playground  Playground to learn, explore, and play with Sauce Labs\nSauce Labs Node.js Tutorial tutorial/ directory is from following the tutorial @ Sauce Labs Node.js Tutorial\ntutorial/test/sauce/tutorial-specs.js contains the tests and is where you can modify the code.\nQuickstart\nBypasses almost all tutorial steps because they\u0026rsquo;ve been completed\ncd tutorial/ grunt  Example Test Run Output Screenshot ","permalink":"https://brianpfeil.com/post/sauce-labs/","postedOnDate":" February 4, 2015","tags":["testing","automation"],"title":"Sauce Labs"},{"categories":null,"contents":" Hi, I\u0026rsquo;m Brian Pfeil. I\u0026rsquo;m passionate about technology, and building things. This is my personal blog where I sometimes write about those and other interests.\nI currently work at a Pharmaceutical company as a Cloud Architect.\nI am an AWS Community Builder (Serverless) and can be found at twitter, github, and stackoverflow.\n","permalink":"https://brianpfeil.com/about/","postedOnDate":" January 14, 2015","tags":null,"title":"About"},{"categories":null,"contents":"Cloud Architect  AWS Azure  Cloud Solutions Architect Veeva  Architect for US sales implementation Administrator Developer Configurator SSO and identity  salesforce.com  Architect Administrator Developer  App Central  adobe air, flex, actionscript desktop app portal / app launcher for sales employees  Siebel  developer and technical lead songo - custom  MyComms  custom salesforce.com communications application administration UI custom (angular SPA) UI (mobile/responsive)  MyCall / Proscape  sales electronic detailing embedded signature capture  Custom Desktop CRM Application (Insight) developer and technical lead\n C++ MSVC MFC ATL .NET (C#) ms-access db then MS-SQL Server  Custom Desktop CRM Application (Quest) developer and technical lead\n VB6 DHTML ms-access db then MS-SQL Server  Sample Signature Control developer and technical lead\n FDA 21 CFR part 11 - e-Signatures C++ for windows and window ce COM, ATL  Sample Tamperproof Verication System  C++ windows service verified use didn\u0026rsquo;t change system time and sent result to backend via Afaria  Reliable Sample Record Delivery System developer\n iPaq -\u0026gt; (VisualBasic 6) laptop -\u0026gt; remoteware/afaria -\u0026gt; windows file server -\u0026gt; (winbatch) Sample Accountability Management System (HP-UX)  Vector Website  UI design client-side javascript (roll overs for menus :))  Field Sales Laptop Refresh Inventory Tracking  Java Servlet, JSP FedEx Bar Code device integration MS-SQL Server  Field Sales Laptop Refresh QA  unpacked laptops from boxes entered laptop details into tracking system upgraded windows QA\u0026rsquo;d packed into boxes  ","permalink":"https://brianpfeil.com/resume-full/","postedOnDate":" January 14, 2015","tags":null,"title":"Full Resume"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/go-postgres-playground  playground for go lib/pq package\nDependencies go get github.com/lib/pq  Running go run main.go  ","permalink":"https://brianpfeil.com/post/go-postgres/","postedOnDate":" January 11, 2015","tags":["golang","postgres"],"title":"Go Postgres"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/nodemailer-playground  Playground for exploring the use of Nodemailer to send email\nUsage Update index.js with email password before running.\nnpm install npm start OR node index.js  ","permalink":"https://brianpfeil.com/post/nodemailer/","postedOnDate":" December 6, 2014","tags":["nodejs","gmail","email"],"title":"Nodemailer"},{"categories":null,"contents":"Minotes Minotes - minimalist notes - is designed from the ground up to provide fast and clean note taking. Rather than packing features into a crowded interface, Minotes provides a minimal streamlined interface for your notes.\n clean — The interface of Minotes is intentionally simple. It provides just what you need, without any distractions fast — Minotes is optimized from the ground up to be fast and fluid, whether you are on the fanciest new iPhone or a more vintage model. beautiful — From its thoughtfully laid out navigation to its select set of settings, Minotes is designed to make you want to open it.    Minotes Product Page\n  Animal Fun Animal Fun is an iPhone and iPad app I wrote for my son when he was 3 to help him learn about animals while also entertaining him. It\u0026rsquo;s a free app available on the App Store and the source code is available on github\n      Vehicle Fun for Kids Fun and easy interactive vehicle app designed by parents for young children who enjoy the look and sound of vehicles. A terrific collection of real vehicle pictures and sounds that play with one easy tap. You\u0026rsquo;ll also hear the name of the vehicle along with the sound. It will keep those little ones busy for quite a while! They\u0026rsquo;ll get their fill of cars, trucks, and boats!\n  Vehicle Fun for Kids Product Page\n  Alpha Sound Alpha Sound is a simple ABC\u0026rsquo;s learning program for children. Children learn their letters by seeing and hearing the letter names. It\u0026rsquo;s a free app available on the App Store\n     Alpha Sound Product Page\n  Music Sound Touch Fun and easy interactive music app designed by parents for young children who enjoy the look and sound of musical instruments. A terrific collection of real musical instrument pictures and sounds that play with one easy tap. You\u0026rsquo;ll also hear the name of the instrument along with the sound. It will keep those little ones busy for quite a while!\n  Music Sound Touch Product Page\n  Mobile Account \u0026amp; Contact Manager Mobile Contact and Account management web application built using the salesforce platform for the backend and jQuery Mobile for the frontend. Provides the same functionality when disconnected by using HTML5 Application Cache and local storage.\nSee Salesforce and jQuery Mobile post for details\nsource code\n iOS Enterprise App Store Enterprises that are members of the iOS Developer Enterpise Program can distribute their employee apps with their own App Store using Apple\u0026rsquo;s over-the-air distribution. With this solution, you just drop your app .ipa file and a file with information about the app into a directory, and it\u0026rsquo;s immediately available for users to install.\nThe backend is a Sinatra web app. On the front-end there\u0026rsquo;s a built-in jQuery Mobile web interface, and also a separate native iPhone app.\nApp Store Web App\n     Native iPhone App Store Client\n     source code\n","permalink":"https://brianpfeil.com/projects/","postedOnDate":" August 4, 2014","tags":null,"title":"Projects"},{"categories":["\u003cnil\u003e","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/kendo-ui-playground  Place to play around and learn Kendo UI\n","permalink":"https://brianpfeil.com/post/kendo-ui/","postedOnDate":" August 2, 2014","tags":["javascript","ui","framework"],"title":"Kendo UI"},{"categories":["Swift","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/ios-swift-playground  Scratchpad to learn and explore swift\n","permalink":"https://brianpfeil.com/post/ios-swift/","postedOnDate":" July 13, 2014","tags":["ios"],"title":"iOS Swift"},{"categories":["heroku"],"contents":"Heroku Connect was announced at Dreamforce \u0026lsquo;13 shortly after salesforce aquired cloudconnect. Cloudconnect is the original product created by Adam Gross, formerly of Dropbox that became Heroku Connect.\nThere\u0026rsquo;s a rich developer ecosystem around web apps built with popular web frameworks such as Rails, Django, Express, Symfony, etc. All of these frameworks assume a relational database as a backend, which because of it\u0026rsquo;s age, usage, and rich set of existing toolsets, makes it easy to get started with. Salesforce\u0026rsquo;s force.com platform wanted gain this ease of use and speed at which apps could be developed. Salesforce has it\u0026rsquo;s own data storage solution that is built for scale and multitenatcy and doesn\u0026rsquo;t cleanly map to the standard relational model.\nConnect solves this problem by bi-directionaly synchronizing your salesforce data to a heroku postgres database. Once in postgres, all the popular web frameworks with a huge developer community can be used to develop salesforce apps.\nHeroku Connect Setup Connect is provided as a heroku add-on, which enables easy intregration with heroku apps. A prerequisite is to have a postgres database provisioned for connect to synchronize your salesforce data to. Once your database is in place, you install the add-on via\nheroku addons:add herokuconnect -a appname\nHere\u0026rsquo;s what it looks like\nThe rest of the setup and configuration takes place in the Heroku Connect web interface. You access it by logging into heroku and navigate to your app, then click the Heroku Connect link in the Add-ons section. This will lauch the web ui.\nOn first lauch you will be greeted with a setup screen. This will automatically use to the DATABASE_URL config variable, which was put in place when the postgres database was provisioned.\nThe final setup looks like\nNext you need to authorize Connect to access your salesforce org\nYou allow permission\nYou are then ready to configure the data you want to use with Connect.\nResources  Introducing Heroku Connect: Connecting Clouds and Customers Heroku Connect Dev Center article  ","permalink":"https://brianpfeil.com/post/heroku-connect/","postedOnDate":" July 5, 2014","tags":["heroku"],"title":"Heroku Connect"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/kue-playground  Playground for learning / playing with Kue. Kue is a priority job queue for node.\nRunning redis-server # start redis server node index.js -m process # run job processor node index.js -m create # run job creator in another terminal  View the Kue web ui at http://localhost:3000\n","permalink":"https://brianpfeil.com/post/kue/","postedOnDate":" June 13, 2014","tags":["javascript","queue"],"title":"Kue"},{"categories":["JavaScript","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/jsforce-playground  Area to learn and play with JSForce. index.js contains the code.\nmigrator.js migrates salesforce metadata from a source org to a target org\nTo Run\n$ ./node_modules/.bin/babel-node migrator.js sharing-rules-operations.js created country code firewall criteria based sharing rules\nTo Run\n$ ./node_modules/.bin/babel-node sharing-rules-operations.js account-fetcher.js Developing\n$ DEBUG=account* nodemon -e js account-fetcher.js ","permalink":"https://brianpfeil.com/post/jsforce/","postedOnDate":" June 12, 2014","tags":["salesforce","javascript"],"title":"JSForce"},{"categories":["Swift","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/mac-swift-playground   Swift Playground Swift playground for exploring the swift programming language\nPlayground Specific Functions There are a set of functions that enable the code you write to interact with the plaground UI. For example, you can display a UIView live. The XCPlayground module provides these functions\nXCPSetExecutionShouldContinueIndefinitely(continueIndefinitely:Bool) Allows async code to run. For example, dispatch_* calls and networking.\nXCPCaptureValue(identifier: String, value:AnyObject) Displays the value in the view pane with the identifier as the title\nXCPShowView(identifier: String, view: NSView) Display the provided view in the view pane with the identifier as the title\n","permalink":"https://brianpfeil.com/post/mac-swift/","postedOnDate":" June 5, 2014","tags":["mac"],"title":"Mac Swift"},{"categories":["Go","playground"],"contents":"code for article\u0026nbsp;\u0026nbsp;pfeilbr/go-playground  A set of example Go programs for learning\nEach subdirectory contains an example\nRunning go run filename  e.g.\ngo run hello.go  Resources  Go Documentation  ","permalink":"https://brianpfeil.com/post/go/","postedOnDate":" December 31, 2013","tags":["golang"],"title":"Go"},{"categories":["ios","app"],"contents":"There are many choices for notes apps out in the App Store. So many that it\u0026rsquo;d be a couple days effort just to look into and evaluate them all. Everything from the built-in simple Notes app to the feature packed Evernote. A notes app is one of those utility apps that gets a lot of mileage like mail and weather. Something with high usage you want the most efficient and streamlined app. It\u0026rsquo;s also something that becomes personal and people get attached to.\nI wanted something extremely simple, clean up, and fast. I started with the simplest possible solution of a single text view you could type in. From that, the ability to create multiple notes was added, but I didn\u0026rsquo;t want the freedom to create as many notes as you want. Having constraints on the number of notes forces the user to create more meaningful notes and manage / clean up notes. The goal with minotes is not to have an archive of all historical notes with search, etc. The type of notes appropriate for this app are short-lived ones and in general have a lifespan of around a week. I landed on a UI metaphor similar to mobile safari with a max of 9 notes.\nPreferences around typography and text size is something that is really needed in order to be useful for more than a specific set of users. For example, older people may need a little bit larger font size, whereas younger users may want to cram more text on the screen and are fine with a smaller font size. In order to keep it simple, there are three typefaces to choose from and in sizes, small, medium, large.\nIt\u0026rsquo;s an opinionated app built with my specific needs in mind. It\u0026rsquo;s doesn\u0026rsquo;t try to appeal to all users universally, but if you like simple purpose built apps, check it out.\n     Minotes Product Page\n","permalink":"https://brianpfeil.com/post/minotes/","postedOnDate":" June 21, 2013","tags":["ios","app"],"title":"Minotes"},{"categories":["web","heroku"],"contents":"I was recently creating a web site for a family member, and was looking around for the best place to host it. It\u0026rsquo;s a simple personal site that only contains static content. There are many options out there from the freebie wordpress options to rackspace and the like. None of the \u0026ldquo;web publishing platform\u0026rdquo; type sites were a fit because I wanted full control over the layout, and look and feel of the site.\nI\u0026rsquo;ve been working with Heroku for my day job for web applications, and it\u0026rsquo;s been simple to get things up and running at no cost. Heroku allows you to create a web application for free, and only if you need to scale to support the traffic do you have to pay.\nOne of the limitations of using the free plan with heroku is that if your app hasn\u0026rsquo;t recieved any traffic within an hour, it puts it into an idle state. They call this dyno idling and when a request comes in and your dyno is in an idle state, it has to spin it back up, and that takes time. In my experience, I\u0026rsquo;ll go to hit the site and it takes approx. 5 seconds to respond. It\u0026rsquo;s free, so I can understand when they do this to save on compute resources, and if you have pay / have multiple dynos, they never with idle your app.\nTo work around this you just need to have at least 1 request come in an hour. There are many ways to do this, and I took the simple approach of using a monitoring service (pingdom) to check/ping the site for availability every 5 minutes. You could also implement by using a background worker process.\nThere’s a great Creating Static Sites in Ruby with Rack walkthrough on the heroku dev center that will have you up and running in few minutes. They provide a fully functional sample application that you can modify to make you own.\n","permalink":"https://brianpfeil.com/post/hosting-static-sites-on-heroku/","postedOnDate":" September 16, 2012","tags":["web","heroku"],"title":"Hosting Static Sites on Heroku"},{"categories":["ruby"],"contents":"RubyMotion is a toolchain that lets you develop iOS using Ruby. I\u0026rsquo;m a big fan of Ruby and have been using it on and off since 2001. It\u0026rsquo;s been a huge timesaver in many cases allowing me to quickly script solutions. When I heard it was coming to iOS I had to check it out.\nThe toolchain and the way you use the various components matches the rails development process. Open your favorite text editor and a terminal, and you\u0026rsquo;re ready to go. For example to create a new project.\nmotion create project Interfacing with the toolchain is all rake driven. Edit your files, type rake device, and your app is compiled and launches in the iOS Simulator. It\u0026rsquo;s a very nice and familiar development process.\nOne of the big benefits with using Ruby is concise code. Compared to Objective-C, you\u0026rsquo;ll end up with a lot less code for an app. For example with Ruby, you could put your entire app in a single .rb file. With Objective-C you have the .h and .m files for every class, and you spend quite a bit of time switching between them all.\nRuby helps ease the app development process, but most of the learning and skill with iOS development is understanding the various iOS frameworks. This doesn\u0026rsquo;t go away with RubyMotion. You still have to take the time to learn these. Part of learning is reviewing the code samples that Apple provides, and they\u0026rsquo;re all in Objective-C. Knowing the native language of a platform is always the best thing, and if someone wanted to get started with iOS development, I\u0026rsquo;d recommend learning Objective-C.\nRubyMotion costs $200, and this might be a barrier for it taking off. The Ruby community is used to things being open source and free. It\u0026rsquo;d be nice if they took the approach Apple does with Xcode. With a free Apple Developer account, you can create apps, but your limited to running them in the simulator. Once you pay the $99 for to be a part of the developer program, you can put apps on devices and the App Store. RubyMotion could do the same, free for apps running on the simulator, and purchase to put apps in the App Store.\nThe creator of it is former Apple employee, Laurent Sansonetti, who also led the development of the MacRuby project, which tries to achieve the same goal by allowing devs to create OS X apps with Ruby. Apple supported the MacRuby project heavily in the past, but it seems to have slowed with the rise of iOS. I have to think that Sansonetti proposed Ruby on iOS while he was at Apple, but it didn\u0026rsquo;t get support internally. Apple doesn\u0026rsquo;t like platforms being built on top of it\u0026rsquo;s own platforms because they loose control and if the apps created using the platform don\u0026rsquo;t match the user experience Apple wants, they can\u0026rsquo;t do anything about it (remember flash).\nI\u0026rsquo;m skeptical that it\u0026rsquo;ll take off, but am definitely rooting for it.\n","permalink":"https://brianpfeil.com/post/rubymotion/","postedOnDate":" May 11, 2012","tags":["ruby"],"title":"RubyMotion"},{"categories":["productivity","dropbox","appengine"],"contents":"Between work and home,I\u0026rsquo;ve always got more things to do than I can keep straight my head. Like most people, I keep a to-do list so I don\u0026rsquo;t have to worry about forgetting it. My to-do list is a simple bulleted text (Markdown) file that I keep in Dropbox so I can access it from anywhere.\n # TODOS * get gas * get leaf bags * send thank you cards # Completed * get propane * get burgers and hot dogs  This setup works fairly well, but they\u0026rsquo;re times when I think of something I need to do, but I don\u0026rsquo;t get it into this list because of the time it takes to add it. The usual scenario is that I\u0026rsquo;m not sitting in front of a computer, and I need to add it using my iPhone. There are plenty of to-do and dropbox text file editor apps our there to choose from (way too many), but none of them make it fast enough to enter, and fit my to-do-list-text-file-in-dropbox setup.\nThe best case scenario would be an app, that opens awaiting my next to-do, and I\u0026rsquo;d just type it in, and it\u0026rsquo;d add it to my to-do list text file in dropbox in the right format. I thought about making an app that did just that, but I knew there had to be an easier way. That\u0026rsquo;s when email popped into my head. It\u0026rsquo;s dead simple, and available everywhere. I\u0026rsquo;d never have an excuse not to get something on the list. It\u0026rsquo;s also fast and easy to send email.\nSolution My solution is to send an email to a special \u0026ldquo;todo\u0026rdquo; email address where the subject would be the todo item, the email would be processed, and the item added to my to-do list text file in dropbox.\nGoogle App Engine lets you run web apps on Google infrastructure for free, and they offer a way to receive and process email. Dropbox provides a Dropbox Python SDK to get at your files, which is works out nicely since Python is the primary language used for App Engine development.\nYou can take a look at the Google App Engine Receiving Email Documentation, but the gist of it is that an email sent to NAME@APP.appspotmail.com will result in a HTTP POST request sent to /_ah/mail/NAME@APP.appspotmail.com with the POST body containing the contents of the email. Google provides a nice InboundMailHandler class to make handling inbound email a breeze.\nThe first thing we need to do is to map a handler for inbound emails. I\u0026rsquo;m using the Django Python web framework in my app engine app, which provides some connivence mechanisms. To map a URL to a handler we add the following to the urls.py file.\nurlpatterns = patterns(\u0026#39;\u0026#39;, (r\u0026#39;^_ah/mail/todo@myapp.appspotmail.com`, \u0026#39;emailengine.views.todo_email_handler\u0026#39;), We mapped the url to todo_email_handler method\ndef todo_email_handler(request): if request.POST: message = mail.InboundEmailMessage(request.raw_post_data) logging.info(\u0026#34;Received a message from: \u0026#34; + message.sender) if is_whitelisted_email_address(message.sender): mgr = DropboxManager() mgr.add_todo(message.subject) logging.info(\u0026#34;Received a message from: \u0026#34; + message.sender + \u0026#34;, Todo:\u0026#34; + message.subject) return HttpResponse(\u0026#39;ok\u0026#39;) In order to prevent anyone from adding to-do items to my list, I added the is_whitelisted_email_address method to restrict processing of emails to only those that come from me.\ndef is_whitelisted_email_address(email): result = False for whitelist_email in EMAIL_ADDRESS_WHITELIST: if email.lower().find(whitelist_email) != -1: result = True return result The work to add the to-do item to the TODO.txt file in dropbox is\nmgr = DropboxManager() mgr.add_todo(message.subject) I created the DropboxManager class as a simple wrapper around the Dropbox API. This keeps the code tidy, and all the dropbox specific code like the app key, secret, and token in one place.\nConclusion I\u0026rsquo;m sure one of the many existing to-do list apps fits the needs of most people. This solution required a little work upfront, but has already proven to be a timesaver.\n","permalink":"https://brianpfeil.com/post/emailing-todos-to-dropbox/","postedOnDate":" November 20, 2011","tags":["productivity","dropbox","appengine"],"title":"Emailing Todos to Dropbox"},{"categories":["html","javascript","fonts"],"contents":"I\u0026rsquo;ve been working on a web app that targets both smartphones and tablets. The large variation in screen sizes has sent me down the path of using a dynamic proportional layout that adapts to fit the available space. For example, I\u0026rsquo;ve allocated 20% of the available vertical space to the header section that displays a title. The jQuery UI.Layout Plug-in has worked great for laying out the content areas, but I ran into a wall when it came to sizing my text proportionately.\nThe basic problem is that I have a box, and I want to display some text in it at the largest font size without it being wrapped or clipped. The only way to determine the bounding rectangle a string of text with certain font characteristics, is to create it, add it to the DOM, and then measure it. The following function does just that.\nfunction sizeWithText(text, cssStyles) { // create temp element to hold our text var e = document.createElement(\u0026#39;span\u0026#39;); e.appendChild(document.createTextNode(text)); // apply any styles that have been passed in // to our element - these can affect the text size for (var prop in cssStyles) { e.style[prop] = cssStyles[prop]; } // hide our temp element e.style[\u0026#39;visibility\u0026#39;] = \u0026#39;hidden\u0026#39;; // add to DOM in order to have it render document.body.appendChild(e); // get the bounding rectangle dimensions var s = {w: e.offsetWidth, h: e.offsetHeight}; // remove from DOM document.body.removeChild(e); return s; } The cssStyles parameter holds the other css style attributes that you\u0026rsquo;d like to apply to the text. For example, you might have a font-weight: bold attribute that increases the size of the text, and we want to make sure we account for it.\nNow we can use this function to check whether text with a font size and a set of styles will fit in our box. We set the font size to 1 and continuously increase it by 1 check whether it\u0026rsquo;ll fit at every iteration. As soon as it doesn\u0026rsquo;t, we stop.\nfunction bestFitTextSize(text, css, width, height) { var pixel = 1; do { css[\u0026#39;font-size\u0026#39;] = (pixel++) + \u0026#39;px\u0026#39;; s = sizeWithText(text, css); } while ( (s.w \u0026lt; width) \u0026amp;\u0026amp; (s.h \u0026lt; height) ) return pixel - 2; } This is a brute force and inefficient way to do the calculation, and there are improvements that could be made. We could start at a reasonable font size like 6px, increment by standard font sizes, etc., but this is fine for my usage where I only do it once on app load.\nHere\u0026rsquo;s a code sample that shows how the previous functions are used.\n// box we want to fill with text var c = document.getElementById(\u0026#39;content\u0026#39;); // out text var text = \u0026#39;Lorem ipsum dolor sit amet\u0026#39;; // styles var cssStyles = { \u0026#39;font-family\u0026#39;: \u0026#39;Impact\u0026#39;, \u0026#39;font-style\u0026#39;: \u0026#39;normal\u0026#39;, \u0026#39;font-weight\u0026#39;: \u0026#39;bolder\u0026#39;, \u0026#39;letter-spacing\u0026#39;: \u0026#39;1px\u0026#39;, \u0026#39;text-shadow\u0026#39;: \u0026#39;3px 3px 3px white\u0026#39; }; // size the text to fit function applyBestFitText() { // get the pixel size for the font var px = bestFitTextSize(text, cssStyles, c.offsetWidth, c.offsetHeight); cssStyles[\u0026#39;font-size\u0026#39;] = px + \u0026#39;px\u0026#39;; // set the text c.innerHTML = text; // apply our styles for (var prop in cssStyles) { c.style[prop] = cssStyles[prop]; } } // adjust if the size changes window.addEventListener(\u0026#39;resize\u0026#39;, applyBestFitText, false); // call for first time adjustment applyBestFitText(); The complete example is available as a gist\n","permalink":"https://brianpfeil.com/post/best-fit-web-font-sizing/","postedOnDate":" September 27, 2011","tags":["html","javascript","fonts"],"title":"Best Fit Web Font Sizing"},{"categories":["windows","win8","metro"],"contents":"I\u0026rsquo;ve been digesting all the new information around Windows 8 and Metro over the past week. I\u0026rsquo;ve watched the BUILD Conference Channel 9 Videos, read the articles and docs on the Windows Dev Center and the Building Windows 8 blog. The best resource for your time on learning what Metro is all about from a design perspective is 8 traits of great Metro style apps.\nThe Metro Style interface is a totally new and original approach to UI. Microsoft put a lot of thought into the design of it, and they demonstrated this by providing background during the BUILD sessions on how they studied how users held and used slate devices, what areas of the screen where reachable by their thumbs, etc.\nThe concept of dedicating all the available screen space to content with no chrome makes perfect sense. It doesn\u0026rsquo;t makes sense for all applications, especially those rich in functionality. For example, Microsoft showed Photoshop and it\u0026rsquo;s many tool palettes and menus, and it was clear that you wouldn\u0026rsquo;t make a Metro Style Photoshop app. Metro makes sense for \u0026ldquo;consumery\u0026rdquo; type apps like casual games, productivity apps, and rich media apps; the same things you see on an iPad or Android tablet. This is one of the reasons that they need to support \u0026ldquo;classic\u0026rdquo; windows app, and they can\u0026rsquo;t make a clean break to the Metro Style UI.\nOne potential problem with the immersive content, and no chrome approach is the lack of discoverability to take actions on the content. Metro relies heavily on gestures that take place at the edges of the screen. For example to display the charm bar, you place your finger off to the right of the screen where there isn\u0026rsquo;t any content and touch isn\u0026rsquo;t recognized then swipe in towards the center of the screen. Another example is the application bar at the bottom where you have to swipe up to summon it. Is a user gonna know to do this? Will devices come with an in-your-face tutorial on these things when you first boot it up? There have been many studies that have proven if it\u0026rsquo;s out of site then users won\u0026rsquo;t discover it. For touch, there are only two gestures you should assume your users know, and that\u0026rsquo;s tap and swipe to scroll; everything else is power user territory.\nThere\u0026rsquo;s another issue around using a mouse in Metro. Microsoft made the statement that Metro is a natural fit for a mouse in addition to touch. I\u0026rsquo;ve been using the Developer Preview running in VMware, and using a mouse with Metro is very tedious. The level of indirection you have between the mouse and what happens on the screen makes the things that work well with touch feel like a large amount of effort. I actually resorted to using the windows 8 keyboard shortcuts. to activate the standard toolbars and menus because it was so painful. If the apps interaction is limited to clicks and/or keyboard input with no application bar, then the mouse could work, but that\u0026rsquo;s only gonna be a handful of apps.\nThe tiles interface for the home screen was very visually appealing in all the BUILD demos with nice typography, rich pictures, and pastel colors. This is great and demos well when Microsoft controls all the apps, but what happens when you have a whole community of app developers who have their own opinions on design and style building Metro apps. The app that doesn\u0026rsquo;t use a pastel color for their tile background, shows a poorly shot overexposed photo that the user took on their phone, uses an ugly icon, etc. There\u0026rsquo;s nothing from keeping people from doing this. Microsoft is aware of this and they emphasized many times in the BUILD sessions to use the templates they provide in Visual Studio 11. This is a problem on any platform, and it happens on iOS and Android, but the reason it\u0026rsquo;s a bigger issue for Metro is that it\u0026rsquo;s critical to have in place for the immersive experience. All you have is content. You don\u0026rsquo;t have standard chrome title bars and toolbars with a standard look and feel to make your app fit in. Content is everything, and if it\u0026rsquo;s poor, then it\u0026rsquo;ll stick out like a sore thumb.\nIt\u0026rsquo;s still early. Microsoft always previews things and gets them out early to users, so I\u0026rsquo;m sure there\u0026rsquo;ll be some tweaks. This is a big change for them, and the most recent thing as big as this has been there move into the game console space with XBox. Time will tell.\n","permalink":"https://brianpfeil.com/post/metro-ui-initial-thoughts/","postedOnDate":" September 21, 2011","tags":["windows","win8","metro"],"title":"Metro UI: Initial Thoughts"},{"categories":["salesforce","jquery","mobile"],"contents":"I wanted to do a project to learn salesforce, but not a trivial hello world style example. I had recently played around with jQuery Mobile, but didn\u0026rsquo;t do anything significant with it. I decided to put together a basic mobile CRM app. Here\u0026rsquo;s what the finished app looks like.\nSalesforce provides a full-featured environment for free to anyone. It takes no time to sign-up for this Developer Edition, and you get access to everything. If you\u0026rsquo;re just getting started with salesforce, I can\u0026rsquo;t recommend enough the online tutorials, workbooks, and documentation at developer.force.com.\nAccessing the App Data Our app will contain Contact and Account data. We\u0026rsquo;ll use Apex Web Service methods to provide the data. We can get all our Contacts with the following:\nwebService static List\u0026lt;Contact\u0026gt; getContacts() { ApexPages.StandardSetController setCon = new ApexPages.StandardSetController( Database.getQueryLocator( [select id, name, lastname, firstname, title, department, phone, email from Contact])); return (List\u0026lt;Contact\u0026gt;)setCon.getRecords(); } Next we need to call the web service method from the client code. We\u0026rsquo;ll use the force.com ajax apex javascript libraries to access our data. Add these script references to your page \u0026lt;head\u0026gt; section.\n\u0026lt;script src=\u0026#34;/soap/ajax/15.0/connection.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;/soap/ajax/15.0/apex.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; To call the web service method from JavaScript we use this simple one-liner.\nvar contacts = sforce.apex.execute(\u0026#34;MyWebService\u0026#34;, \u0026#34;getContacts\u0026#34;, {}); Building the UI Our mobile app UI will be 100% jQuery Mobile, and we can use force.com Sites to provide pure web content. Sites by default provides configurable headers, footers, navigation, etc. that you can apply themes to. We don\u0026rsquo;t want any of this in our app since we\u0026rsquo;ll be controlling everything in the UI. To turn off the default stylesheets, header, and navigation elements your apex:page element should set the corresponding attributes, and should look similar to the following:\n\u0026lt;apex:page showHeader=\u0026#34;false\u0026#34; sidebar=\u0026#34;false\u0026#34; standardStylesheets=\u0026#34;false\u0026#34; contentType=\u0026#34;text/html\u0026#34;\u0026gt; Now we\u0026rsquo;ll add in the jQuery Mobile references.\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;http://code.jquery.com/mobile/1.0b2/jquery.mobile-1.0b2.min.css\u0026#34; /\u0026gt; \u0026lt;script src=\u0026#34;http://code.jquery.com/jquery-1.6.2.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://code.jquery.com/mobile/1.0b2/jquery.mobile-1.0b2.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; The beauty of jQuery Mobile is that all you have to do is markup your html with the correct attributes to get a mobile UI. You don\u0026rsquo;t need to write any JavaScript. Usually you serve up the jQuery Mobilized html from the server. We want our app to run and function when the device is offline, so we\u0026rsquo;re going to generate the html at run-time on the client using JavaScript to remove the dependency on the server.\nTo minimize the amount of html we embed in our JavaScript, we\u0026rsquo;re going to use jQuery Templates. jQuery Templates allows us to write our html for the UI as we usually would, and to leave placeholders for the pieces we want to replace. Here\u0026rsquo;s an example of a template used to generate a list page.\n\u0026lt;script id=\u0026#34;object-list-page-template\u0026#34; type=\u0026#34;text/x-jquery-tmpl\u0026#34;\u0026gt; \u0026lt;div data-role=\u0026#34;page\u0026#34; id=\u0026#34;${type}-list-page\u0026#34; data-url=\u0026#39;${type}-list-page\u0026#39;\u0026gt; \u0026lt;div data-role=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;${pageTitle}\u0026lt;/h1\u0026gt; \u0026lt;a id=\u0026#39;${type}-add-link\u0026#39; data-obj-type=\u0026#39;${type}\u0026#39; class=\u0026#39;ui-btn-right object-add-link\u0026#39; data-icon=\u0026#34;add\u0026#34;\u0026gt;Add\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div data-role=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;ul data-role=\u0026#34;listview\u0026#34; id=\u0026#34;${type}-list\u0026#34; data-filter=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div data-role=\u0026#34;footer\u0026#34; data-id=\u0026#39;footer-nav-bar\u0026#39; data-position=\u0026#34;fixed\u0026#34;\u0026gt; \u0026lt;div data-role=\u0026#34;navbar\u0026#34;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#contact-list-page\u0026#34; data-transition=\u0026#34;fade\u0026#34; class=\u0026#34;${(type == \u0026#39;contact\u0026#39;) ? \u0026#39;ui-btn-active\u0026#39; : \u0026#39;\u0026#39;} ui-state-persist\u0026#34;\u0026gt;Contacts\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#account-list-page\u0026#34; data-transition=\u0026#34;fade\u0026#34; class=\u0026#34;${(type == \u0026#39;account\u0026#39;) ? \u0026#39;ui-btn-active\u0026#39; : \u0026#39;\u0026#39;} ui-state-persist\u0026#34;\u0026gt;Accounts\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/script\u0026gt; The things wrapped in ${} are replaced with the values. The way we use the template is by calling the $.tmpl method.\nvar $page = $(\u0026#39;#object-list-page-template\u0026#39;).tmpl(data); jQuery Templates are very powerful, and really help with the maintainability of your code. Check out the documentation to learn more.\nConclusion This provides an overview of the core pieces of the solution and the technologies used. If you like to dive in deeper, the complete source is available on github, and the working app is available here (must be viewed in a WebKit based browser).\n","permalink":"https://brianpfeil.com/post/salesforce-and-jquery-mobile/","postedOnDate":" September 11, 2011","tags":["salesforce","jquery","mobile"],"title":"Salesforce and jQuery Mobile"},{"categories":["mac","network"],"contents":"I bounce back and forth between work and home with a MacBook Pro. At work, I\u0026rsquo;m behind a firewall, and have to go through a web proxy to get to public internet sites. I have 2 network locations setup, home and work. When I get to work I manually set my location to work, and when I get home, I manually set it to home again.\nI got tired of remembering to do this so I looked around, and found scselect. scselect is a command line utility that comes with OS X that lets you set your location by name\nscselect \u0026#34;home\u0026#34; Now all I needed was a way to determine whether I was at work or home and then run scselect with the corresponding location. My work assigned ip address has a set prefix, so I can use that to say I\u0026rsquo;m at work and anything else would default to home.\n# exit code is 0 if on work network and 1 otherwise ifconfig | grep -i \u0026#34;inet 59.33\u0026#34; \u0026gt; /dev/null In order to prevent setting the location to the same location we need to find out what the current location is. Running scselect with no arguments displays a list of locations and the active one is marked with an asterisk (*). Here\u0026rsquo;s my list.\n\u0026gt; scselect Defined sets include: (* == current set) 575844ED-8466-479C-9567-3F0B7D767EE9\t(home) 3DF4B8B9-2E92-4F61-B684-74E0D0D38DEE\t(Automatic) * 6064213B-532D-43C9-8941-DC72B6487955\t(work) The output is a bit messy, and we need to parse out the active location.\n#!/usr/bin/env ruby # example output: * 6064213B-532D-43C9-8941-DC72B6487955\t(work) output = `scselect 2\u0026gt;\u0026amp;amp;1 | grep \u0026#39; \\\\* \u0026#39;` # parse out the location. location = output.scan(/\\(.*\\)/).first.gsub(/[\\(\\)]/, \u0026#34;\u0026#34;) # location = work We now compare the active location with the location our ip address tells us. If different, we call scselect with the new location.\nComplete script is available here\n","permalink":"https://brianpfeil.com/post/automatic-network-location/","postedOnDate":" August 5, 2011","tags":["mac","network"],"title":"Automatic Network Location"},{"categories":null,"contents":"ABC - Letters and Shapes Fun A Fun and easy app designed by parents for young children learning preschool skills of letters, numbers, and shapes. A colorful display of letters A-Z, numbers 1-10 and various shapes that are narrated with one easy tap! Very clear design with a “flashcard” like feel. This is a great app to help introduce and perfect basic letter, shape, and number skills.\nFeatures  Hear the name of the letter, number, or shape Includes letters A thru Z and numbers 0 thru 10 All the basic shapes  iPhone/iPod Touch Screenshots   iPad Screenshots ","permalink":"https://brianpfeil.com/ios-apps/abc-letters-and-shapes-fun/","postedOnDate":" January 1, 0001","tags":null,"title":""},{"categories":null,"contents":"Alpha Sound Alpha Sound is a simple ABC\u0026rsquo;s learning program for children. Children learn their letters by seeing and hearing the letter names.\n Features  Hear the name of the letter Uppercase and lowercase letters Quickly access any letter Autoplay letters Large easy to read letters Includes numbers 0 thru 10  iPhone/iPod Touch Screenshots iPad Screenshots ","permalink":"https://brianpfeil.com/ios-apps/alpha-sound/","postedOnDate":" January 1, 0001","tags":null,"title":""},{"categories":null,"contents":"Music Sound Touch Fun and easy interactive music app designed by parents for young children who enjoy the look and sound of musical instruments. A terrific collection of real musical instrument pictures and sounds that play with one easy tap. You\u0026rsquo;ll also hear the name of the instrument along with the sound. It will keep those little ones busy for quite a while!\n Features  Easy to use Real Photos High Quality Sound Narration of instrument name  iPhone/iPod Touch Screenshots iPad Screenshots ","permalink":"https://brianpfeil.com/ios-apps/music-sound-touch/","postedOnDate":" January 1, 0001","tags":null,"title":""},{"categories":null,"contents":"Vehicle Fun for Kids Fun and easy interactive vehicle app designed by parents for young children who enjoy the look and sound of vehicles. A terrific collection of real vehicle pictures and sounds that play with one easy tap. You\u0026rsquo;ll also hear the name of the vehicle along with the sound. It will keep those little ones busy for quite a while! They\u0026rsquo;ll get their fill of cars, trucks, and boats!\nFeatures  Easy to use Real Photos High Quality Sound Narration of vehicle name  Screenshots ","permalink":"https://brianpfeil.com/ios-apps/vehicle-fun-for-kids/","postedOnDate":" January 1, 0001","tags":null,"title":""}]